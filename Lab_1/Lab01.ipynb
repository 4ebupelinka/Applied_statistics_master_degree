{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPpJwBUhk3qU"
      },
      "source": [
        "\n",
        "# Лабораторная 1. Аудит набора данных и экспресс-EDA для многомерных выборок. Детектирование выбросов и пропусков, сравнение критериев. Проектирование конвейера препроцессинга и документация артефактов.\n",
        "\n",
        "**Курс:** Прикладная статистика и анализ данных   \n",
        "**Раздел 1:** Современные методы описательной статистики и разведочного анализа  \n",
        "**Тема:** Разведочный анализ многомерных данных, диагностика распределений и аномалий, очистка и препроцессинг в едином пайплайне.\n",
        "\n",
        "---\n",
        "\n",
        "## Цели ЛР\n",
        "\n",
        "1. Научиться проводить корректный EDA для многомерных таблиц: устойчивые сводки, матрицы попарных связей, проекции, ранняя диагностика проблем качества данных.\n",
        "2. Освоить диагностику формы распределений (асимметрия/тяжёлые хвосты) с использованием ECDF/QQ-плотов и робастных стандартных баллов; научиться выявлять аномалии как в одномерном, так и в многомерном варианте (через расстояние Махаланобиса и робастную ковариацию).\n",
        "3. Построить воспроизводимый конвейер препроцессинга на базе Pipeline/ColumnTransformer, исключающий утечки: импутация, масштабирование, кодирование категорий, трансформации распределений; продемонстрировать корректную валидацию.\n",
        "4. Включить минимальный машинно-проверяемый контроль качества входных данных (data validation) на основе декларативных ожиданий.\n",
        "\n",
        "Ожидаемые результаты: умение (1) формулировать первичные гипотезы по структуре данных, (2) аргументированно выбирать устойчивые сводки и визуализации, (3) объяснять эффект трансформаций на форму распределений и расстояния, (4) проектировать и документировать пайплайн препроцессинга, (5) готовить воспроизводимый ноутбук с отчётом и иллюстрациями.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Датасет, мотивация выбора и подготовка окружения\n",
        "\n",
        "Для обобщающей работы используется открытый набор Hotel bookings (бронирования отелей). Он богат числовыми и категориальными признаками (включая даты, длительности, цену/ADR), содержит пропуски и нетривиальные распределения (правые хвосты по цене, разную сезонность), что делает его существенно более реалистичным, чем «игрушечные» учебные наборы. Широко используется производная версия из сообщества TidyTuesday (CSV) — удобно загружается напрямую в pandas.\n",
        "\n",
        "> Замечание об источнике: для воспроизводимости берём «плоский» CSV TidyTuesday: https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv (содержит столбцы бронирований для двух типов отелей). Краткое описание структуры и происхождения см. в репозитории TidyTuesday и статье Data in Brief.\n",
        "\n",
        "---"
      ],
      "id": "vPpJwBUhk3qU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqHFxoYDk3qW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Подготовка окружения и загрузка:\n",
        "\n",
        "# Импорт базовых библиотек\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Статистика/моделирование\n",
        "from statsmodels.distributions.empirical_distribution import ECDF  # ECDF-кривые\n",
        "from statsmodels.graphics.gofplots import qqplot                     # QQ-плоты\n",
        "from sklearn.covariance import MinCovDet                             # робастная ковариация (MCD)\n",
        "from sklearn.preprocessing import RobustScaler, QuantileTransformer, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
        "\n",
        "# Графические параметры\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Загрузка набора данных (CSV TidyTuesday)\n",
        "URL = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\"\n",
        "df = pd.read_csv(URL)  # pandas.read_csv поддерживает URL-источники\n",
        "df.shape, df.head(3)\n"
      ],
      "id": "WqHFxoYDk3qW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDdGlIhak3qX"
      },
      "source": [
        "\n",
        "## 2. Часть 1. Разведочный анализ (EDA): устойчивые сводки и визуализация многомерности\n",
        "\n",
        "Убедиться, что строки/категории и числа распознаны корректно; явные даты соберите из компонент arrival_date_year, arrival_date_month, arrival_date_day_of_month в единый столбец (опционально).\n",
        "\n",
        "Для числовых колонок рассчитайте устойчивые сводки: медиана $\\tilde{x}$, межквартильный размах $IQR=Q_{0.75}-Q_{0.25}$, медианное абсолютное отклонение $MAD=\\mathrm{median}(|x_i-\\tilde{x}|)$.\n",
        "\n",
        "Сформируйте таблицу устойчивых сводок по ключевым числовым полям: lead_time, stays_in_weekend_nights, stays_in_week_nights, adults, children, babies, adr (average daily rate).\n"
      ],
      "id": "IDdGlIhak3qX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iMUXVVgk3qX"
      },
      "outputs": [],
      "source": [
        "# Преобразование месяца в номер и сборка даты заезда (для иллюстраций сезонности)\n",
        "month_map = {m:i for i, m in enumerate(\n",
        "    [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"], start=1)}\n",
        "df[\"arrival_month_num\"] = df[\"arrival_date_month\"].map(month_map)\n",
        "df[\"arrival_date\"] = pd.to_datetime(dict(year=df[\"arrival_date_year\"],\n",
        "                                         month=df[\"arrival_month_num\"],\n",
        "                                         day=df[\"arrival_date_day_of_month\"]), errors=\"coerce\")\n",
        "\n",
        "# Устойчивые сводки по выбранным числовым признакам\n",
        "num_cols = [\"lead_time\",\"stays_in_weekend_nights\",\"stays_in_week_nights\",\"adults\",\"children\",\"babies\",\"adr\"]\n",
        "def robust_summary(s: pd.Series):\n",
        "    s = s.dropna()\n",
        "    med = np.median(s)\n",
        "    q1, q3 = np.percentile(s, [25, 75])\n",
        "    iqr = q3 - q1\n",
        "    mad = np.median(np.abs(s - med))\n",
        "    return pd.Series({\"count\": s.size, \"median\": med, \"q1\": q1, \"q3\": q3, \"IQR\": iqr, \"MAD\": mad})\n",
        "\n",
        "robust_tbl = df[num_cols].apply(robust_summary, axis=0).T\n",
        "robust_tbl\n"
      ],
      "id": "-iMUXVVgk3qX"
    },
    {
      "cell_type": "markdown",
      "id": "a8063cb2",
      "metadata": {
        "id": "a8063cb2"
      },
      "source": [
        "### Матрицы парных связей и тепловые карты корреляций\n",
        "\n",
        "Постройте pairplot для поднабора числовых признаков (включая $\\log(\\text{adr}+1)$ для стабилизации правого хвоста).\n",
        "\n",
        "Постройте тепловую карту корреляций (Пирсон и Спирмен) и сравните паттерны (кластеры, мультиколлинеарность)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIL5qNaUk3qZ"
      },
      "outputs": [],
      "source": [
        "# Лёгкая стабилизация \"правого хвоста\" цены\n",
        "df[\"log_adr\"] = np.log1p(df[\"adr\"].clip(lower=0))\n",
        "\n",
        "# Pairplot для обзорной разведки\n",
        "sns.pairplot(df[[\"lead_time\",\"stays_in_week_nights\",\"stays_in_weekend_nights\",\"adults\",\"log_adr\"]]\n",
        "             .dropna().sample(5000, random_state=42), diag_kind=\"hist\", plot_kws=dict(alpha=0.3, s=10))\n",
        "plt.suptitle(\"Матрица парных диаграмм (подвыборка 5k)\", y=1.02)\n",
        "plt.show()\n",
        "\n",
        "# Тепловая карта корреляций (Пирсон, затем Спирмен)\n",
        "corr_p = df[num_cols].corr(method=\"pearson\")\n",
        "corr_s = df[num_cols].corr(method=\"spearman\")\n",
        "fig, axes = plt.subplots(1,2, figsize=(14,5))\n",
        "sns.heatmap(corr_p, ax=axes[0], vmin=-1, vmax=1, annot=False)\n",
        "axes[0].set_title(\"Корреляции Пирсона\")\n",
        "sns.heatmap(corr_s, ax=axes[1], vmin=-1, vmax=1, annot=False)\n",
        "axes[1].set_title(\"Корреляции Спирмена\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Пояснение: seaborn.pairplot и тепловая карта — стандартные инструменты первого взгляда на структуру признаков. С практической точки зрения полезно сопоставлять Пирсона (линейная зависимость) и Спирмена (монотонная) при правых хвостах и выбросах."
      ],
      "id": "bIL5qNaUk3qZ"
    },
    {
      "cell_type": "markdown",
      "id": "fb9682c1",
      "metadata": {
        "id": "fb9682c1"
      },
      "source": [
        "## 3. Часть 2. Исследование распределений и аномалий\n",
        "\n",
        "### ECDF и интерпретация хвостов\n",
        "\n",
        "Эмпирическая CDF (ECDF) определяется как $ \\hat{F}(x)=\\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}{X_i \\le x} $. Постройте ECDF для adr раздельно по типу отеля (hotel), отметьте вертикалями перцентили $P_{50},P_{90},P_{99}$ и SLA-пороги (если применимо)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIf82L5pk3qZ"
      },
      "outputs": [],
      "source": [
        "def plot_ecdf_by_group(df, value, group):\n",
        "    plt.figure()\n",
        "    for g, dfg in df[[value, group]].dropna().groupby(group):\n",
        "        ecdf = ECDF(dfg[value].values)\n",
        "        xs = np.linspace(dfg[value].min(), dfg[value].quantile(0.995), 400)\n",
        "        ys = ecdf(xs)\n",
        "        plt.plot(xs, ys, label=str(g))\n",
        "    for q in [0.5, 0.9, 0.99]:\n",
        "        plt.axvline(df[value].quantile(q), ls=\"--\", alpha=0.4)\n",
        "    plt.xlabel(value); plt.ylabel(\"ECDF\")\n",
        "    plt.title(f\"ECDF {value} по группам {group}\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_ecdf_by_group(df, \"adr\", \"hotel\")\n",
        "\n",
        "\n",
        "# Пояснение: ECDF позволяет читать хвостовые доли без «бининга» и сразу сравнивать группы; реализация доступна в statsmodels."
      ],
      "id": "GIf82L5pk3qZ"
    },
    {
      "cell_type": "markdown",
      "id": "caf7dd99",
      "metadata": {
        "id": "caf7dd99"
      },
      "source": [
        "### QQ-плоты и выбор трансформаций\n",
        "\n",
        "QQ-плот сравнивает квантили выборки с теоретическим распределением. Для adr постройте два QQ-плота: против нормального закона для $adr$ и для $\\log(adr+1)$. Наблюдения о «выпрямлении» линий обосновывают применение степенных/лог-трансформаций перед моделированием."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4270a07",
      "metadata": {
        "id": "a4270a07"
      },
      "outputs": [],
      "source": [
        "# QQ-плот для adr и log_adr\n",
        "fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
        "qqplot(df[\"adr\"].dropna().clip(upper=df[\"adr\"].quantile(0.999)), line=\"s\", ax=axes[0])\n",
        "axes[0].set_title(\"QQ: adr vs Normal\")\n",
        "qqplot(df[\"log_adr\"].dropna(), line=\"s\", ax=axes[1])\n",
        "axes[1].set_title(\"QQ: log(adr+1) vs Normal\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a9648cc",
      "metadata": {
        "id": "8a9648cc"
      },
      "source": [
        "### Робастные z-оценки и одномерные «выбросы»\n",
        "\n",
        "Определим модифицированную $z$-оценку $ z_i^{(MAD)} = \\dfrac{x_i-\\tilde{x}}{1.4826\\cdot MAD} $ и пометим наблюдения с $|z_i^{(MAD)}|>3.5$ как «подозрительные» для аудита."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2333f121",
      "metadata": {
        "id": "2333f121"
      },
      "outputs": [],
      "source": [
        "def robust_z(x):\n",
        "    x = np.asarray(x[~np.isnan(x)])\n",
        "    med = np.median(x)\n",
        "    mad = np.median(np.abs(x - med))\n",
        "    return (x - med) / (1.4826 * (mad + 1e-12))\n",
        "\n",
        "z = robust_z(df[\"adr\"].values)\n",
        "np.mean(np.abs(z)>3.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a482f938",
      "metadata": {
        "id": "a482f938"
      },
      "source": [
        "### Многомерные аномалии: расстояние Махаланобиса с робастной ковариацией (MCD)\n",
        "\n",
        "Расстояние Махаланобиса $ d_i=\\sqrt{(x_i-\\hat{\\mu})^\\top \\hat{\\Sigma}^{-1} (x_i-\\hat{\\mu})} $ при робастных оценках $(\\hat{\\mu},\\hat{\\Sigma})$ (алгоритм Minimum Covariance Determinant) уменьшает влияние «хвостов» и «рычагов». Модель MinCovDet реализована в scikit-learn. Для числового подпространства оцените $d_i^2$ и отметьте точки с $d_i^2>\\chi^2_{p,,0.995}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d40c0ea1",
      "metadata": {
        "id": "d40c0ea1"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import chi2\n",
        "\n",
        "X = df[[\"lead_time\",\"stays_in_week_nights\",\"stays_in_weekend_nights\",\"adults\",\"log_adr\"]].dropna().values\n",
        "mcd = MinCovDet(random_state=42).fit(X)  # FAST-MCD\n",
        "d2 = mcd.mahalanobis(X)                  # квадраты расстояний\n",
        "thr = chi2.ppf(0.995, df=X.shape[1])     # порог по chi2(p)\n",
        "np.mean(d2 > thr), thr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "122b2f2f",
      "metadata": {
        "id": "122b2f2f"
      },
      "source": [
        "\n",
        "\n",
        "> Пояснение: MinCovDet даёт робастные оценки центра/ковариации; квадраты расстояний сопоставимы с квантилями $\\chi^2_p$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLLl5xNpk3qd"
      },
      "source": [
        "\n",
        "## Часть 3. Очистка и препроцессинг в едином пайплайне (без утечки)\n",
        "\n",
        "Постановка: подготовить признаки для простой задачи бинарной классификации отмены бронирования (is_canceled) с корректной обработкой пропусков и категорий; цель — не «высокий скор», а правильно устроенный конвейер.\n",
        "\n",
        "Шаги:\n",
        "1. Разделите признаки на числовые и категориальные; для числовых примените импутацию (медиана) и робастное масштабирование (RobustScaler), устойчивое к хвостам $IQR$; для сильно асимметричных величин можно использовать QuantileTransformer (к нормальному распределению).\n",
        "2. Для категориальных — импутация «most_frequent» и OneHotEncoder(handle_unknown=\"ignore\").\n",
        "3. Соберите всё через ColumnTransformer и Pipeline; проверьте метрику на валидации (StratifiedKFold)."
      ],
      "id": "MLLl5xNpk3qd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yun8FUHXk3qd"
      },
      "outputs": [],
      "source": [
        "# Целевая переменная и поднабор признаков\n",
        "y = df[\"is_canceled\"].astype(int)\n",
        "features_num = [\"lead_time\",\"stays_in_week_nights\",\"stays_in_weekend_nights\",\"adults\",\"children\",\"babies\",\"adr\"]\n",
        "features_cat = [\"hotel\",\"meal\",\"market_segment\",\"distribution_channel\",\"reserved_room_type\",\"customer_type\",\"deposit_type\",\"country\"]\n",
        "\n",
        "X = df[features_num + features_cat]\n",
        "\n",
        "# Простейшая стратегия импутации\n",
        "num_pipe = Pipeline(steps=[\n",
        "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scale\", RobustScaler())  # масштаб по медиане и IQR\n",
        "])\n",
        "\n",
        "cat_pipe = Pipeline(steps=[\n",
        "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", min_frequency=20))\n",
        "])\n",
        "\n",
        "pre = ColumnTransformer([\n",
        "    (\"num\", num_pipe, features_num),\n",
        "    (\"cat\", cat_pipe, features_cat)\n",
        "])\n",
        "\n",
        "clf = Pipeline(steps=[\n",
        "    (\"pre\", pre),\n",
        "    (\"est\", LogisticRegression(max_iter=2000, n_jobs=None))\n",
        "])\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(clf, X, y, cv=cv, scoring=\"roc_auc\")\n",
        "scores.mean(), scores.std()\n"
      ],
      "id": "Yun8FUHXk3qd"
    },
    {
      "cell_type": "markdown",
      "id": "1c2a1832",
      "metadata": {
        "id": "1c2a1832"
      },
      "source": [
        "> Пояснение: RobustScaler центрирует по медиане и масштабирует по $IQR$, снижая влияние выбросов; QuantileTransformer (по желанию) может дополнительно «выпрямить» маргинальные распределения (но меняет геометрию расстояний). ColumnTransformer/Pipeline предотвращают утечки, обучая все шаги только на обучающей части.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c62eb1c",
      "metadata": {
        "id": "5c62eb1c"
      },
      "source": [
        "## 5. Мини-валидация качества входных данных (data validation)\n",
        "\n",
        "Перед обучением полезно проверять простейшие инварианты набора: уникальность идентификаторов (если есть), домен значений, отсутствие отрицательных длительностей/количеств, адекватность валют и т. п. В промышленных пайплайнах применяют декларативные ожидания (expectations), которые автоматически валидируют таблицу и формируют отчёт. Пример ниже — «микро-suite» в стиле Great Expectations (идея/терминология); его можно встроить в ноутбук/скрипт как быстрый гейт на входе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF1c4xrMk3qe"
      },
      "outputs": [],
      "source": [
        "# Простейшие проверки \"как ожидания\": возвращают True/False и список нарушений\n",
        "def expect_not_null(s: pd.Series, name: str):\n",
        "    bad = s[s.isna()]\n",
        "    return bad.empty, bad.index.tolist()\n",
        "\n",
        "def expect_ge(s: pd.Series, name: str, min_value: float):\n",
        "    bad = s[s < min_value]\n",
        "    return bad.empty, bad.index.tolist()\n",
        "\n",
        "checks = {\n",
        "    \"adr_nonneg\": expect_ge(df[\"adr\"].fillna(0), \"adr\", 0.0),\n",
        "    \"adults_nonneg\": expect_ge(df[\"adults\"].fillna(0), \"adults\", 0.0),\n",
        "    \"lead_time_nonneg\": expect_ge(df[\"lead_time\"].fillna(0), \"lead_time\", 0.0),\n",
        "    \"hotel_not_null\": expect_not_null(df[\"hotel\"], \"hotel\")\n",
        "}\n",
        "\n",
        "{key: ok for key, (ok, idx) in checks.items()}"
      ],
      "id": "sF1c4xrMk3qe"
    },
    {
      "cell_type": "markdown",
      "id": "fd38a5e5",
      "metadata": {
        "id": "fd38a5e5"
      },
      "source": [
        "> Пояснение: В полномасштабных проектах такие правила оформляют как «expectation suites» (например, Great Expectations) с HTML-отчётами и историей прогонов."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edb06ce1",
      "metadata": {
        "id": "edb06ce1"
      },
      "source": [
        "## 6. Формулы и блок-схема работы\n",
        "\n",
        "Ключевые формулы:\n",
        "- Эмпирическая CDF: $ \\hat{F}(x)=\\tfrac{1}{n}\\sum_{i=1}^n \\mathbf{1}{X_i\\le x} $.\n",
        "- Межквартильный размах: $ \\mathrm{IQR}=Q_{0.75}-Q_{0.25} $.\n",
        "- MAD: $ \\mathrm{MAD}=\\mathrm{median}(|x_i-\\tilde{x}|) $, робастный масштаб $ \\hat{\\sigma}_{MAD}=1.4826\\cdot \\mathrm{MAD} $.\n",
        "- Робастная $z$-оценка: $ z_i^{(MAD)}=\\dfrac{x_i-\\tilde{x}}{1.4826\\cdot \\mathrm{MAD}} $.\n",
        "- Расстояние Махаланобиса: $ d_i=\\sqrt{(x_i-\\hat{\\mu})^\\top \\hat{\\Sigma}^{-1}(x_i-\\hat{\\mu})} $.\n",
        "- Порог по $\\chi^2$: $ d_i^2>\\chi^2_{p,,1-\\alpha} $ — «аномалия» на уровне значимости $\\alpha$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8423e92",
      "metadata": {
        "id": "a8423e92"
      },
      "source": [
        "### Блок-схема (ASCII):\n",
        "    \n",
        "    - A[[Загрузка CSV]]\n",
        "    \n",
        "    - B[Быстрые проверки: типы / NA]\n",
        "    \n",
        "    - C[EDA: устойчивые сводки;<br/>корреляции; pairplot]\n",
        "    \n",
        "    - D[ECDF, QQ: диагностика формы]\n",
        "    \n",
        "    - E[Outliers: z(MAD), MCD / Махаланобис]\n",
        "    \n",
        "    - F[Пайплайн препроцессинга:<br/>импутация → масштаб/преобр. → OHE]\n",
        "    \n",
        "    - G[Валидация данных (expectations)]\n",
        "    \n",
        "    - H[Кросс-валидация модели]\n",
        "\n",
        "    A --> B --> C\n",
        "    C --> D\n",
        "    C --> E\n",
        "    D --> F\n",
        "    E --> F\n",
        "    F --> G --> H\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVqGOfD-k3qf"
      },
      "source": [
        "\n",
        "## 7. Контрольные задания\n",
        "\n",
        "### 1. EDA и устойчивые сводки.\n",
        "Сформируйте таблицу устойчивых сводок по выбранным числовым признакам (см. § 2.1), прокомментируйте различия «медиана/MAD/IQR» vs «среднее/SD» в правохвостых столбцах (напр., adr, lead_time). Объясните, почему медиана/IQR устойчивее при наличии редких экстремумов, и как это видно на гистограммах/ECDF. Обязательно включите матрицу корреляций (Пирсон и Спирмен) и разберите не менее двух несоответствий между ними: где линейная связь слабая, а монотонная - выражена (или наоборот). Сформулируйте как минимум три первичные гипотезы о структуре данных: групповые различия (тип отеля), сезонность по месяцу приезда, потенциальные взаимодействия признаков (например, lead_time × сезон). Сохраните рисунки (pairplot, heatmap) и кратко опишите интерпретацию.\n",
        "\n",
        "### 2. Форма распределений и трансформации.\n",
        "Постройте ECDF для adr (цены/сутки) раздельно по типу отеля и отметьте $P_{50},P_{90},P_{99}$. Сравните хвосты: есть ли систематический сдвиг у одной из групп? Добавьте QQ-плоты adr и $\\log(adr+1)$ против нормального закона; оцените, насколько лог-трансформация «выпрямляет» хвосты и среднюю часть. Обоснуйте, какие признаки в дальнейшем разумно трансформировать (лог/степень/квантили) и почему. В отчёте отразите формулы ECDF и аргументы про хвостовые доли (например, долю наблюдений с adr выше $P_{95}$). Сопоставьте выводы с корреляционными матрицами: как трансформации влияют на линейные коэффициенты? Приведите не менее двух иллюстраций с пояснениями.\n",
        "\n",
        "### 3. Одномерные и многомерные аномалии.\n",
        "Для adr вычислите модифицированные $z$-оценки $z^{(MAD)}$ и дайте оценку доли наблюдений с $|z|>3.5$. Проверьте несколько «аномальных» строк на предмет ошибок/редких режимов (например, высокий adr при коротком lead_time). В многомерном подпространстве оцените квадраты расстояний Махаланобиса на базе робастной ковариации (MCD) и пометьте точки с $d^2>\\chi^2_{p,0.995}$. Сравните наборы «аномальных» наблюдений из одномерного и многомерного подходов: где методы согласуются, а где — выявляют разные случаи? Объясните, почему многомерная метка может отличаться (корреляции, другая геометрия). Приложите диаграмму рассеяния с цветовой пометкой «аномалий» и прокомментируйте.\n",
        "\n",
        "### 4. Пайплайн препроцессинга и валидация.\n",
        "Соберите Pipeline + ColumnTransformer для задачи is_canceled (см. § 4), добейтесь корректной кросс-валидации (StratifiedKFold) и отчётливо объясните, почему такая организация исключает утечки (все статистики fit обучаются только на тренировочных фолдах). Сравните две конфигурации: (A) RobustScaler для чисел; (B) та же схема + QuantileTransformer для сильно асимметричных чисел (например, adr, lead_time). Приведите среднее и стандартное отклонение ROC-AUC по фолдам, а также поясните отличия. Добавьте «микро-suite» проверок входных данных (см. § 5), опишите, какие нарушения он ловит на этом наборе. Сохраните финальный рисунок или таблицу с результатами."
      ],
      "id": "ZVqGOfD-k3qf"
    },
    {
      "cell_type": "markdown",
      "id": "4ea9192d",
      "metadata": {
        "id": "4ea9192d"
      },
      "source": [
        "## 8. Критерии оценивания\n",
        "\n",
        "Воспроизводимость (10 %) — ноутбук запускается «с нуля»; ссылки на источник данных и версии библиотек указаны; установлен фиксированный random_state.\n",
        "\n",
        "Корректный EDA (25 %) — устойчивые сводки, матрицы корреляций (Пирсон/Спирмен), интерпретации по группам/сезонам; аккуратность графиков (легенды, подписи, осмысленные лимиты).\n",
        "\n",
        "Диагностика распределений (20 %) — ECDF/QQ-плоты с внятными выводами о хвостах и трансформациях; корректные формулы/обоснования.\n",
        "\n",
        "Аномалии (15 %) — корректная реализация $z^{(MAD)}$ и MCD-Махаланобиса, сравнение одномерного и многомерного кейсов с предметными комментариями.\n",
        "\n",
        "Пайплайн и валидация (20 %) — отсутствие утечек, понятная разметка числовых/категориальных, адекватные трансформеры, кросс-валидация, краткий анализ метрик; наличие мини-валидации качества входных данных.\n",
        "\n",
        "Отчётность и стиль (10 %) — готовый отчет, академический слог, структурированность (рисунки, таблицы, формулы), равернутые и понятные подписи и интерпретации."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72cc60a8",
      "metadata": {
        "id": "72cc60a8"
      },
      "source": [
        "## 9. Приложение: дополнительные фрагменты кода"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07cbe747",
      "metadata": {
        "id": "07cbe747"
      },
      "outputs": [],
      "source": [
        "# Подсветка многомерных аномалий на парных графиках\n",
        "\n",
        "# Метки \"аномалий\" по порогу chi2 для визуализации\n",
        "mask = d2 > thr\n",
        "X_df = pd.DataFrame(X, columns=[\"lead_time\",\"stays_wd\",\"stays_we\",\"adults\",\"log_adr\"])\n",
        "X_df[\"outlier\"] = np.where(mask, \"anom\", \"ok\")\n",
        "sns.pairplot(X_df.sample(5000, random_state=42), hue=\"outlier\", plot_kws=dict(alpha=0.4, s=10))\n",
        "plt.suptitle(\"Многомерные аномалии по робастному Махаланобису (подвыборка)\", y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4499dd13",
      "metadata": {
        "id": "4499dd13"
      },
      "outputs": [],
      "source": [
        "# Вариант с QuantileTransformer для «тяжёлых» чисел\n",
        "\n",
        "skewed = [\"lead_time\",\"adr\"]\n",
        "num_pipe_qt = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"qt\", QuantileTransformer(output_distribution=\"normal\", random_state=42))\n",
        "])\n",
        "\n",
        "pre_qt = ColumnTransformer([\n",
        "    (\"num_qt\", num_pipe_qt, skewed),\n",
        "    (\"num_rs\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")), (\"scale\", RobustScaler())]),\n",
        "     list(set(features_num) - set(skewed))),\n",
        "    (\"cat\", cat_pipe, features_cat)\n",
        "])\n",
        "\n",
        "clf_qt = Pipeline([(\"pre\", pre_qt), (\"est\", LogisticRegression(max_iter=2000))])\n",
        "scores_qt = cross_val_score(clf_qt, X, y, cv=cv, scoring=\"roc_auc\")\n",
        "scores.mean(), scores.std(), scores_qt.mean(), scores_qt.std()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aff039e",
      "metadata": {
        "id": "0aff039e"
      },
      "source": [
        "> Пояснение: QuantileTransformer приводит маргинальные распределения к Uniform/Normal, «сжимая» хвосты; полезно на правохвостых признаках, однако меняет метрику расстояний — интерпретируйте аккуратно."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}