{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4f4658",
   "metadata": {
    "id": "ad4f4658"
   },
   "source": [
    "\n",
    "# Лабораторная работа 2. Регрессия, мультиколлинеарность, множественные сравнения, байесовские выводы и ресемплинг\n",
    "\n",
    "**Курс:** Прикладная статистика и анализ данных\n",
    "\n",
    "**Раздел 2:** Статистическое моделирование, гипотезы и интерпретация    \n",
    "\n",
    "**Цель:** построить и сравнить несколько спецификаций множественной линейной регрессии, диагностировать мультиколлинеарность и применить регуляризацию; корректно проверять семейства гипотез (контрасты/коэффициенты) с контролем FDR; провести байесовскую регрессию с априорами и постериорной проверкой предсказаний; оценить доверие к выводам с помощью бутстрепа и перестановочных тестов.\n",
    "\n",
    "**Ожидаемые результаты:** уметь (1) задавать и интерпретировать линейные модели с взаимодействиями; (2) диагностировать и снижать мультиколлинеарность (VIF, Ridge/Lasso с подбором $\\lambda$ по CV); (3) применять FDR-контроль к семействам проверок; (4) формулировать априоры и читать апостериор (PyMC), выполнять PPC; (5) строить бутстреп-ДИ и перестановочные p-значения; (6) оформлять воспроизводимый отчёт.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb347b5b",
   "metadata": {
    "id": "eb347b5b"
   },
   "source": [
    "## 1. Данные и дизайн эксперимента\n",
    "\n",
    "Требования к данным. Желательно $n\\in[5\\cdot10^4,1.5\\cdot10^5]$, смешанные типы (число+категории+время). Разрешены большие наборы с честной подвыборкой (например, фиксированный интервал времени/случайная выборка 100–120 тыс. строк). Хорошими источниками являются городские такси (NYC TLC, Chicago Taxi), e-commerce (Olist), поведенческие/рейтинговые (MovieLens), дорожно-транспортные происшествия (STATS19).\n",
    "\n",
    "Вопросы и переменные. Определите: целевую переменную $y$ (непрерывную: выручка/длительность/сумма), набор предикторов $X$ (стоимость, время суток, категория товара, погодные/районные признаки), потенциальные взаимодействия (например, «час$\\times$район»). Разбейте данные на обучающую/валидационную схему с кросс-валидацией. Для задач на транзакциях важно исключить утечки (например, признаки, формирующиеся пост-фактум).\n",
    "\n",
    "Критерии качества и риска. Выберите метрики: $R^2$, RMSE/MAE для базовой модели; для сравнения моделей используйте перекрёстную проверку (KFold/StratifiedKFold, при необходимости — TimeSeriesSplit). Фиксируйте случайные зерна и протоколы предобработки.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12536dc9",
   "metadata": {
    "id": "12536dc9"
   },
   "source": [
    "## 2. Линейные модели и ANOVA: спецификация и сравнение (минимум 600 слов)\n",
    "\n",
    "OLS-модель. Запишите базовую спецификацию: $y = X\\beta+\\varepsilon$, где $\\varepsilon\\sim \\mathcal{N}(0,\\sigma^2 I)$. Оценка МНК: $\\hat\\beta=(X^\\top X)^{-1}X^\\top y$. Включите категориальные эффекты (OHE) и взаимодействия (например, «категория$\\times$час»). Сравните вложенные модели через частичные F-тесты/девиансы.\n",
    "\n",
    "ANOVA/контрасты. Для сравнения спецификаций используйте дисперсионный анализ в смысле разложения суммы квадратов и тестирования добавочных блоков признаков. Вектор контраста $c$ для проверки гипотезы $H_0: c^\\top\\beta=0$; оценка и стандартная ошибка выводятся из ковариационной матрицы $\\widehat{\\mathrm{Var}}(\\hat\\beta)=\\hat\\sigma^2 (X^\\top X)^{-1}$.\n",
    "\n",
    "Множественные проверки. При тестировании множества коэффициентов/контрастов применяйте контроль FDR (Benjamini–Hochberg): упорядочьте p-значения $p_{(1)}\\le\\cdots\\le p_{(m)}$ и найдите максимальный $k$ с $p_{(k)}\\le \\frac{k}{m}\\alpha$; значимыми считаются $p_{(1)},\\dots,p_{(k)}$. Реализация — statsmodels.stats.multitest.multipletests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22259257",
   "metadata": {
    "id": "22259257"
   },
   "source": [
    "## 3. Мультиколлинеарность, VIF и регуляризация (минимум 600 слов)\n",
    "\n",
    "Диагностика. Индекс инфляции дисперсии для признака $j$: $VIF_j=\\frac{1}{1-R_j^2}$, где $R_j^2$ — коэффициент детерминации регрессии $x_j$ на все прочие признаки. Большие $VIF$ (условно $>10$) указывают на нестабильность оценок и раздутые стандартные ошибки.\n",
    "Ridge/Lasso. Регуляризованные оценки:\n",
    "- Ridge: $\\hat\\beta_\\lambda=\\arg\\min_\\beta |y-X\\beta|_2^2 + \\lambda|\\beta|_2^2$,\n",
    "- Lasso: $\\hat\\beta_\\lambda=\\arg\\min_\\beta |y-X\\beta|_2^2 + \\lambda|\\beta|_1$.\n",
    "Подбирайте $\\lambda$ по кросс-валидации (например, лог-сетка). Ridge снижает дисперсию оценок и стабилизирует прогнозы при умеренной корреляции; Lasso даёт разреженность и встроенный отбор признаков, но чувствителен к масштабированию. См. документы и примеры scikit-learn по OLS/Ridge и обобщениям."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de13612",
   "metadata": {
    "id": "8de13612"
   },
   "source": [
    "## 4. Байесовская регрессия и постериорно-предсказательная проверка\n",
    "\n",
    "Модель. Пусть $y\\mid X,\\beta,\\sigma^2\\sim \\mathcal{N}(X\\beta,\\sigma^2 I)$, априорные распределения $p(\\beta)$ и $p(\\sigma^2)$ (например, $\\beta\\sim \\mathcal{N}(0,\\tau^2 I)$; $\\sigma\\sim \\mathrm{HalfCauchy}$). Постериор: $p(\\beta,\\sigma^2\\mid y)\\propto p(y\\mid X,\\beta,\\sigma^2),p(\\beta),p(\\sigma^2)$. Предсказательное распределение для нового $x_\\star$: $p(y_\\star\\mid x_\\star,y)=\\int p(y_\\star\\mid x_\\star,\\beta,\\sigma^2),p(\\beta,\\sigma^2\\mid y),d\\beta,d\\sigma^2$.\n",
    "\n",
    "Практика. В PyMC укажите модель в явном виде, используйте NUTS для сэмплинга, проверьте сходимость (R-hat, ESS), постериорные интервалые для коэффициентов и PPC для согласованности с наблюдаемыми данными."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46baa873",
   "metadata": {
    "id": "46baa873"
   },
   "source": [
    "## 5. Ресемплинг: бутстреп-ДИ и перестановочные тесты\n",
    "\n",
    "Бутстреп. Для параметра $\\theta=g(X,y)$ (например, коэффициента $\\beta_j$ или RMSE) сформируйте $B$ бутстреп-выборок с возвращением, получите ${\\hat\\theta^{(b)}}{b=1}^B$, и задайте ДИ по процентилям: $[q{\\alpha/2},q_{1-\\alpha/2}]$.\n",
    "\n",
    "Перестановочные тесты. Для статистики $T$ (например, корреляция/разность RMSE между моделями на одинаковых фолдах) переставляйте метки/знаки по нулевой гипотезе, получая ${T^{(b)}}$, и вычисляйте $p$-значение $p=\\frac{1+\\sum_{b=1}^B \\mathbb{I}(|T^{(b)}|\\ge |T_{\\text{obs}}|)}{1+B}$. Эти процедуры особенно полезны при нарушениях гауссовости/гомоскедастичности либо сложной зависимой структуре данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae0bfda",
   "metadata": {
    "id": "bae0bfda"
   },
   "source": [
    "## Пул рекомендованных датасетов\n",
    "\n",
    "D1. NYC TLC Trip Records (Yellow/Green). Возьмите один месяц и случайную подвыборку 100–120k поездок (например, январь 2019). Документация и структура полей — в руководстве TLC.\n",
    "\n",
    "D2. Chicago Taxi Trips. Фильтрация по кварталу 2020-го даёт нужный объём; таблица содержит стоимость, время, гео-идентификаторы.\n",
    "\n",
    "D3. Olist Brazilian E-commerce. Таблица orders $\\approx 99,441$ заказов + связи с продуктами/категориями/логистикой. Отлично подходит для регрессии по выручке/времени доставки.\n",
    "\n",
    "D4. MovieLens 100K. 100k рейтингов с признаками пользователей/фильмов; можно строить регрессию по рейтингу, учитывая жанры и время.\n",
    "\n",
    "D5. UK Road Safety (STATS19). Выберите один год (например, 2017) и сформируйте подмножество ≈100–140k инцидентов, обогащая погодой/дорожными условиями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a84beae",
   "metadata": {
    "id": "9a84beae"
   },
   "source": [
    "## 35 вариантов заданий (обобщающие, с привязкой к D1–D5)\n",
    "### Общие методические требования (для всех вариантов):\n",
    "1) Постройте базовую OLS-модель (целевую переменную укажу в каждом варианте).\n",
    "2) Выполните диагностику мультиколлинеарности (VIF) и сравните с Ridge/Lasso (подбор $\\lambda$ по $K$-fold CV).\n",
    "3) Проведите проверки гипотез по коэффициентам/контрастам; множественные сравнения контролируйте по BH-FDR.\n",
    "4) Постройте байесовскую версию ключевой модели с умеренно информативными априорами и выполните предиктивную проверку (PPC).\n",
    "5) Оцените устойчивость: бутстреп-ДИ для ключевого показателя (RMSE/MAE/$R^2$) и перестановочный тест для сопоставления двух моделей.\n",
    "6) Объём данных: используйте подвыборку 50–150 тыс. строк из указанного источника, обоснуйте схему семплинга (по месяцам/зонам/времени и т. п.).\n",
    "\n",
    "MovieLens-Rating (D4). Цель: предсказать rating. Признаки: жанровые фиктивные переменные (из movies.csv), средний рейтинг фильма (leave-one-out), активность пользователя (кол-во оценок; LOO), временной тренд по году. Сравните OLS vs. Ridge; выполните BH-FDR по семейству жанров. Бутстреп-ДИ для $R^2$; перестановка для разницы RMSE между OLS/Ridge; байес-версия с частичным пуллингом по фильмам/пользователям (иерархичность)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c19a99-bfce-4d59-a92a-a86bc90405c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD = C:\\Users\\batar\\Python\\Applied_statistics_master_degree\\Lab_2\n"
     ]
    }
   ],
   "source": [
    "# Импорты и фиксируем зерно случайности для воспроизводимости\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Убедимся, что рабочая директория — папка с ноутбуком\n",
    "print(\"CWD =\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46e51cf-fe5d-4a05-8e77-60b3f628209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4) (1682, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   user_id  movie_id  rating  timestamp\n",
       " 0      196       242       3  881250949\n",
       " 1      186       302       3  891717742\n",
       " 2       22       377       1  878887116\n",
       " 3      244        51       2  880606923\n",
       " 4      166       346       1  886397596,\n",
       "    movie_id             title release_date  video_release  \\\n",
       " 0         1  Toy Story (1995)  01-Jan-1995            NaN   \n",
       " 1         2  GoldenEye (1995)  01-Jan-1995            NaN   \n",
       " \n",
       "                                             imdb_url  unknown  Action  \\\n",
       " 0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       " 1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       " \n",
       "    Adventure  Animation  Children's  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
       " 0          0          1           1  ...        0          0       0        0   \n",
       " 1          1          0           0  ...        0          0       0        0   \n",
       " \n",
       "    Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       " 0        0        0       0         0    0        0  \n",
       " 1        0        0       0         1    0        0  \n",
       " \n",
       " [2 rows x 24 columns])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пути (адаптируются, если ноутбук лежит в C:...\\Lab_2\\)\n",
    "data_dir = Path(\"ml-100k\")\n",
    "\n",
    "path_ratings = data_dir / \"u.data\"\n",
    "path_items   = data_dir / \"u.item\"\n",
    "path_users   = data_dir / \"u.user\"   # пока не используем, но оставим для расширений\n",
    "\n",
    "# Загрузка\n",
    "ratings = pd.read_csv(\n",
    "    path_ratings, sep=\"\\t\", header=None,\n",
    "    names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    ")\n",
    "\n",
    "items = pd.read_csv(\n",
    "    path_items, sep=\"|\", header=None, encoding=\"latin-1\",\n",
    "    names=[\n",
    "        \"movie_id\",\"title\",\"release_date\",\"video_release\",\"imdb_url\",\n",
    "        \"unknown\",\"Action\",\"Adventure\",\"Animation\",\"Children's\",\"Comedy\",\"Crime\",\n",
    "        \"Documentary\",\"Drama\",\"Fantasy\",\"Film-Noir\",\"Horror\",\"Musical\",\"Mystery\",\n",
    "        \"Romance\",\"Sci-Fi\",\"Thriller\",\"War\",\"Western\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(ratings.shape, items.shape)\n",
    "ratings.head(), items.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94006a9-7f91-4dcd-9e58-4a421f027212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 100000\n",
      "Users: 943 Movies: 1682\n",
      "Years (rate): 1997 – 1998\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>dt</th>\n",
       "      <th>year_rate</th>\n",
       "      <th>year_release</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>year_release_c</th>\n",
       "      <th>year_rate_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>1997-12-04 15:55:49+00:00</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.04324</td>\n",
       "      <td>-0.47101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>1998-04-04 19:22:22+00:00</td>\n",
       "      <td>1998</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.04324</td>\n",
       "      <td>0.52899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>1997-11-07 07:18:36+00:00</td>\n",
       "      <td>1997</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.04324</td>\n",
       "      <td>-0.47101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>1997-11-27 05:02:03+00:00</td>\n",
       "      <td>1997</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.04324</td>\n",
       "      <td>-0.47101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>1998-02-02 05:33:16+00:00</td>\n",
       "      <td>1998</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.04324</td>\n",
       "      <td>0.52899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp                        dt  year_rate  \\\n",
       "0      196       242       3  881250949 1997-12-04 15:55:49+00:00       1997   \n",
       "1      186       302       3  891717742 1998-04-04 19:22:22+00:00       1998   \n",
       "2       22       377       1  878887116 1997-11-07 07:18:36+00:00       1997   \n",
       "3      244        51       2  880606923 1997-11-27 05:02:03+00:00       1997   \n",
       "4      166       346       1  886397596 1998-02-02 05:33:16+00:00       1998   \n",
       "\n",
       "   year_release  unknown  Action  Adventure  ...  Horror  Musical  Mystery  \\\n",
       "0        1997.0        0       0          0  ...       0        0        0   \n",
       "1        1997.0        0       0          0  ...       0        0        1   \n",
       "2        1994.0        0       0          0  ...       0        0        0   \n",
       "3        1994.0        0       0          0  ...       0        0        0   \n",
       "4        1997.0        0       0          0  ...       0        0        0   \n",
       "\n",
       "   Romance  Sci-Fi  Thriller  War  Western  year_release_c  year_rate_c  \n",
       "0        0       0         0    0        0         9.04324     -0.47101  \n",
       "1        0       0         1    0        0         9.04324      0.52899  \n",
       "2        0       0         0    0        0         6.04324     -0.47101  \n",
       "3        1       0         0    1        1         6.04324     -0.47101  \n",
       "4        0       0         0    0        0         9.04324      0.52899  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Парсим год релиза из строки \"dd-Mmm-YYYY\", иногда есть пропуски\n",
    "def parse_year_from_date(s):\n",
    "    if isinstance(s, str) and len(s) >= 4:\n",
    "        try:\n",
    "            return int(s[-4:])\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "items[\"year_release\"] = items[\"release_date\"].apply(parse_year_from_date)\n",
    "genre_cols = [\n",
    "    \"unknown\",\"Action\",\"Adventure\",\"Animation\",\"Children's\",\"Comedy\",\"Crime\",\n",
    "    \"Documentary\",\"Drama\",\"Fantasy\",\"Film-Noir\",\"Horror\",\"Musical\",\"Mystery\",\n",
    "    \"Romance\",\"Sci-Fi\",\"Thriller\",\"War\",\"Western\"\n",
    "]\n",
    "\n",
    "# Превратим timestamp оценок в календарный год — это \"временной тренд по году\" с точки зрения момента оценки\n",
    "ratings[\"dt\"] = pd.to_datetime(ratings[\"timestamp\"], unit=\"s\", utc=True)\n",
    "ratings[\"year_rate\"] = ratings[\"dt\"].dt.year.astype(int)\n",
    "\n",
    "# Склеиваем\n",
    "df = ratings.merge(\n",
    "    items[[\"movie_id\", \"year_release\"] + genre_cols],\n",
    "    on=\"movie_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Обработка пропусков года релиза (редки): заменим на медиану\n",
    "df[\"year_release\"] = df[\"year_release\"].fillna(df[\"year_release\"].median())\n",
    "\n",
    "# Центрирование временных признаков (ортогонализует сдвиг)\n",
    "df[\"year_release_c\"] = df[\"year_release\"] - df[\"year_release\"].mean()\n",
    "df[\"year_rate_c\"]    = df[\"year_rate\"]    - df[\"year_rate\"].mean()\n",
    "\n",
    "# Контроль размера и базовые sanity-checks\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Users:\", df[\"user_id\"].nunique(), \"Movies:\", df[\"movie_id\"].nunique())\n",
    "print(\"Years (rate):\", df[\"year_rate\"].min(), \"–\", df[\"year_rate\"].max())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ebd056-2a1c-44f6-9e8b-75f02aa25f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: rating\n",
      "Base features (count): 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['unknown',\n",
       "  'Action',\n",
       "  'Adventure',\n",
       "  'Animation',\n",
       "  \"Children's\",\n",
       "  'Comedy',\n",
       "  'Crime',\n",
       "  'Documentary'],\n",
       " '...',\n",
       " ['Thriller', 'War', 'Western', 'year_release_c', 'year_rate_c'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Целевая переменная\n",
    "y_col = \"rating\"\n",
    "\n",
    "# Базовые предикторы: жанры + временные тренды\n",
    "# (LOO-признаки добавим позже в разделе фичеинжиниринга, чтобы не допустить утечек)\n",
    "base_feature_cols = genre_cols + [\"year_release_c\", \"year_rate_c\"]\n",
    "\n",
    "# Пример потенциальных взаимодействий для следующих пунктов (сейчас только объявляем):\n",
    "# - Жанр × год оценки (динамика восприятия жанра)\n",
    "# - Жанр × год релиза (устаревание эффекта)\n",
    "# Эти взаимодействия создадим позже осознанно, когда будем смотреть VIF/регуляризацию.\n",
    "potential_interactions = {\n",
    "    \"genre_x_year_rate\": [(\"year_rate_c\", g) for g in genre_cols],\n",
    "    \"genre_x_year_release\": [(\"year_release_c\", g) for g in genre_cols],\n",
    "}\n",
    "\n",
    "print(\"Target:\", y_col)\n",
    "print(\"Base features (count):\", len(base_feature_cols))\n",
    "base_feature_cols[:8], \"...\", base_feature_cols[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7e022d-266f-441c-8854-2e241714e0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test size = 20008\n",
      "Fold 2: test size = 20008\n",
      "Fold 3: test size = 20008\n",
      "Fold 4: test size = 19988\n",
      "Fold 5: test size = 19988\n",
      "Sum test sizes = 100000 == 100000\n"
     ]
    }
   ],
   "source": [
    "# Для рейтингов критично: пользовательские паттерны.\n",
    "# Чтобы не «подсматривать» индивидуальные эффекты, держим пользователей разнесёнными по фолдам.\n",
    "# Это снижает optimistic bias и имитирует генерализацию на новых пользователей.\n",
    "\n",
    "n_splits = 5\n",
    "cv_splitter = GroupKFold(n_splits=n_splits)\n",
    "cv_groups = df[\"user_id\"].values  # группы = пользователи\n",
    "\n",
    "# Пример: посчитаем размер фолдов (без обучения — просто дизайн)\n",
    "fold_sizes = []\n",
    "for fold_id, (_, te_idx) in enumerate(cv_splitter.split(df, groups=cv_groups), 1):\n",
    "    fold_sizes.append(len(te_idx))\n",
    "    print(f\"Fold {fold_id}: test size = {len(te_idx)}\")\n",
    "\n",
    "print(\"Sum test sizes =\", sum(fold_sizes), \"==\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "322b714a-d048-40ca-962e-0fd25b1e4919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики готовы: ['RMSE', 'MAE', 'R2']\n",
      "Random state = 42\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred)\n",
    "\n",
    "metrics = {\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAE\": mae,\n",
    "    \"R2\": r2\n",
    "}\n",
    "\n",
    "print(\"Метрики готовы:\", list(metrics.keys()))\n",
    "print(\"Random state =\", RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b220493-8d13-410f-9dff-d7da1031f95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_base shape: (100000, 21) y shape: (100000,)\n",
      "Пример жанровых частот:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Drama         0.39895\n",
       "Comedy        0.29832\n",
       "Action        0.25589\n",
       "Thriller      0.21872\n",
       "Romance       0.19461\n",
       "Adventure     0.13753\n",
       "Sci-Fi        0.12730\n",
       "War           0.09398\n",
       "Crime         0.08055\n",
       "Children's    0.07182\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# На этом шаге мы НЕ создаём LOO-признаки, чтобы не спутать дизайн и вычисления.\n",
    "# Здесь — только базовый X для первичной диагностики и профилирования распределений.\n",
    "\n",
    "X_base = df[base_feature_cols].astype(float).copy()\n",
    "y = df[y_col].astype(float).values\n",
    "\n",
    "print(\"X_base shape:\", X_base.shape, \"y shape:\", y.shape)\n",
    "print(\"Пример жанровых частот:\")\n",
    "df[genre_cols].mean().sort_values(ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af557c36-b13d-4122-b61e-6e630d067837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: n=100000 в требуемом диапазоне [50k, 150k]. Users=943, Movies=1682\n",
      "Типы: numeric=True, categorical(one-hot)=True, temporal=True\n"
     ]
    }
   ],
   "source": [
    "n = len(df)\n",
    "n_users = df[\"user_id\"].nunique()\n",
    "n_movies = df[\"movie_id\"].nunique()\n",
    "\n",
    "assert 50_000 <= n <= 150_000, \"Размер данных не попадает в требуемый диапазон.\"\n",
    "print(f\"OK: n={n} в требуемом диапазоне [50k, 150k]. Users={n_users}, Movies={n_movies}\")\n",
    "\n",
    "# Смешанные типы подтверждаем:\n",
    "has_numeric = True\n",
    "has_categorical_like = len(genre_cols) > 0\n",
    "has_temporal = True  # есть year_rate и year_release\n",
    "print(f\"Типы: numeric={has_numeric}, categorical(one-hot)={has_categorical_like}, temporal={has_temporal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bb42397-0e8a-4b68-a982-cbf5fa7f6f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>dt</th>\n",
       "      <th>year_rate</th>\n",
       "      <th>year_release</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>year_release_c</th>\n",
       "      <th>year_rate_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>1997-12-04 15:55:49+00:00</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.04324</td>\n",
       "      <td>-0.47101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>1998-04-04 19:22:22+00:00</td>\n",
       "      <td>1998</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.04324</td>\n",
       "      <td>0.52899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>1997-11-07 07:18:36+00:00</td>\n",
       "      <td>1997</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.04324</td>\n",
       "      <td>-0.47101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>1997-11-27 05:02:03+00:00</td>\n",
       "      <td>1997</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.04324</td>\n",
       "      <td>-0.47101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>1998-02-02 05:33:16+00:00</td>\n",
       "      <td>1998</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.04324</td>\n",
       "      <td>0.52899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp                        dt  year_rate  \\\n",
       "0      196       242       3  881250949 1997-12-04 15:55:49+00:00       1997   \n",
       "1      186       302       3  891717742 1998-04-04 19:22:22+00:00       1998   \n",
       "2       22       377       1  878887116 1997-11-07 07:18:36+00:00       1997   \n",
       "3      244        51       2  880606923 1997-11-27 05:02:03+00:00       1997   \n",
       "4      166       346       1  886397596 1998-02-02 05:33:16+00:00       1998   \n",
       "\n",
       "   year_release  unknown  Action  Adventure  ...  Horror  Musical  Mystery  \\\n",
       "0        1997.0        0       0          0  ...       0        0        0   \n",
       "1        1997.0        0       0          0  ...       0        0        1   \n",
       "2        1994.0        0       0          0  ...       0        0        0   \n",
       "3        1994.0        0       0          0  ...       0        0        0   \n",
       "4        1997.0        0       0          0  ...       0        0        0   \n",
       "\n",
       "   Romance  Sci-Fi  Thriller  War  Western  year_release_c  year_rate_c  \n",
       "0        0       0         0    0        0         9.04324     -0.47101  \n",
       "1        0       0         1    0        0         9.04324      0.52899  \n",
       "2        0       0         0    0        0         6.04324     -0.47101  \n",
       "3        1       0         0    1        1         6.04324     -0.47101  \n",
       "4        0       0         0    0        0         9.04324      0.52899  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae0bf15-7a07-4477-b42e-9853c7773799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc170c87-f732-486f-a169-c66fa19f8f42",
   "metadata": {},
   "source": [
    "## OLS МОДЕЛИ И ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07e8e4",
   "metadata": {
    "id": "ec07e8e4"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OLS МОДЕЛИ И ANOVA\n",
    "# =============================================================================\n",
    "\n",
    "def fit_ols_model(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    add_constant: bool = True\n",
    ") -> sm.regression.linear_model.RegressionResultsWrapper:\n",
    "    \"\"\"\n",
    "    Построить OLS модель\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Матрица признаков\n",
    "    y : np.ndarray\n",
    "        Целевая переменная\n",
    "    add_constant : bool\n",
    "        Добавить константу\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    statsmodels RegressionResults\n",
    "        Результаты регрессии\n",
    "    \"\"\"\n",
    "    # TODO: Добавить константу если нужно\n",
    "    # TODO: Обучить OLS модель через statsmodels\n",
    "    # TODO: Вывести summary\n",
    "    pass\n",
    "\n",
    "\n",
    "def compare_nested_models(\n",
    "    model_restricted: sm.regression.linear_model.RegressionResultsWrapper,\n",
    "    model_full: sm.regression.linear_model.RegressionResultsWrapper,\n",
    "    alpha: float = 0.05\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Сравнить вложенные модели через F-тест\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_restricted : RegressionResults\n",
    "        Ограниченная модель\n",
    "    model_full : RegressionResults\n",
    "        Полная модель\n",
    "    alpha : float\n",
    "        Уровень значимости\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        Статистики теста (F-stat, p-value, conclusion)\n",
    "    \"\"\"\n",
    "    # TODO: Вычислить F-статистику\n",
    "    # TODO: Сравнить RSS моделей\n",
    "    # TODO: Вернуть результат теста\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_linear_contrasts(\n",
    "    model: sm.regression.linear_model.RegressionResultsWrapper,\n",
    "    contrast_matrix: np.ndarray,\n",
    "    contrast_names: Optional[List[str]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Проверить линейные контрасты\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : RegressionResults\n",
    "        Обученная модель\n",
    "    contrast_matrix : np.ndarray\n",
    "        Матрица контрастов (каждая строка - один контраст)\n",
    "    contrast_names : Optional[List[str]]\n",
    "        Названия контрастов\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Результаты тестов контрастов\n",
    "    \"\"\"\n",
    "    # TODO: Для каждого контраста c^T β = 0\n",
    "    # TODO: Вычислить статистику, p-value\n",
    "    # TODO: Вернуть DataFrame с результатами\n",
    "    pass\n",
    "\n",
    "\n",
    "def compute_anova_table(\n",
    "    model: sm.regression.linear_model.RegressionResultsWrapper,\n",
    "    typ: int = 2\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Вычислить таблицу ANOVA\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : RegressionResults\n",
    "        Обученная модель\n",
    "    typ : int\n",
    "        Тип ANOVA (1, 2, или 3)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Таблица ANOVA\n",
    "    \"\"\"\n",
    "    # TODO: Использовать statsmodels для построения ANOVA\n",
    "    # TODO: Вернуть таблицу с SS, df, F, p-value\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac054a4d",
   "metadata": {
    "id": "ac054a4d"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# МУЛЬТИКОЛЛИНЕАРНОСТЬ И VIF\n",
    "# =============================================================================\n",
    "\n",
    "def compute_vif(X: pd.DataFrame, add_constant: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Вычислить VIF для всех признаков\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Матрица признаков\n",
    "    add_constant : bool\n",
    "        Добавить константу перед вычислением\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        VIF для каждого признака\n",
    "    \"\"\"\n",
    "    # TODO: Для каждого признака вычислить VIF_j = 1/(1-R²_j)\n",
    "    # TODO: Вернуть DataFrame с признаками и их VIF\n",
    "    # TODO: Отметить признаки с VIF > 10\n",
    "    pass\n",
    "\n",
    "\n",
    "def diagnose_multicollinearity(\n",
    "    X: pd.DataFrame,\n",
    "    vif_threshold: float = 10.0,\n",
    "    corr_threshold: float = 0.8\n",
    ") -> Dict[str, Union[pd.DataFrame, List[Tuple[str, str]]]]:\n",
    "    \"\"\"\n",
    "    Диагностировать мультиколлинеарность\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Матрица признаков\n",
    "    vif_threshold : float\n",
    "        Порог VIF\n",
    "    corr_threshold : float\n",
    "        Порог корреляции\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict\n",
    "        VIF таблица и пары сильно коррелирующих признаков\n",
    "    \"\"\"\n",
    "    # TODO: Вычислить VIF\n",
    "    # TODO: Найти пары признаков с высокой корреляцией\n",
    "    # TODO: Рекомендовать какие признаки удалить\n",
    "    pass\n",
    "\n",
    "\n",
    "def iteratively_remove_high_vif(\n",
    "    X: pd.DataFrame,\n",
    "    vif_threshold: float = 10.0,\n",
    "    max_iterations: int = 10\n",
    ") -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Итеративно удалять признаки с высоким VIF\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Матрица признаков\n",
    "    vif_threshold : float\n",
    "        Порог VIF\n",
    "    max_iterations : int\n",
    "        Максимум итераций\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_reduced : pd.DataFrame\n",
    "        Редуцированная матрица признаков\n",
    "    removed_features : List[str]\n",
    "        Список удалённых признаков\n",
    "    \"\"\"\n",
    "    # TODO: Итеративно вычислять VIF\n",
    "    # TODO: На каждой итерации удалять признак с максимальным VIF > threshold\n",
    "    # TODO: Остановиться когда все VIF < threshold\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98281f0d",
   "metadata": {
    "id": "98281f0d"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# РЕГУЛЯРИЗАЦИЯ (RIDGE/LASSO)\n",
    "# =============================================================================\n",
    "\n",
    "def fit_ridge_cv(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    alphas: Optional[np.ndarray] = None,\n",
    "    cv: int = 5,\n",
    "    scoring: str = 'neg_mean_squared_error'\n",
    ") -> Tuple[Ridge, np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Подобрать Ridge регрессию с кросс-валидацией\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Матрица признаков\n",
    "    y : np.ndarray\n",
    "        Целевая переменная\n",
    "    alphas : Optional[np.ndarray]\n",
    "        Сетка гиперпараметров λ\n",
    "    cv : int\n",
    "        Число фолдов\n",
    "    scoring : str\n",
    "        Метрика для оптимизации\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : Ridge\n",
    "        Обученная модель с лучшим α\n",
    "    alphas : np.ndarray\n",
    "        Использованные значения α\n",
    "    best_alpha : float\n",
    "        Оптимальное значение α\n",
    "    \"\"\"\n",
    "    # TODO: Стандартизировать признаки\n",
    "    # TODO: Использовать RidgeCV для подбора α\n",
    "    # TODO: Построить график CV score vs alpha\n",
    "    # TODO: Вернуть лучшую модель\n",
    "    pass\n",
    "\n",
    "\n",
    "def fit_lasso_cv(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    alphas: Optional[np.ndarray] = None,\n",
    "    cv: int = 5,\n",
    "    scoring: str = 'neg_mean_squared_error',\n",
    "    max_iter: int = 10000\n",
    ") -> Tuple[Lasso, np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Подобрать Lasso регрессию с кросс-валидацией\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Матрица признаков\n",
    "    y : np.ndarray\n",
    "        Целевая переменная\n",
    "    alphas : Optional[np.ndarray]\n",
    "        Сетка гиперпараметров λ\n",
    "    cv : int\n",
    "        Число фолдов\n",
    "    scoring : str\n",
    "        Метрика для оптимизации\n",
    "    max_iter : int\n",
    "        Максимум итераций\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : Lasso\n",
    "        Обученная модель с лучшим α\n",
    "    alphas : np.ndarray\n",
    "        Использованные значения α\n",
    "    best_alpha : float\n",
    "        Оптимальное значение α\n",
    "    \"\"\"\n",
    "    # TODO: Стандартизировать признаки\n",
    "    # TODO: Использовать LassoCV для подбора α\n",
    "    # TODO: Построить график CV score vs alpha\n",
    "    # TODO: Построить график путей коэффициентов (Lasso path)\n",
    "    # TODO: Вернуть лучшую модель\n",
    "    pass\n",
    "\n",
    "\n",
    "def compare_regularization_methods(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: np.ndarray\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Сравнить OLS, Ridge и Lasso\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train, y_train : обучающая выборка\n",
    "    X_test, y_test : тестовая выборка\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Таблица сравнения метрик (RMSE, MAE, R²)\n",
    "    \"\"\"\n",
    "    # TODO: Обучить OLS, Ridge, Lasso\n",
    "    # TODO: Вычислить метрики на train и test\n",
    "    # TODO: Сравнить количество ненулевых коэффициентов\n",
    "    # TODO: Вернуть сводную таблицу\n",
    "    pass\n",
    "\n",
    "\n",
    "def plot_coefficient_comparison(\n",
    "    models: Dict[str, Union[LinearRegression, Ridge, Lasso]],\n",
    "    feature_names: List[str],\n",
    "    top_n: int = 20\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Визуализировать сравнение коэффициентов моделей\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models : Dict[str, model]\n",
    "        Словарь обученных моделей\n",
    "    feature_names : List[str]\n",
    "        Названия признаков\n",
    "    top_n : int\n",
    "        Показать top N признаков по абсолютной величине\n",
    "    \"\"\"\n",
    "    # TODO: Извлечь коэффициенты из каждой модели\n",
    "    # TODO: Построить grouped bar plot\n",
    "    # TODO: Отсортировать по важности\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84683cd",
   "metadata": {
    "id": "f84683cd"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# МНОЖЕСТВЕННЫЕ СРАВНЕНИЯ И FDR-КОНТРОЛЬ\n",
    "# =============================================================================\n",
    "\n",
    "def apply_fdr_correction(\n",
    "    pvalues: np.ndarray,\n",
    "    alpha: float = 0.05,\n",
    "    method: str = 'fdr_bh'\n",
    ") -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Применить коррекцию FDR (Benjamini-Hochberg)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pvalues : np.ndarray\n",
    "        Массив p-значений\n",
    "    alpha : float\n",
    "        Уровень FDR\n",
    "    method : str\n",
    "        Метод коррекции ('fdr_bh', 'fdr_by', 'bonferroni')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rejected : np.ndarray\n",
    "        Булевы маски отклонённых гипотез\n",
    "    pvals_corrected : np.ndarray\n",
    "        Скорректированные p-значения\n",
    "    alphac : float\n",
    "        Скорректированный уровень значимости\n",
    "    \"\"\"\n",
    "    # TODO: Использовать statsmodels.stats.multitest.multipletests\n",
    "    # TODO: Вернуть результаты коррекции\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_coefficient_family(\n",
    "    model: sm.regression.linear_model.RegressionResultsWrapper,\n",
    "    family_indices: List[int],\n",
    "    family_name: str,\n",
    "    fdr_alpha: float = 0.05\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Проверить семейство коэффициентов с FDR-контролем\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : RegressionResults\n",
    "        Обученная модель\n",
    "    family_indices : List[int]\n",
    "        Индексы коэффициентов в семействе\n",
    "    family_name : str\n",
    "        Название семейства\n",
    "    fdr_alpha : float\n",
    "        Уровень FDR\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Результаты тестов с коррекцией\n",
    "    \"\"\"\n",
    "    # TODO: Извлечь p-значения для семейства\n",
    "    # TODO: Применить FDR-коррекцию\n",
    "    # TODO: Вернуть таблицу с результатами\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_multiple_contrasts(\n",
    "    model: sm.regression.linear_model.RegressionResultsWrapper,\n",
    "    contrast_dict: Dict[str, np.ndarray],\n",
    "    fdr_alpha: float = 0.05\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Проверить множество контрастов с FDR-контролем\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : RegressionResults\n",
    "        Обученная модель\n",
    "    contrast_dict : Dict[str, np.ndarray]\n",
    "        Словарь {название: вектор контраста}\n",
    "    fdr_alpha : float\n",
    "        Уровень FDR\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Результаты всех контрастов с коррекцией\n",
    "    \"\"\"\n",
    "    # TODO: Для каждого контраста вычислить статистику и p-value\n",
    "    # TODO: Применить FDR-коррекцию к семейству p-values\n",
    "    # TODO: Вернуть сводную таблицу\n",
    "    pass\n",
    "\n",
    "\n",
    "def visualize_multiple_testing_results(\n",
    "    pvalues_raw: np.ndarray,\n",
    "    pvalues_corrected: np.ndarray,\n",
    "    rejected: np.ndarray,\n",
    "    test_names: List[str],\n",
    "    alpha: float = 0.05\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Визуализировать результаты множественных сравнений\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pvalues_raw : np.ndarray\n",
    "        Исходные p-значения\n",
    "    pvalues_corrected : np.ndarray\n",
    "        Скорректированные p-значения\n",
    "    rejected : np.ndarray\n",
    "        Маска отклонённых гипотез\n",
    "    test_names : List[str]\n",
    "        Названия тестов\n",
    "    alpha : float\n",
    "        Уровень значимости\n",
    "    \"\"\"\n",
    "    # TODO: Построить volcano plot или bar plot\n",
    "    # TODO: Показать линию отсечения α\n",
    "    # TODO: Выделить значимые тесты\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e55719",
   "metadata": {
    "id": "16e55719"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# БАЙЕСОВСКАЯ РЕГРЕССИЯ (PyMC)\n",
    "# =============================================================================\n",
    "\n",
    "def build_bayesian_linear_model(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    prior_scale: float = 10.0,\n",
    "    prior_sigma: str = 'halfcauchy'\n",
    ") -> pm.Model:\n",
    "    \"\"\"\n",
    "    Построить байесовскую линейную модель\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Матрица признаков (стандартизированная)\n",
    "    y : np.ndarray\n",
    "        Целевая переменная\n",
    "    prior_scale : float\n",
    "        Масштаб априорного распределения для β\n",
    "    prior_sigma : str\n",
    "        Тип априора для σ ('halfcauchy', 'halfnormal', 'exponential')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pm.Model\n",
    "        PyMC модель\n",
    "    \"\"\"\n",
    "    # TODO: Создать PyMC модель\n",
    "    # TODO: Задать априоры: β ~ N(0, prior_scale²)\n",
    "    # TODO: Задать априор для σ (HalfCauchy, HalfNormal)\n",
    "    # TODO: Задать likelihood: y ~ N(Xβ, σ²)\n",
    "    pass\n",
    "\n",
    "\n",
    "def sample_bayesian_model(\n",
    "    model: pm.Model,\n",
    "    draws: int = 2000,\n",
    "    tune: int = 1000,\n",
    "    chains: int = 4,\n",
    "    target_accept: float = 0.95\n",
    ") -> az.InferenceData:\n",
    "    \"\"\"\n",
    "    Сэмплировать из апостериорного распределения\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : pm.Model\n",
    "        PyMC модель\n",
    "    draws : int\n",
    "        Число сэмплов после warmup\n",
    "    tune : int\n",
    "        Число warmup итераций\n",
    "    chains : int\n",
    "        Число цепей\n",
    "    target_accept : float\n",
    "        Целевая вероятность принятия (для NUTS)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    az.InferenceData\n",
    "        Результаты сэмплирования\n",
    "    \"\"\"\n",
    "    # TODO: Использовать pm.sample с NUTS\n",
    "    # TODO: Вернуть InferenceData объект\n",
    "    pass\n",
    "\n",
    "\n",
    "def check_convergence_diagnostics(trace: az.InferenceData) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Проверить диагностики сходимости\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trace : az.InferenceData\n",
    "        Результаты сэмплирования\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Таблица с R-hat, ESS для каждого параметра\n",
    "    \"\"\"\n",
    "    # TODO: Вычислить R-hat (должен быть < 1.01)\n",
    "    # TODO: Вычислить ESS (effective sample size)\n",
    "    # TODO: Построить trace plots\n",
    "    # TODO: Построить autocorrelation plots\n",
    "    pass\n",
    "\n",
    "\n",
    "def posterior_predictive_check(\n",
    "    model: pm.Model,\n",
    "    trace: az.InferenceData,\n",
    "    y_observed: np.ndarray,\n",
    "    n_samples: int = 1000\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Выполнить постериорно-предсказательную проверку (PPC)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : pm.Model\n",
    "        PyMC модель\n",
    "    trace : az.InferenceData\n",
    "        Апостериорное распределение\n",
    "    y_observed : np.ndarray\n",
    "        Наблюдаемые данные\n",
    "    n_samples : int\n",
    "        Число предсказательных сэмплов\n",
    "    \"\"\"\n",
    "    # TODO: Сгенерировать предсказания из апостериора\n",
    "    # TODO: Сравнить распределение предсказаний с наблюдениями\n",
    "    # TODO: Построить PPC plots (гистограммы, density plots)\n",
    "    # TODO: Проверить статистики (среднее, дисперсия, квантили)\n",
    "    pass\n",
    "\n",
    "\n",
    "def extract_posterior_intervals(\n",
    "    trace: az.InferenceData,\n",
    "    var_names: List[str],\n",
    "    hdi_prob: float = 0.95\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Извлечь апостериорные интервалы для параметров\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trace : az.InferenceData\n",
    "        Апостериорное распределение\n",
    "    var_names : List[str]\n",
    "        Названия переменных\n",
    "    hdi_prob : float\n",
    "        Вероятность для HDI (highest density interval)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Таблица с mean, sd, HDI для каждого параметра\n",
    "    \"\"\"\n",
    "    # TODO: Использовать arviz.summary\n",
    "    # TODO: Извлечь HDI интервалы\n",
    "    # TODO: Построить forest plots\n",
    "    pass\n",
    "\n",
    "\n",
    "def compare_bayesian_models(\n",
    "    models: Dict[str, pm.Model],\n",
    "    traces: Dict[str, az.InferenceData]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Сравнить байесовские модели через LOO/WAIC\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models : Dict[str, pm.Model]\n",
    "        Словарь моделей\n",
    "    traces : Dict[str, az.InferenceData]\n",
    "        Словарь апостериорных распределений\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Таблица сравнения (LOO, WAIC, weights)\n",
    "    \"\"\"\n",
    "    # TODO: Вычислить LOO (leave-one-out cross-validation)\n",
    "    # TODO: Вычислить WAIC\n",
    "    # TODO: Использовать arviz.compare\n",
    "    # TODO: Вернуть таблицу сравнения моделей\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d3207",
   "metadata": {
    "id": "4f6d3207"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. БУТСТРЕП\n",
    "# =============================================================================\n",
    "\n",
    "def bootstrap_metric(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    metric_func: callable,\n",
    "    n_bootstrap: int = 1000,\n",
    "    confidence_level: float = 0.95,\n",
    "    random_state: int = RANDOM_STATE\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Вычислить бутстреп доверительный интервал для метрики\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Матрица признаков\n",
    "    y : np.ndarray\n",
    "        Целевая переменная\n",
    "    metric_func : callable\n",
    "        Функция метрики (принимает X, y; возвращает число)\n",
    "    n_bootstrap : int\n",
    "        Число бутстреп-итераций\n",
    "    confidence_level : float\n",
    "        Уровень доверия\n",
    "    random_state : int\n",
    "        Зерно для воспроизводимости\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        mean, std, CI_lower, CI_upper\n",
    "    \"\"\"\n",
    "    # TODO: Для каждой итерации:\n",
    "    #   - Сформировать бутстреп-выборку (с возвращением)\n",
    "    #   - Вычислить метрику\n",
    "    # TODO: Вычислить процентильный CI\n",
    "    # TODO: Построить гистограмму распределения\n",
    "    pass\n",
    "\n",
    "\n",
    "def bootstrap_coefficients(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    n_bootstrap: int = 1000,\n",
    "    confidence_level: float = 0.95,\n",
    "    model_type: str = 'ols'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Бутстреп доверительные интервалы для коэффициентов регрессии\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Матрица признаков\n",
    "    y : np.ndarray\n",
    "        Целевая переменная\n",
    "    n_bootstrap : int\n",
    "        Число бутстреп-итераций\n",
    "    confidence_level : float\n",
    "        Уровень доверия\n",
    "    model_type : str\n",
    "        Тип модели ('ols', 'ridge', 'lasso')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Таблица с оценками и CI для каждого коэффициента\n",
    "    \"\"\"\n",
    "    # TODO: Для каждой итерации обучить модель на бутстреп-выборке\n",
    "    # TODO: Сохранить коэффициенты\n",
    "    # TODO: Вычислить процентильные CI для каждого коэффициента\n",
    "    # TODO: Построить violin plots для важных коэффициентов\n",
    "    pass\n",
    "\n",
    "\n",
    "def bootstrap_model_comparison(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    model1_func: callable,\n",
    "    model2_func: callable,\n",
    "    metric_func: callable,\n",
    "    n_bootstrap: int = 1000,\n",
    "    confidence_level: float = 0.95\n",
    ") -> Dict[str, Union[float, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Бутстреп сравнение двух моделей\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X, y : данные\n",
    "    model1_func, model2_func : callable\n",
    "        Функции обучения моделей\n",
    "    metric_func : callable\n",
    "        Функция метрики\n",
    "    n_bootstrap : int\n",
    "        Число итераций\n",
    "    confidence_level : float\n",
    "        Уровень доверия\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict\n",
    "        Статистики разницы метрик и CI\n",
    "    \"\"\"\n",
    "    # TODO: Для каждой итерации:\n",
    "    #   - Сформировать бутстреп-выборку\n",
    "    #   - Обучить обе модели\n",
    "    #   - Вычислить разницу метрик\n",
    "    # TODO: Вычислить CI для разницы\n",
    "    # TODO: Тест: включает ли CI ноль?\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e8314",
   "metadata": {
    "id": "f91e8314"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ПЕРЕСТАНОВОЧНЫЕ ТЕСТЫ\n",
    "# =============================================================================\n",
    "\n",
    "def permutation_test(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    test_statistic_func: callable,\n",
    "    n_permutations: int = 1000,\n",
    "    alternative: str = 'two-sided',\n",
    "    random_state: int = RANDOM_STATE\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Перестановочный тест для статистики\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Матрица признаков\n",
    "    y : np.ndarray\n",
    "        Целевая переменная\n",
    "    test_statistic_func : callable\n",
    "        Функция вычисления статистики (принимает X, y)\n",
    "    n_permutations : int\n",
    "        Число перестановок\n",
    "    alternative : str\n",
    "        'two-sided', 'greater', 'less'\n",
    "    random_state : int\n",
    "        Зерно\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        observed_statistic, p_value, permuted_statistics\n",
    "    \"\"\"\n",
    "    # TODO: Вычислить наблюдаемую статистику\n",
    "    # TODO: Для каждой перестановки:\n",
    "    #   - Перемешать y (или X, в зависимости от теста)\n",
    "    #   - Вычислить статистику на перемешанных данных\n",
    "    # TODO: Вычислить p-value: (1 + #{|T_perm| >= |T_obs|}) / (1 + n_perm)\n",
    "    # TODO: Построить гистограмму нулевого распределения\n",
    "    pass\n",
    "\n",
    "\n",
    "def permutation_test_model_difference(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    model1_func: callable,\n",
    "    model2_func: callable,\n",
    "    metric_func: callable,\n",
    "    n_permutations: int = 1000,\n",
    "    cv_folds: int = 5\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Перестановочный тест для разницы метрик двух моделей\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X, y : данные\n",
    "    model1_func, model2_func : callable\n",
    "        Функции обучения моделей\n",
    "    metric_func : callable\n",
    "        Функция метрики\n",
    "    n_permutations : int\n",
    "        Число перестановок\n",
    "    cv_folds : int\n",
    "        Число фолдов для CV\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        observed_diff, p_value\n",
    "    \"\"\"\n",
    "    # TODO: Вычислить разницу метрик на исходных данных (с CV)\n",
    "    # TODO: Для каждой перестановки:\n",
    "    #   - Перемешать y\n",
    "    #   - Вычислить разницу метрик с CV\n",
    "    # TODO: Вычислить p-value\n",
    "    pass\n",
    "\n",
    "\n",
    "def permutation_feature_importance(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    model_func: callable,\n",
    "    metric_func: callable,\n",
    "    n_permutations: int = 100\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Вычислить важность признаков через перестановки\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Матрица признаков\n",
    "    y : np.ndarray\n",
    "        Целевая переменная\n",
    "    model_func : callable\n",
    "        Функция обучения модели\n",
    "    metric_func : callable\n",
    "        Функция метрики (чем выше, тем лучше)\n",
    "    n_permutations : int\n",
    "        Число перестановок для каждого признака\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Важность каждого признака (снижение метрики)\n",
    "    \"\"\"\n",
    "    # TODO: Обучить базовую модель, вычислить базовую метрику\n",
    "    # TODO: Для каждого признака:\n",
    "    #   - Перемешать значения признака\n",
    "    #   - Вычислить метрику с перемешанным признаком\n",
    "    #   - Важность = (base_metric - permuted_metric)\n",
    "    # TODO: Усреднить по перестановкам\n",
    "    # TODO: Построить bar plot важности\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d1635",
   "metadata": {
    "id": "111d1635"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# КРОСС-ВАЛИДАЦИЯ И ОЦЕНКА МОДЕЛЕЙ\n",
    "# =============================================================================\n",
    "\n",
    "def cross_validate_models(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    models: Dict[str, callable],\n",
    "    cv: int = 5,\n",
    "    scoring: List[str] = ['neg_mean_squared_error', 'r2']\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Кросс-валидация нескольких моделей\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Матрица признаков\n",
    "    y : np.ndarray\n",
    "        Целевая переменная\n",
    "    models : Dict[str, callable]\n",
    "        Словарь {название: модель}\n",
    "    cv : int\n",
    "        Число фолдов\n",
    "    scoring : List[str]\n",
    "        Список метрик\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Результаты CV для каждой модели и метрики\n",
    "    \"\"\"\n",
    "    # TODO: Для каждой модели выполнить cross_val_score\n",
    "    # TODO: Вычислить среднее и std по фолдам\n",
    "    # TODO: Вернуть сводную таблицу\n",
    "    pass\n",
    "\n",
    "\n",
    "def evaluate_model_on_test(\n",
    "    model,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: np.ndarray\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Оценить модель на тестовой выборке\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : обучаемая модель\n",
    "    X_train, y_train : обучающая выборка\n",
    "    X_test, y_test : тестовая выборка\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        Метрики (RMSE, MAE, R², MAPE)\n",
    "    \"\"\"\n",
    "    # TODO: Обучить модель на train\n",
    "    # TODO: Сделать предсказания на test\n",
    "    # TODO: Вычислить метрики\n",
    "    # TODO: Построить actual vs predicted plot\n",
    "    # TODO: Построить residual plot\n",
    "    pass\n",
    "\n",
    "\n",
    "def plot_learning_curves(\n",
    "    model,\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    train_sizes: np.ndarray = np.linspace(0.1, 1.0, 10),\n",
    "    cv: int = 5\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Построить кривые обучения\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : обучаемая модель\n",
    "    X, y : данные\n",
    "    train_sizes : np.ndarray\n",
    "        Доли обучающей выборки\n",
    "    cv : int\n",
    "        Число фолдов\n",
    "    \"\"\"\n",
    "    # TODO: Использовать sklearn.model_selection.learning_curve\n",
    "    # TODO: Построить графики train/validation scores vs sample size\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a51ade",
   "metadata": {
    "id": "45a51ade"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ВИЗУАЛИЗАЦИЯ И ОТЧЁТНОСТЬ\n",
    "# =============================================================================\n",
    "\n",
    "def plot_residual_diagnostics\n",
    "    \"\"\"\n",
    "    Построить диагностические графики остатков\n",
    "\n",
    "\n",
    "\n",
    "def create_coefficient_table\n",
    "\n",
    "    \"\"\"\n",
    "    Создать сводную таблицу коэффициентов\n",
    "\n",
    "\n",
    "\n",
    "def plot_model_comparison_summary\n",
    "\n",
    "    \"\"\"\n",
    "    Визуализировать сравнение моделей по метрикам\n",
    "\n",
    "\n",
    "\n",
    "def generate_summary_report\n",
    "\n",
    "    Сгенерировать текстовый отчёт с результатами\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc0e68",
   "metadata": {
    "id": "cebc0e68"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ОСНОВНОЙ ПАЙПЛАЙН\n",
    "# =============================================================================\n",
    "\n",
    "def run_full_analysis_pipeline\n",
    "(\n",
    "  . . .\n",
    "\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Выполнить полный анализ по лабораторной работе\n",
    "\n",
    "    Этапы:\n",
    "    1. Загрузка и предобработка данных\n",
    "    2. OLS модель и диагностика\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_name : str\n",
    "        Название датасета\n",
    "    target_col : str\n",
    "        Целевая переменная\n",
    "   .\n",
    "   .\n",
    "   .\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict\n",
    "        Словарь со всеми результатами анализа\n",
    "    \"\"\"\n",
    "    # TODO: Реализовать полный пайплайн согласно требованиям ЛР\n",
    "    # TODO: Сохранить все графики в output_dir\n",
    "    # TODO: Сохранить таблицы результатов\n",
    "    # TODO: Сгенерировать итоговый отчёт\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb5c77b",
   "metadata": {
    "id": "9cb5c77b"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ\n",
    "# =============================================================================\n",
    "\n",
    "def set_plot_style() -> None:\n",
    "    \"\"\"Установить стиль графиков\"\"\"\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    sns.set_palette(\"husl\")\n",
    "    plt.rcParams['figure.figsize'] = (12, 6)\n",
    "    plt.rcParams['font.size'] = 10\n",
    "\n",
    "\n",
    "def save_figure(fig, filename: str, output_dir: str = 'results') -> None:\n",
    "    \"\"\"Сохранить фигуру\"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fig.savefig(os.path.join(output_dir, filename), dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def print_section_header(title: str) -> None:\n",
    "    \"\"\"Вывести заголовок раздела\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"  {title}\")\n",
    "    print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1217de0",
   "metadata": {
    "id": "a1217de0"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Утилиты для загрузки и предобработки конкретных датасетов\n",
    "Лабораторная работа 2\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# NYC TAXI DATA (D1)\n",
    "# =============================================================================\n",
    "\n",
    "class NYCTaxiLoader:\n",
    "    \"\"\"Загрузчик и обработчик данных NYC Taxi\"\"\"\n",
    "\n",
    "    # Словарь зон TLC -> Borough\n",
    "    # TODO: Заполнить полный маппинг из taxi_zone_lookup.csv\n",
    "    ZONE_TO_BOROUGH = {\n",
    "        # Примеры (не полный список!)\n",
    "        4: 'Manhattan',\n",
    "        12: 'Manhattan',\n",
    "        13: 'Manhattan',\n",
    "        24: 'Manhattan',\n",
    "        41: 'Manhattan',\n",
    "        42: 'Manhattan',\n",
    "        43: 'Manhattan',\n",
    "        48: 'Manhattan',\n",
    "        50: 'Manhattan',\n",
    "        68: 'Manhattan',\n",
    "        74: 'Manhattan',\n",
    "        75: 'Manhattan',\n",
    "        79: 'Brooklyn',\n",
    "        80: 'Brooklyn',\n",
    "        # ... дополнить остальные зоны\n",
    "    }\n",
    "\n",
    "    @staticmethod\n",
    "    def load_nyc_taxi_parquet(\n",
    "        filepath: str,\n",
    "        sample_size: Optional[int] = None,\n",
    "        year: int = 2019,\n",
    "        month: int = 1\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Загрузить NYC Taxi данные из Parquet\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath : str\n",
    "            Путь к .parquet файлу\n",
    "        sample_size : Optional[int]\n",
    "            Размер случайной выборки\n",
    "        year : int\n",
    "            Год данных (для фильтрации)\n",
    "        month : int\n",
    "            Месяц данных (для фильтрации)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        # TODO: Загрузить parquet\n",
    "        # df = pd.read_parquet(filepath)\n",
    "\n",
    "        # TODO: Фильтровать по дате если нужно\n",
    "        # df = df[(df['pickup_datetime'].dt.year == year) &\n",
    "        #         (df['pickup_datetime'].dt.month == month)]\n",
    "\n",
    "        # TODO: Случайная выборка\n",
    "        # if sample_size and len(df) > sample_size:\n",
    "        #     df = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_nyc_taxi(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Очистить данные от аномалий\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Сырые данные\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Очищенные данные\n",
    "        \"\"\"\n",
    "        df_clean = df.copy()\n",
    "\n",
    "        # TODO: Удалить аномальные значения\n",
    "        # - Негативные или нулевые fare_amount\n",
    "        # df_clean = df_clean[df_clean['fare_amount'] > 0]\n",
    "\n",
    "        # - Негативные или слишком большие trip_distance\n",
    "        # df_clean = df_clean[(df_clean['trip_distance'] > 0) &\n",
    "        #                     (df_clean['trip_distance'] < 100)]\n",
    "\n",
    "        # - Негативные чаевые\n",
    "        # df_clean = df_clean[df_clean['tip_amount'] >= 0]\n",
    "\n",
    "        # - Аномально большие суммы\n",
    "        # df_clean = df_clean[df_clean['total_amount'] < 500]\n",
    "\n",
    "        # - Пассажиры: 1-6\n",
    "        # df_clean = df_clean[(df_clean['passenger_count'] >= 1) &\n",
    "        #                     (df_clean['passenger_count'] <= 6)]\n",
    "\n",
    "        # TODO: Удалить поездки с аномальной длительностью\n",
    "        # df_clean['duration_min'] = (df_clean['tpep_dropoff_datetime'] -\n",
    "        #                             df_clean['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "        # df_clean = df_clean[(df_clean['duration_min'] > 1) &\n",
    "        #                     (df_clean['duration_min'] < 180)]\n",
    "\n",
    "        return df_clean\n",
    "\n",
    "    @staticmethod\n",
    "    def add_temporal_features(df: pd.DataFrame, datetime_col: str = 'tpep_pickup_datetime') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Добавить временные признаки\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Данные\n",
    "        datetime_col : str\n",
    "            Название колонки с datetime\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        # TODO: Извлечь компоненты времени\n",
    "        # df['hour'] = df[datetime_col].dt.hour\n",
    "        # df['day_of_week'] = df[datetime_col].dt.dayofweek\n",
    "        # df['day_of_month'] = df[datetime_col].dt.day\n",
    "        # df['month'] = df[datetime_col].dt.month\n",
    "        # df['year'] = df[datetime_col].dt.year\n",
    "\n",
    "        # TODO: Категориальные признаки времени\n",
    "        # df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "        # df['is_rush_hour'] = ((df['hour'].between(7, 9)) |\n",
    "        #                       (df['hour'].between(17, 19))).astype(int)\n",
    "        # df['time_of_day'] = pd.cut(df['hour'],\n",
    "        #                             bins=[0, 6, 12, 18, 24],\n",
    "        #                             labels=['Night', 'Morning', 'Afternoon', 'Evening'])\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def add_borough_feature(df: pd.DataFrame, zone_col: str = 'PULocationID') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Добавить признак Borough из LocationID\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Данные\n",
    "        zone_col : str\n",
    "            Название колонки с LocationID\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        # TODO: Маппинг через ZONE_TO_BOROUGH\n",
    "        # df['borough'] = df[zone_col].map(NYCTaxiLoader.ZONE_TO_BOROUGH)\n",
    "        # df['borough'] = df['borough'].fillna('Unknown')\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_trip_duration(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Вычислить длительность поездки\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Данные с pickup и dropoff datetime\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        # TODO: Вычислить в минутах\n",
    "        # df['trip_duration'] = (df['tpep_dropoff_datetime'] -\n",
    "        #                        df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# OLIST E-COMMERCE DATA (D3)\n",
    "# =============================================================================\n",
    "\n",
    "class OlistLoader:\n",
    "    \"\"\"Загрузчик и обработчик данных Olist\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def load_olist_tables(data_dir: str) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Загрузить все таблицы Olist\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_dir : str\n",
    "            Директория с CSV файлами\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, pd.DataFrame]\n",
    "            Словарь таблиц\n",
    "        \"\"\"\n",
    "        tables = {}\n",
    "\n",
    "        # TODO: Загрузить каждую таблицу\n",
    "        # tables['orders'] = pd.read_csv(f'{data_dir}/olist_orders_dataset.csv')\n",
    "        # tables['order_items'] = pd.read_csv(f'{data_dir}/olist_order_items_dataset.csv')\n",
    "        # tables['order_payments'] = pd.read_csv(f'{data_dir}/olist_order_payments_dataset.csv')\n",
    "        # tables['products'] = pd.read_csv(f'{data_dir}/olist_products_dataset.csv')\n",
    "        # tables['sellers'] = pd.read_csv(f'{data_dir}/olist_sellers_dataset.csv')\n",
    "        # tables['customers'] = pd.read_csv(f'{data_dir}/olist_customers_dataset.csv')\n",
    "        # tables['geolocation'] = pd.read_csv(f'{data_dir}/olist_geolocation_dataset.csv')\n",
    "        # tables['product_category_name_translation'] = pd.read_csv(\n",
    "        #     f'{data_dir}/product_category_name_translation.csv'\n",
    "        # )\n",
    "\n",
    "        return tables\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_olist_data(tables: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Объединить таблицы Olist в единый датафрейм\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tables : Dict[str, pd.DataFrame]\n",
    "            Словарь загруженных таблиц\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Объединённые данные на уровне заказа\n",
    "        \"\"\"\n",
    "        # TODO: Начать с orders\n",
    "        # df = tables['orders'].copy()\n",
    "\n",
    "        # TODO: Join order_items\n",
    "        # df = df.merge(tables['order_items'], on='order_id', how='left')\n",
    "\n",
    "        # TODO: Join payments (агрегировать по order_id)\n",
    "        # payments_agg = tables['order_payments'].groupby('order_id').agg({\n",
    "        #     'payment_value': 'sum',\n",
    "        #     'payment_installments': 'mean'\n",
    "        # }).reset_index()\n",
    "        # df = df.merge(payments_agg, on='order_id', how='left')\n",
    "\n",
    "        # TODO: Join products\n",
    "        # df = df.merge(tables['products'], on='product_id', how='left')\n",
    "\n",
    "        # TODO: Join sellers\n",
    "        # df = df.merge(tables['sellers'], on='seller_id', how='left')\n",
    "\n",
    "        # TODO: Translate category names\n",
    "        # df = df.merge(tables['product_category_name_translation'],\n",
    "        #               on='product_category_name', how='left')\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_olist_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Вычислить производные признаки для Olist\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Объединённые данные\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        # TODO: GMV (Gross Merchandise Value)\n",
    "        # df['gmv'] = df.groupby('order_id')['price'].transform('sum')\n",
    "\n",
    "        # TODO: Delivery time\n",
    "        # df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "        # df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "        # df['delivery_time'] = (df['order_delivered_customer_date'] -\n",
    "        #                        df['order_purchase_timestamp']).dt.days\n",
    "\n",
    "        # TODO: Delivery delay\n",
    "        # df['order_estimated_delivery_date'] = pd.to_datetime(df['order_estimated_delivery_date'])\n",
    "        # df['delivery_delay'] = (df['order_delivered_customer_date'] -\n",
    "        #                         df['order_estimated_delivery_date']).dt.days\n",
    "\n",
    "        # TODO: Number of items per order\n",
    "        # df['num_items'] = df.groupby('order_id')['order_item_id'].transform('count')\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MOVIELENS DATA (D4)\n",
    "# =============================================================================\n",
    "\n",
    "class MovieLensLoader:\n",
    "    \"\"\"Загрузчик и обработчик данных MovieLens\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def load_movielens_100k(data_dir: str) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Загрузить MovieLens 100K данные\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_dir : str\n",
    "            Директория с файлами\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, pd.DataFrame]\n",
    "            Словарь таблиц\n",
    "        \"\"\"\n",
    "        tables = {}\n",
    "\n",
    "        # TODO: Загрузить ratings (u.data)\n",
    "        # columns_ratings = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "        # tables['ratings'] = pd.read_csv(\n",
    "        #     f'{data_dir}/u.data',\n",
    "        #     sep='\\t',\n",
    "        #     names=columns_ratings\n",
    "        # )\n",
    "\n",
    "        # TODO: Загрузить movies (u.item)\n",
    "        # columns_movies = ['item_id', 'title', 'release_date', 'video_release_date',\n",
    "        #                   'imdb_url'] + [f'genre_{i}' for i in range(19)]\n",
    "        # tables['movies'] = pd.read_csv(\n",
    "        #     f'{data_dir}/u.item',\n",
    "        #     sep='|',\n",
    "        #     names=columns_movies,\n",
    "        #     encoding='latin-1'\n",
    "        # )\n",
    "\n",
    "        # TODO: Загрузить users (u.user)\n",
    "        # columns_users = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "        # tables['users'] = pd.read_csv(\n",
    "        #     f'{data_dir}/u.user',\n",
    "        #     sep='|',\n",
    "        #     names=columns_users\n",
    "        # )\n",
    "\n",
    "        return tables\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_movielens_data(tables: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Объединить таблицы MovieLens\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tables : Dict[str, pd.DataFrame]\n",
    "            Словарь таблиц\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Объединённые данные\n",
    "        \"\"\"\n",
    "        # TODO: Начать с ratings\n",
    "        # df = tables['ratings'].copy()\n",
    "\n",
    "        # TODO: Join movies\n",
    "        # df = df.merge(tables['movies'], on='item_id', how='left')\n",
    "\n",
    "        # TODO: Join users\n",
    "        # df = df.merge(tables['users'], on='user_id', how='left')\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_movie_year(df: pd.DataFrame, title_col: str = 'title') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Извлечь год релиза из названия фильма\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Данные с колонкой title\n",
    "        title_col : str\n",
    "            Название колонки с заголовком\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        # TODO: Извлечь год из названия (обычно в конце в скобках)\n",
    "        # df['year'] = df[title_col].str.extract(r'\\((\\d{4})\\)')\n",
    "        # df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_genre_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Создать one-hot признаки жанров\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Данные с колонками genre_*\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        # TODO: Жанры уже в one-hot формате в u.item\n",
    "        # Можно переименовать для удобства\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_user_movie_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Вычислить агрегированные статистики пользователей и фильмов\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Данные с рейтингами\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        # TODO: Leave-one-out средний рейтинг фильма\n",
    "        # movie_ratings = df.groupby('item_id')['rating'].transform('sum')\n",
    "        # movie_counts = df.groupby('item_id')['rating'].transform('count')\n",
    "        # df['avg_movie_rating_loo'] = (movie_ratings - df['rating']) / (movie_counts - 1)\n",
    "\n",
    "        # TODO: Активность пользователя\n",
    "        # df['user_activity'] = df.groupby('user_id')['rating'].transform('count')\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# UK ROAD SAFETY DATA - STATS19 (D5)\n",
    "# =============================================================================\n",
    "\n",
    "class STATS19Loader:\n",
    "    \"\"\"Загрузчик и обработчик данных STATS19\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def load_stats19_csv(filepath: str, year: int = 2017) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Загрузить STATS19 данные\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath : str\n",
    "            Путь к CSV файлу\n",
    "        year : int\n",
    "            Год данных\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        # TODO: Загрузить accidents\n",
    "        # df = pd.read_csv(filepath)\n",
    "\n",
    "        # TODO: Фильтровать по году если нужно\n",
    "        # df['date'] = pd.to_datetime(df['date'])\n",
    "        # df = df[df['date'].dt.year == year]\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def create_severity_score(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Создать суррогат серьёзности ДТП\n",
    "\n",
    "        Формула: 10 * fatal + 3 * serious + 1 * slight\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Данные с casualty columns\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        # TODO: Вычислить взвешенную сумму пострадавших\n",
    "        # df['severity_score'] = (\n",
    "        #     10 * df['number_of_casualties_fatal'] +\n",
    "        #     3 * df['number_of_casualties_serious'] +\n",
    "        #     1 * df['number_of_casualties_slight']\n",
    "        # )\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_categorical_stats19(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Закодировать категориальные признаки\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Сырые данные\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        # TODO: Weather conditions\n",
    "        # weather_mapping = {\n",
    "        #     1: 'Fine',\n",
    "        #     2: 'Raining',\n",
    "        #     3: 'Snowing',\n",
    "        #     4: 'Fine + high winds',\n",
    "        #     5: 'Raining + high winds',\n",
    "        #     6: 'Snowing + high winds',\n",
    "        #     7: 'Fog or mist',\n",
    "        #     8: 'Other',\n",
    "        #     9: 'Unknown'\n",
    "        # }\n",
    "        # df['weather_conditions'] = df['weather_conditions'].map(weather_mapping)\n",
    "\n",
    "        # TODO: Light conditions\n",
    "        # TODO: Road type\n",
    "        # TODO: Junction detail\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CHICAGO TAXI DATA (D2)\n",
    "# =============================================================================\n",
    "\n",
    "class ChicagoTaxiLoader:\n",
    "    \"\"\"Загрузчик и обработчик данных Chicago Taxi\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def load_chicago_taxi_csv(filepath: str, sample_size: Optional[int] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Загрузить Chicago Taxi данные\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath : str\n",
    "            Путь к CSV файлу\n",
    "        sample_size : Optional[int]\n",
    "            Размер выборки\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        # TODO: Загрузить данные\n",
    "        # df = pd.read_csv(filepath)\n",
    "\n",
    "        # TODO: Парсинг дат\n",
    "        # df['trip_start_timestamp'] = pd.to_datetime(df['trip_start_timestamp'])\n",
    "        # df['trip_end_timestamp'] = pd.to_datetime(df['trip_end_timestamp'])\n",
    "\n",
    "        # TODO: Случайная выборка\n",
    "        # if sample_size and len(df) > sample_size:\n",
    "        #     df = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_chicago_taxi(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Очистить данные Chicago Taxi\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Сырые данные\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "        \"\"\"\n",
    "        df_clean = df.copy()\n",
    "\n",
    "        # TODO: Удалить аномалии\n",
    "        # - Негативные fare\n",
    "        # - Нулевые trip_miles/trip_seconds\n",
    "        # - Аномально большие значения\n",
    "\n",
    "        return df_clean"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
