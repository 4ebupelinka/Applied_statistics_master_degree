{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad4f4658",
      "metadata": {
        "id": "ad4f4658"
      },
      "source": [
        "\n",
        "# Лабораторная работа 2. Регрессия, мультиколлинеарность, множественные сравнения, байесовские выводы и ресемплинг\n",
        "\n",
        "**Курс:** Прикладная статистика и анализ данных\n",
        "\n",
        "**Раздел 2:** Статистическое моделирование, гипотезы и интерпретация    \n",
        "\n",
        "**Цель:** построить и сравнить несколько спецификаций множественной линейной регрессии, диагностировать мультиколлинеарность и применить регуляризацию; корректно проверять семейства гипотез (контрасты/коэффициенты) с контролем FDR; провести байесовскую регрессию с априорами и постериорной проверкой предсказаний; оценить доверие к выводам с помощью бутстрепа и перестановочных тестов.\n",
        "\n",
        "**Ожидаемые результаты:** уметь (1) задавать и интерпретировать линейные модели с взаимодействиями; (2) диагностировать и снижать мультиколлинеарность (VIF, Ridge/Lasso с подбором $\\lambda$ по CV); (3) применять FDR-контроль к семействам проверок; (4) формулировать априоры и читать апостериор (PyMC), выполнять PPC; (5) строить бутстреп-ДИ и перестановочные p-значения; (6) оформлять воспроизводимый отчёт.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb347b5b",
      "metadata": {
        "id": "eb347b5b"
      },
      "source": [
        "## 1. Данные и дизайн эксперимента\n",
        "\n",
        "Требования к данным. Желательно $n\\in[5\\cdot10^4,1.5\\cdot10^5]$, смешанные типы (число+категории+время). Разрешены большие наборы с честной подвыборкой (например, фиксированный интервал времени/случайная выборка 100–120 тыс. строк). Хорошими источниками являются городские такси (NYC TLC, Chicago Taxi), e-commerce (Olist), поведенческие/рейтинговые (MovieLens), дорожно-транспортные происшествия (STATS19).\n",
        "\n",
        "Вопросы и переменные. Определите: целевую переменную $y$ (непрерывную: выручка/длительность/сумма), набор предикторов $X$ (стоимость, время суток, категория товара, погодные/районные признаки), потенциальные взаимодействия (например, «час$\\times$район»). Разбейте данные на обучающую/валидационную схему с кросс-валидацией. Для задач на транзакциях важно исключить утечки (например, признаки, формирующиеся пост-фактум).\n",
        "\n",
        "Критерии качества и риска. Выберите метрики: $R^2$, RMSE/MAE для базовой модели; для сравнения моделей используйте перекрёстную проверку (KFold/StratifiedKFold, при необходимости — TimeSeriesSplit). Фиксируйте случайные зерна и протоколы предобработки.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12536dc9",
      "metadata": {
        "id": "12536dc9"
      },
      "source": [
        "## 2. Линейные модели и ANOVA: спецификация и сравнение (минимум 600 слов)\n",
        "\n",
        "OLS-модель. Запишите базовую спецификацию: $y = X\\beta+\\varepsilon$, где $\\varepsilon\\sim \\mathcal{N}(0,\\sigma^2 I)$. Оценка МНК: $\\hat\\beta=(X^\\top X)^{-1}X^\\top y$. Включите категориальные эффекты (OHE) и взаимодействия (например, «категория$\\times$час»). Сравните вложенные модели через частичные F-тесты/девиансы.\n",
        "\n",
        "ANOVA/контрасты. Для сравнения спецификаций используйте дисперсионный анализ в смысле разложения суммы квадратов и тестирования добавочных блоков признаков. Вектор контраста $c$ для проверки гипотезы $H_0: c^\\top\\beta=0$; оценка и стандартная ошибка выводятся из ковариационной матрицы $\\widehat{\\mathrm{Var}}(\\hat\\beta)=\\hat\\sigma^2 (X^\\top X)^{-1}$.\n",
        "\n",
        "Множественные проверки. При тестировании множества коэффициентов/контрастов применяйте контроль FDR (Benjamini–Hochberg): упорядочьте p-значения $p_{(1)}\\le\\cdots\\le p_{(m)}$ и найдите максимальный $k$ с $p_{(k)}\\le \\frac{k}{m}\\alpha$; значимыми считаются $p_{(1)},\\dots,p_{(k)}$. Реализация — statsmodels.stats.multitest.multipletests."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22259257",
      "metadata": {
        "id": "22259257"
      },
      "source": [
        "## 3. Мультиколлинеарность, VIF и регуляризация (минимум 600 слов)\n",
        "\n",
        "Диагностика. Индекс инфляции дисперсии для признака $j$: $VIF_j=\\frac{1}{1-R_j^2}$, где $R_j^2$ — коэффициент детерминации регрессии $x_j$ на все прочие признаки. Большие $VIF$ (условно $>10$) указывают на нестабильность оценок и раздутые стандартные ошибки.\n",
        "Ridge/Lasso. Регуляризованные оценки:\n",
        "- Ridge: $\\hat\\beta_\\lambda=\\arg\\min_\\beta |y-X\\beta|_2^2 + \\lambda|\\beta|_2^2$,\n",
        "- Lasso: $\\hat\\beta_\\lambda=\\arg\\min_\\beta |y-X\\beta|_2^2 + \\lambda|\\beta|_1$.\n",
        "Подбирайте $\\lambda$ по кросс-валидации (например, лог-сетка). Ridge снижает дисперсию оценок и стабилизирует прогнозы при умеренной корреляции; Lasso даёт разреженность и встроенный отбор признаков, но чувствителен к масштабированию. См. документы и примеры scikit-learn по OLS/Ridge и обобщениям."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8de13612",
      "metadata": {
        "id": "8de13612"
      },
      "source": [
        "## 4. Байесовская регрессия и постериорно-предсказательная проверка\n",
        "\n",
        "Модель. Пусть $y\\mid X,\\beta,\\sigma^2\\sim \\mathcal{N}(X\\beta,\\sigma^2 I)$, априорные распределения $p(\\beta)$ и $p(\\sigma^2)$ (например, $\\beta\\sim \\mathcal{N}(0,\\tau^2 I)$; $\\sigma\\sim \\mathrm{HalfCauchy}$). Постериор: $p(\\beta,\\sigma^2\\mid y)\\propto p(y\\mid X,\\beta,\\sigma^2),p(\\beta),p(\\sigma^2)$. Предсказательное распределение для нового $x_\\star$: $p(y_\\star\\mid x_\\star,y)=\\int p(y_\\star\\mid x_\\star,\\beta,\\sigma^2),p(\\beta,\\sigma^2\\mid y),d\\beta,d\\sigma^2$.\n",
        "\n",
        "Практика. В PyMC укажите модель в явном виде, используйте NUTS для сэмплинга, проверьте сходимость (R-hat, ESS), постериорные интервалые для коэффициентов и PPC для согласованности с наблюдаемыми данными."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46baa873",
      "metadata": {
        "id": "46baa873"
      },
      "source": [
        "## 5. Ресемплинг: бутстреп-ДИ и перестановочные тесты\n",
        "\n",
        "Бутстреп. Для параметра $\\theta=g(X,y)$ (например, коэффициента $\\beta_j$ или RMSE) сформируйте $B$ бутстреп-выборок с возвращением, получите ${\\hat\\theta^{(b)}}{b=1}^B$, и задайте ДИ по процентилям: $[q{\\alpha/2},q_{1-\\alpha/2}]$.\n",
        "\n",
        "Перестановочные тесты. Для статистики $T$ (например, корреляция/разность RMSE между моделями на одинаковых фолдах) переставляйте метки/знаки по нулевой гипотезе, получая ${T^{(b)}}$, и вычисляйте $p$-значение $p=\\frac{1+\\sum_{b=1}^B \\mathbb{I}(|T^{(b)}|\\ge |T_{\\text{obs}}|)}{1+B}$. Эти процедуры особенно полезны при нарушениях гауссовости/гомоскедастичности либо сложной зависимой структуре данных."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bae0bfda",
      "metadata": {
        "id": "bae0bfda"
      },
      "source": [
        "## Пул рекомендованных датасетов\n",
        "\n",
        "D1. NYC TLC Trip Records (Yellow/Green). Возьмите один месяц и случайную подвыборку 100–120k поездок (например, январь 2019). Документация и структура полей — в руководстве TLC.\n",
        "\n",
        "D2. Chicago Taxi Trips. Фильтрация по кварталу 2020-го даёт нужный объём; таблица содержит стоимость, время, гео-идентификаторы.\n",
        "\n",
        "D3. Olist Brazilian E-commerce. Таблица orders $\\approx 99,441$ заказов + связи с продуктами/категориями/логистикой. Отлично подходит для регрессии по выручке/времени доставки.\n",
        "\n",
        "D4. MovieLens 100K. 100k рейтингов с признаками пользователей/фильмов; можно строить регрессию по рейтингу, учитывая жанры и время.\n",
        "\n",
        "D5. UK Road Safety (STATS19). Выберите один год (например, 2017) и сформируйте подмножество ≈100–140k инцидентов, обогащая погодой/дорожными условиями."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a84beae",
      "metadata": {
        "id": "9a84beae"
      },
      "source": [
        "## 35 вариантов заданий (обобщающие, с привязкой к D1–D5)\n",
        "\n",
        "### Общие методические требования (для всех вариантов):\n",
        "1) Постройте базовую OLS-модель (целевую переменную укажу в каждом варианте).\n",
        "2) Выполните диагностику мультиколлинеарности (VIF) и сравните с Ridge/Lasso (подбор $\\lambda$ по $K$-fold CV).\n",
        "3) Проведите проверки гипотез по коэффициентам/контрастам; множественные сравнения контролируйте по BH-FDR.\n",
        "4) Постройте байесовскую версию ключевой модели с умеренно информативными априорами и выполните предиктивную проверку (PPC).\n",
        "5) Оцените устойчивость: бутстреп-ДИ для ключевого показателя (RMSE/MAE/$R^2$) и перестановочный тест для сопоставления двух моделей.\n",
        "6) Объём данных: используйте подвыборку 50–150 тыс. строк из указанного источника, обоснуйте схему семплинга (по месяцам/зонам/времени и т. п.).\n",
        "\n",
        "\n",
        "### Варианты заданий для самостоятельной работы (выбрать один не повторяющийся):\n",
        "NYC-Fare Demand (D1). Цель: предсказать fare_amount. Сформируйте признаки: trip_distance, PULocationID/DOLocationID (One-Hot или hashing), календарные факторы (час, день недели, месяц), прокси-нагрузки (час пик/выходной), а также взаимодействия hour×borough (боро восстановите из зон TLC). Сравните: базовая OLS vs. Ridge/Lasso при полной фиксации календарных и геопризнаков. Выполните контрасты для сравнения средних тарифов по боровым кластерам (контроль BH-FDR внутри семейства «география»). Проведите бутстреп-ДИ для $R^2$ и перестановочный тест для различия RMSE между OLS и Ridge. Для байес-модели задайте слабые $N(0,\\sigma^2)$ априоры на коэффициенты и Half-Cauchy на шум; проверьте PPC по распределению остатков. Используйте случайную выборку поездок из двух соседних месяцев, чтобы получить 50–150k наблюдений.\n",
        "\n",
        "NYC-Duration (D1). Цель: предсказать trip_duration (разница между dropoff и pickup). Сформируйте trip_distance, hour, day_of_week, borough, плотность посадок в окне предыдущего часа (прокси трафика). Сравните две спецификации: без прокси-трафика и с ним; протестируйте значимость добавления по F-тесту/перестановочному аналогу; контролируйте BH-FDR по группе временных эффектов. Ridge/Lasso для стабилизации при множестве фиктивных переменных зон. В байес-версии используйте регуляризирующие априоры с различной шкалой для календарных (у́же) и геопризнаков (шире). Бутстреп-ДИ для разницы $R^2$ между моделями; перестановочный тест для разницы MAE.\n",
        "\n",
        "NYC-Tips (D1). Цель: tip_amount / fare_amount (доля чаевых) — учтите отсечения/аномалии (негативные или сверхбольшие). Признаки: payment_type, trip_distance, hour, borough, fare_amount. Проверьте семейство гипотез по эффектам payment_type и часам суток (контроль BH-FDR в каждом семействе отдельно). Сравните OLS vs. Lasso для отсеивания слабых категориальных эффектов; бутстреп-ДИ для медианной ошибки предсказания доли чаевых; байес-версия с логит-ссылкой для доли (альтернатива: моделируйте логит-трансформированную долю). Перестановочный тест — разница в $R^2$/MAE между OLS и Lasso.\n",
        "\n",
        "NYC-Surge Proxy (D1). Бинаризуйте признак is_surge: «итоговая стоимость за милю выше медианы данного часа в боро». Постройте линейную вероятность (OLS) и логистическую регрессию; сравните калибровку (Brier), AUC и интерпретируемость коэффициентов (через маргинальные эффекты). Контрасты — «ночь vs. день» внутри каждого боро (BH-FDR). Перестановочный тест для разницы AUC. Бутстреп-ДИ для разницы Brier. В байес-логите используйте слабые $N(0,1)$ априоры и оцените предиктивные вероятности событий «surge».\n",
        "\n",
        "NYC-Airports (D1). Сфокусируйтесь на поездках из/в JFK/LGA; целевая — total_amount или fare_amount. Признаки: airport_indicator, hour, distance, toll_amount, взаимодействия airport×hour×distance. Проверьте значимость тройного взаимодействия; контролируйте BH-FDR по группе взаимодействий. Ridge рекомендуется из-за сильной корреляции distance/времени и фиксированных эффектов зон. Байес-версия: слабоинформативные априоры; PPC для хвостов распределения остатков; бутстреп-ДИ для коэффициента при airport×hour.\n",
        "\n",
        "Chicago-Fare (D2). Цель: fare. Признаки: trip_miles, trip_seconds, pickup/dropoff_community_area, company, календарные факторы. Проверьте гипотезы о средних тарифах по поставщикам (семейство «company», BH-FDR). OLS vs. Ridge/Lasso (много фиксированных эффектов → регуляризация полезна). Перестановочный тест разницы RMSE; бутстреп-ДИ для $R^2$. Байес-версия: иерархические эффекты «company» (частично-пуловые априоры).\n",
        "\n",
        "Chicago-WaitTime (D2). Цель: прокси waiting_time — для каждой зоны и часа оцените средний лаг между посадками (постройте по временам начала поездки, агрегируя «следующая поездка»). Модель: waiting_time ~ календарные факторы + company + плотность поездок в окне. Проверьте, снижается ли ожидание в час пик в центре (контраст «Loop vs. прочие»; BH-FDR внутри геофакторов). Ridge для стабилизации; байес-версия с лог-нормальным шумом. Перестановочный тест для разницы MAE с/без плотности.\n",
        "\n",
        "Chicago-TipRate (D2). Цель: tips / (fare+fees). Признаки: trip_miles, trip_seconds, company, payment_type, календарные. Семейство гипотез по категориям оплаты и временам суток (BH-FDR). Сравните OLS и Lasso для отбора категориальных фиктивных признаков. Бутстреп-ДИ для медианной абсолютной ошибки доли; байес-логит-модель доли с PPC.\n",
        "\n",
        "Olist-GMV (D3). Соберите таблицу заказов (merge orders + order_items + payments + products). Цель: GMV заказа (сумма платежей). Признаки: product_category_name, seller_state, delivery_time (разница между доставкой и отправкой), способ оплаты, количество позиций. Проверьте VIF, сравните OLS vs. Ridge; семейство гипотез — эффекты категорий (BH-FDR). Бутстреп-ДИ для $R^2$ по товарам high-freq; байес-версия с регуляризующими априорами.\n",
        "\n",
        "Olist-DeliveryDelay (D3). Цель: delivery_delay = (время доставки − обещанный срок). Признаки: категория товара, габариты/вес (если доступны прокси), перевозчик, расстояние «seller_state→customer_state» (приблизьте по центроидам штатов). Сравните спецификации: без перевозчика и с ним (F-тест + перестановка). Контроль BH-FDR по семейству категорий. Ridge для коррелирующих логистических признаков. Байес-модель — лог-нормальный шум и слабоинформативные априоры.\n",
        "\n",
        "Olist-ItemPrice (D3). Цель: цена позиции (price). Признаки: категория, количество позиций в заказе, скидки/рассрочки (из payments), сезонность по месяцу. Сравните OLS/Lasso; Lasso — для отбора релевантных категорий. Гипотезы по кластерам категорий (предварительно укрупните словарь) — контроль BH-FDR. Бутстреп-ДИ для коэффициента при «bundle size»; перестановка для разницы MAE.\n",
        "\n",
        "Olist-ReturnRisk (D3). ПСравнить линейную вероятность (LPM, OLS на бинарной $Y$) и логистическую регрессию. LPM даёт простую интерпретацию коэффициентов как приближённые изменения вероятности, но страдает от гетероскедастичности и предсказаний вне [0,1]; логит корректно моделирует вероятность и даёт устойчивые оценки на краях.\n",
        "\n",
        "MovieLens-Rating (D4). Цель: предсказать rating. Признаки: жанровые фиктивные переменные (из movies.csv), средний рейтинг фильма (leave-one-out), активность пользователя (кол-во оценок; LOO), временной тренд по году. Сравните OLS vs. Ridge; выполните BH-FDR по семейству жанров. Бутстреп-ДИ для $R^2$; перестановка для разницы RMSE между OLS/Ridge; байес-версия с частичным пуллингом по фильмам/пользователям (иерархичность).\n",
        "\n",
        "MovieLens-Temporal (D4). Добавьте взаимодействие genre×year и прокси усталости пользователя (порядковый номер оценки). Проверьте значимость взаимодействий (семейство взаимодействий — BH-FDR). Ridge/Lasso для стабилизации параметров. Бутстреп-ДИ для эффекта тренда по ключевым жанрам; байес-модель с априорами, понижающими дисперсию взаимодействий.\n",
        "\n",
        "MovieLens-ColdStart (D4). Исключите редкие жанры (<1% фильмов), затем верните их с Lasso-регуляризацией (цель — rating). Сравните стабильность выбранных жанров по бутстрепу (доля совпавших ненулевых коэффициентов). Перестановочный тест для разницы MAE с/без Lasso. BH-FDR — семейство «жанры». Байес-аналог: лапласовские (L1-подобные) априоры для индукции разреженности.\n",
        "\n",
        "STATS19-Severity (D5). Соберите данные ДТП и создайте непрерывный суррогат серьёзности (например, число пострадавших/скорость/интенсивность). Признаки: weather, lighting, speed_limit, road_type, urban_or_rural, время суток и дня недели. Проверьте взаимодействия weather×lighting; BH-FDR для семейства сред по категориям инфраструктуры. Ridge для коррелирующих дорожных факторов. Перестановочный тест для разницы RMSE с/без взаимодействий; бутстреп-ДИ для эффекта освещённости.\n",
        "\n",
        "STATS19-TimeOfDay (D5). Цель: предсказать суррогат серьёзности/число пострадавших по времени суток. Признаки: hour, day_of_week, lighting, speed_limit, junction_detail, police_force (фиксированные эффекты). Контрасты «ночь vs. день» по типам дорог (BH-FDR в семействе контрастов). Ridge для стабилизации; байес-версия с частичным пуллингом по регионам; бутстреп-ДИ для эффекта ночи; перестановка — разница MAE.\n",
        "\n",
        "STATS19-Junctions (D5). Исследуйте влияние типа перекрёстка (junction_control/junction_detail) на серьёзность. Проверьте мультиколлинеарность инфраструктурных признаков (VIF); при необходимости примените Ridge/Lasso. Семейство гипотез — эффекты разных типов перекрёстков (BH-FDR). Бутстреп-ДИ для ключевых коэффициентов; байес-модель с иерархией по регионам.\n",
        "\n",
        "NYC-TollEffect (D1). Цель: оценить влияние toll_amount на total_amount с учётом distance, hour, borough. Контраст «с toll vs. без toll» по сопоставимым окнам времени/маршрутам; BH-FDR — по семейству контрастов в боро. Ridge — при сильной корреляции distance/toll. Бутстреп-ДИ для коэффициента toll_amount; перестановка — разница RMSE между спецификациями.\n",
        "\n",
        "NYC-NightPremium (D1). Определите «ночную надбавку» как взаимодействие night×weekend×borough в модели fare_amount. Проверьте значимость взаимодействия (семейство — взаимодействия; BH-FDR). Ridge — из-за большого числа фиктивных. Бутстреп-ДИ для эффекта ночи по боро; байес-версия с регуляризирующими априорами на взаимодействия.\n",
        "\n",
        "Chicago-WeatherProxy (D2). Поскольку в прямом виде погоды нет, используйте прокси: индикатор «пятница вечер/час пик» и сезонность по месяцам. Цель — fare или trip_seconds. Сравните модели: (A) без прокси; (B) с прокси. Оцените смещение по перестановочным тестам (разница RMSE) и устойчивость по бутстреп-ДИ. Контроль BH-FDR для группы временных эффектов. Ridge предпочтителен при множестве фиктивных переменных зон.\n",
        "\n",
        "Chicago-ProviderEffect (D2). Цель: объяснить fare с акцентом на company/provider. Задайте контрасты «крупные vs. малые провайдеры» с контролем BH-FDR по семейству всех пар провайдеров (корректно опишите семейство). Сравните OLS и Lasso; бутстреп-ДИ для разницы $R^2$; байес-иерархическая модель с частичным пуллингом по провайдерам; PPC на хвосты.\n",
        "\n",
        "Olist-Bundle (D3). Эффект количества позиций в заказе на GMV. Добавьте категории, способ оплаты, сроки доставки. VIF — проверьте мультиколлинеарность категориальных фиктивных; Ridge против Lasso при большом словаре категорий. BH-FDR — по семейству категорий. Бутстреп-ДИ для коэффициента «bundle size»; перестановка — разница RMSE.\n",
        "\n",
        "Olist-Geo (D3). Добавьте признаки географии seller_state и customer_state, а также взаимодействие seller_state×customer_state (укрупните штаты в макрорегионы, чтобы не раздуть модель). Цель: delivery_time или GMV. Ridge — предпочтителен при множестве взаимодействий. BH-FDR — по семейству региональных эффектов. Бутстреп-ДИ для эффекта «межрегиональность»; перестановка — разница MAE.\n",
        "\n",
        "Olist-Holiday (D3). Определите праздничные периоды (бразильские федеральные праздники); цель — GMV. Постройте контраст «holiday vs. non-holiday», учтя взаимодействия holiday×category; контролируйте BH-FDR по семейству категорий. Сравните OLS/Ridge (много фиктивных переменных). Перестановочный тест для разницы RMSE; бутстреп-ДИ для эффекта праздников на GMV.\n",
        "\n",
        "MovieLens-GenreClusters (D4). Сформируйте кластеры жанров (например, по со-встречаемости в фильмах), замените жанры на принадлежность к кластерам. Цель — rating. Lasso для отбора кластеров; BH-FDR — семейство «кластеры». Проверьте устойчивость кластеризации бутстрепом (stability selection). Байес-версия: априоры на кластеры с общей шкалой.\n",
        "\n",
        "MovieLens-UserAge (D4). Исследовать нелинейное влияние возраста пользователя на рейтинг с контролем жанров/года релиза. Сопоставить три спецификации:\n",
        "(a) кусочно-постоянный биннинг возраста;\n",
        "(b) гладкие B-сплайны (например, 4–6 узлов) через SplineTransformer;\n",
        "(c) сплайны с Ridge на коэффициентах для сглаживания и борьбы с мультиколлинеарностью базисных функций.\n",
        "\n",
        "STATS19-Lighting (D5). Цель: эффект lighting_conditions при контроле weather, speed_limit, urban/rural, времени суток. Сравните модели: без освещения и с ним; оцените прирост качества (перестановка для разницы RMSE). Проведите контрасты «темнота без освещения vs. день» и «искусственное освещение vs. день» с BH-FDR. Бутстреп-ДИ для эффектов освещения; байес-версия с лог-нормальным шумом (если целевая — положительная непрерывная).\n",
        "\n",
        "STATS19-SpeedLimit (D5). Цель: предсказать суррогат серьёзности по speed_limit и типу дороги; добавьте взаимодействие speed_limit×road_type. VIF — на предмет коллинеарности дорожных переменных; Ridge — для стабилизации. Семейство гипотез — уровни speed_limit (BH-FDR). Бутстреп-ДИ для эффекта повышения лимита на +10 mph; перестановка — сравнение RMSE между OLS/Ridge.\n",
        "\n",
        "NYC-PaymentType (D1). Цель: объяснить tip_rate по payment_type, контролируя distance, hour, borough. Семейство гипотез — пары типов оплаты (BH-FDR). Lasso — для отбора слабых категориальных эффектов. Бутстреп-ДИ для медианной ошибки; перестановочный тест — разница $R^2$ OLS/Lasso.\n",
        "\n",
        "NYC-ShortTrips (D1). Сосредоточьтесь на поездках ≤ 2 мили. Цель: fare_per_mile. Признаки: hour, borough, payment_type, congestion_surcharge. Проверьте гипотезу о систематическом завышении цены в часы пик (контрасты внутри боро; BH-FDR). Бутстреп-ДИ для эффекта часа пик; перестановка — разница RMSE с/без surcharge.\n",
        "\n",
        "Chicago-AirportRuns (D2). ЭВыделите поездки из/в ORD/MDW (по зонам). Цель: fare или fare_per_mile. Признаки: hour, trip_miles, company, индикатор аэропорта, взаимодействия airport×hour. Контрасты «airport vs. non-airport» (BH-FDR). Ridge — при множестве фиктивных зон. Перестановочный тест — разница RMSE; бутстреп-ДИ для эффекта аэропортов.\n",
        "\n",
        "Olist-CategoryDepth (D3). Построить регрессионную модель (целевую величину выберите по сценарию: price, freight_value или средний чек по товару/категории). Ввести числовой прокси «глубина категории» как $(1+\\text{количество\\_подчёркиваний})$ в product_category_name (например, bed_bath_table → 3), а также альтернативы: число токенов (после замены _ на пробел), длина строки, бинарный признак «сложная категория» (глубина ≥3). Включить one-hot кодирование категорий/продавцов по необходимости.\n",
        "\n",
        "MovieLens-Bias (D4). Сравнить две вложенные модели предсказания рейтинга $r_{ui}$:\n",
        "— Базовая OLS: $r_{ui}=\\beta_0+X_{ui}\\beta+\\varepsilon_{ui}$, где $X_{ui}$ — жанры (one-hot), год релиза (биннинг/сплайны), возможно длительность/ключевые метки.\n",
        "— Модель со смещениями (fixed effects): $r_{ui}=\\mu+b_u+b_i+X_{ui}\\beta+\\varepsilon_{ui}$, где $b_u$ — пользовательские, $b_i$ — фильмовские эффекты (допуская центрирование). При большом числе эффектов — регуляризация (ridge на эффектах или частичное усреднение).\n",
        "\n",
        "STATS19-UrbanRural (D5). Изучите взаимодействие urban_or_rural×road_type с контролем освещения/погоды/скорости. Гипотезы по контрастам внутри пар «город/село» (BH-FDR). Сравните OLS vs. Ridge; байес-иерархия по регионам; бутстреп-ДИ для ключевого взаимодействия; перестановка — разница MAE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec07e8e4",
      "metadata": {
        "id": "ec07e8e4"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# OLS МОДЕЛИ И ANOVA\n",
        "# =============================================================================\n",
        "\n",
        "def fit_ols_model(\n",
        "    X: pd.DataFrame,\n",
        "    y: np.ndarray,\n",
        "    add_constant: bool = True\n",
        ") -> sm.regression.linear_model.RegressionResultsWrapper:\n",
        "    \"\"\"\n",
        "    Построить OLS модель\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pd.DataFrame\n",
        "        Матрица признаков\n",
        "    y : np.ndarray\n",
        "        Целевая переменная\n",
        "    add_constant : bool\n",
        "        Добавить константу\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    statsmodels RegressionResults\n",
        "        Результаты регрессии\n",
        "    \"\"\"\n",
        "    # TODO: Добавить константу если нужно\n",
        "    # TODO: Обучить OLS модель через statsmodels\n",
        "    # TODO: Вывести summary\n",
        "    pass\n",
        "\n",
        "\n",
        "def compare_nested_models(\n",
        "    model_restricted: sm.regression.linear_model.RegressionResultsWrapper,\n",
        "    model_full: sm.regression.linear_model.RegressionResultsWrapper,\n",
        "    alpha: float = 0.05\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Сравнить вложенные модели через F-тест\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model_restricted : RegressionResults\n",
        "        Ограниченная модель\n",
        "    model_full : RegressionResults\n",
        "        Полная модель\n",
        "    alpha : float\n",
        "        Уровень значимости\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, float]\n",
        "        Статистики теста (F-stat, p-value, conclusion)\n",
        "    \"\"\"\n",
        "    # TODO: Вычислить F-статистику\n",
        "    # TODO: Сравнить RSS моделей\n",
        "    # TODO: Вернуть результат теста\n",
        "    pass\n",
        "\n",
        "\n",
        "def test_linear_contrasts(\n",
        "    model: sm.regression.linear_model.RegressionResultsWrapper,\n",
        "    contrast_matrix: np.ndarray,\n",
        "    contrast_names: Optional[List[str]] = None\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Проверить линейные контрасты\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : RegressionResults\n",
        "        Обученная модель\n",
        "    contrast_matrix : np.ndarray\n",
        "        Матрица контрастов (каждая строка - один контраст)\n",
        "    contrast_names : Optional[List[str]]\n",
        "        Названия контрастов\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Результаты тестов контрастов\n",
        "    \"\"\"\n",
        "    # TODO: Для каждого контраста c^T β = 0\n",
        "    # TODO: Вычислить статистику, p-value\n",
        "    # TODO: Вернуть DataFrame с результатами\n",
        "    pass\n",
        "\n",
        "\n",
        "def compute_anova_table(\n",
        "    model: sm.regression.linear_model.RegressionResultsWrapper,\n",
        "    typ: int = 2\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Вычислить таблицу ANOVA\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : RegressionResults\n",
        "        Обученная модель\n",
        "    typ : int\n",
        "        Тип ANOVA (1, 2, или 3)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Таблица ANOVA\n",
        "    \"\"\"\n",
        "    # TODO: Использовать statsmodels для построения ANOVA\n",
        "    # TODO: Вернуть таблицу с SS, df, F, p-value\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac054a4d",
      "metadata": {
        "id": "ac054a4d"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# МУЛЬТИКОЛЛИНЕАРНОСТЬ И VIF\n",
        "# =============================================================================\n",
        "\n",
        "def compute_vif(X: pd.DataFrame, add_constant: bool = True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Вычислить VIF для всех признаков\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pd.DataFrame\n",
        "        Матрица признаков\n",
        "    add_constant : bool\n",
        "        Добавить константу перед вычислением\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        VIF для каждого признака\n",
        "    \"\"\"\n",
        "    # TODO: Для каждого признака вычислить VIF_j = 1/(1-R²_j)\n",
        "    # TODO: Вернуть DataFrame с признаками и их VIF\n",
        "    # TODO: Отметить признаки с VIF > 10\n",
        "    pass\n",
        "\n",
        "\n",
        "def diagnose_multicollinearity(\n",
        "    X: pd.DataFrame,\n",
        "    vif_threshold: float = 10.0,\n",
        "    corr_threshold: float = 0.8\n",
        ") -> Dict[str, Union[pd.DataFrame, List[Tuple[str, str]]]]:\n",
        "    \"\"\"\n",
        "    Диагностировать мультиколлинеарность\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pd.DataFrame\n",
        "        Матрица признаков\n",
        "    vif_threshold : float\n",
        "        Порог VIF\n",
        "    corr_threshold : float\n",
        "        Порог корреляции\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict\n",
        "        VIF таблица и пары сильно коррелирующих признаков\n",
        "    \"\"\"\n",
        "    # TODO: Вычислить VIF\n",
        "    # TODO: Найти пары признаков с высокой корреляцией\n",
        "    # TODO: Рекомендовать какие признаки удалить\n",
        "    pass\n",
        "\n",
        "\n",
        "def iteratively_remove_high_vif(\n",
        "    X: pd.DataFrame,\n",
        "    vif_threshold: float = 10.0,\n",
        "    max_iterations: int = 10\n",
        ") -> Tuple[pd.DataFrame, List[str]]:\n",
        "    \"\"\"\n",
        "    Итеративно удалять признаки с высоким VIF\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pd.DataFrame\n",
        "        Матрица признаков\n",
        "    vif_threshold : float\n",
        "        Порог VIF\n",
        "    max_iterations : int\n",
        "        Максимум итераций\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_reduced : pd.DataFrame\n",
        "        Редуцированная матрица признаков\n",
        "    removed_features : List[str]\n",
        "        Список удалённых признаков\n",
        "    \"\"\"\n",
        "    # TODO: Итеративно вычислять VIF\n",
        "    # TODO: На каждой итерации удалять признак с максимальным VIF > threshold\n",
        "    # TODO: Остановиться когда все VIF < threshold\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98281f0d",
      "metadata": {
        "id": "98281f0d"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# РЕГУЛЯРИЗАЦИЯ (RIDGE/LASSO)\n",
        "# =============================================================================\n",
        "\n",
        "def fit_ridge_cv(\n",
        "    X: pd.DataFrame,\n",
        "    y: np.ndarray,\n",
        "    alphas: Optional[np.ndarray] = None,\n",
        "    cv: int = 5,\n",
        "    scoring: str = 'neg_mean_squared_error'\n",
        ") -> Tuple[Ridge, np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Подобрать Ridge регрессию с кросс-валидацией\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pd.DataFrame\n",
        "        Матрица признаков\n",
        "    y : np.ndarray\n",
        "        Целевая переменная\n",
        "    alphas : Optional[np.ndarray]\n",
        "        Сетка гиперпараметров λ\n",
        "    cv : int\n",
        "        Число фолдов\n",
        "    scoring : str\n",
        "        Метрика для оптимизации\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model : Ridge\n",
        "        Обученная модель с лучшим α\n",
        "    alphas : np.ndarray\n",
        "        Использованные значения α\n",
        "    best_alpha : float\n",
        "        Оптимальное значение α\n",
        "    \"\"\"\n",
        "    # TODO: Стандартизировать признаки\n",
        "    # TODO: Использовать RidgeCV для подбора α\n",
        "    # TODO: Построить график CV score vs alpha\n",
        "    # TODO: Вернуть лучшую модель\n",
        "    pass\n",
        "\n",
        "\n",
        "def fit_lasso_cv(\n",
        "    X: pd.DataFrame,\n",
        "    y: np.ndarray,\n",
        "    alphas: Optional[np.ndarray] = None,\n",
        "    cv: int = 5,\n",
        "    scoring: str = 'neg_mean_squared_error',\n",
        "    max_iter: int = 10000\n",
        ") -> Tuple[Lasso, np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Подобрать Lasso регрессию с кросс-валидацией\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pd.DataFrame\n",
        "        Матрица признаков\n",
        "    y : np.ndarray\n",
        "        Целевая переменная\n",
        "    alphas : Optional[np.ndarray]\n",
        "        Сетка гиперпараметров λ\n",
        "    cv : int\n",
        "        Число фолдов\n",
        "    scoring : str\n",
        "        Метрика для оптимизации\n",
        "    max_iter : int\n",
        "        Максимум итераций\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model : Lasso\n",
        "        Обученная модель с лучшим α\n",
        "    alphas : np.ndarray\n",
        "        Использованные значения α\n",
        "    best_alpha : float\n",
        "        Оптимальное значение α\n",
        "    \"\"\"\n",
        "    # TODO: Стандартизировать признаки\n",
        "    # TODO: Использовать LassoCV для подбора α\n",
        "    # TODO: Построить график CV score vs alpha\n",
        "    # TODO: Построить график путей коэффициентов (Lasso path)\n",
        "    # TODO: Вернуть лучшую модель\n",
        "    pass\n",
        "\n",
        "\n",
        "def compare_regularization_methods(\n",
        "    X_train: pd.DataFrame,\n",
        "    y_train: np.ndarray,\n",
        "    X_test: pd.DataFrame,\n",
        "    y_test: np.ndarray\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Сравнить OLS, Ridge и Lasso\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X_train, y_train : обучающая выборка\n",
        "    X_test, y_test : тестовая выборка\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Таблица сравнения метрик (RMSE, MAE, R²)\n",
        "    \"\"\"\n",
        "    # TODO: Обучить OLS, Ridge, Lasso\n",
        "    # TODO: Вычислить метрики на train и test\n",
        "    # TODO: Сравнить количество ненулевых коэффициентов\n",
        "    # TODO: Вернуть сводную таблицу\n",
        "    pass\n",
        "\n",
        "\n",
        "def plot_coefficient_comparison(\n",
        "    models: Dict[str, Union[LinearRegression, Ridge, Lasso]],\n",
        "    feature_names: List[str],\n",
        "    top_n: int = 20\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Визуализировать сравнение коэффициентов моделей\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    models : Dict[str, model]\n",
        "        Словарь обученных моделей\n",
        "    feature_names : List[str]\n",
        "        Названия признаков\n",
        "    top_n : int\n",
        "        Показать top N признаков по абсолютной величине\n",
        "    \"\"\"\n",
        "    # TODO: Извлечь коэффициенты из каждой модели\n",
        "    # TODO: Построить grouped bar plot\n",
        "    # TODO: Отсортировать по важности\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f84683cd",
      "metadata": {
        "id": "f84683cd"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# МНОЖЕСТВЕННЫЕ СРАВНЕНИЯ И FDR-КОНТРОЛЬ\n",
        "# =============================================================================\n",
        "\n",
        "def apply_fdr_correction(\n",
        "    pvalues: np.ndarray,\n",
        "    alpha: float = 0.05,\n",
        "    method: str = 'fdr_bh'\n",
        ") -> Tuple[np.ndarray, np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Применить коррекцию FDR (Benjamini-Hochberg)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pvalues : np.ndarray\n",
        "        Массив p-значений\n",
        "    alpha : float\n",
        "        Уровень FDR\n",
        "    method : str\n",
        "        Метод коррекции ('fdr_bh', 'fdr_by', 'bonferroni')\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    rejected : np.ndarray\n",
        "        Булевы маски отклонённых гипотез\n",
        "    pvals_corrected : np.ndarray\n",
        "        Скорректированные p-значения\n",
        "    alphac : float\n",
        "        Скорректированный уровень значимости\n",
        "    \"\"\"\n",
        "    # TODO: Использовать statsmodels.stats.multitest.multipletests\n",
        "    # TODO: Вернуть результаты коррекции\n",
        "    pass\n",
        "\n",
        "\n",
        "def test_coefficient_family(\n",
        "    model: sm.regression.linear_model.RegressionResultsWrapper,\n",
        "    family_indices: List[int],\n",
        "    family_name: str,\n",
        "    fdr_alpha: float = 0.05\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Проверить семейство коэффициентов с FDR-контролем\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : RegressionResults\n",
        "        Обученная модель\n",
        "    family_indices : List[int]\n",
        "        Индексы коэффициентов в семействе\n",
        "    family_name : str\n",
        "        Название семейства\n",
        "    fdr_alpha : float\n",
        "        Уровень FDR\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Результаты тестов с коррекцией\n",
        "    \"\"\"\n",
        "    # TODO: Извлечь p-значения для семейства\n",
        "    # TODO: Применить FDR-коррекцию\n",
        "    # TODO: Вернуть таблицу с результатами\n",
        "    pass\n",
        "\n",
        "\n",
        "def test_multiple_contrasts(\n",
        "    model: sm.regression.linear_model.RegressionResultsWrapper,\n",
        "    contrast_dict: Dict[str, np.ndarray],\n",
        "    fdr_alpha: float = 0.05\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Проверить множество контрастов с FDR-контролем\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : RegressionResults\n",
        "        Обученная модель\n",
        "    contrast_dict : Dict[str, np.ndarray]\n",
        "        Словарь {название: вектор контраста}\n",
        "    fdr_alpha : float\n",
        "        Уровень FDR\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Результаты всех контрастов с коррекцией\n",
        "    \"\"\"\n",
        "    # TODO: Для каждого контраста вычислить статистику и p-value\n",
        "    # TODO: Применить FDR-коррекцию к семейству p-values\n",
        "    # TODO: Вернуть сводную таблицу\n",
        "    pass\n",
        "\n",
        "\n",
        "def visualize_multiple_testing_results(\n",
        "    pvalues_raw: np.ndarray,\n",
        "    pvalues_corrected: np.ndarray,\n",
        "    rejected: np.ndarray,\n",
        "    test_names: List[str],\n",
        "    alpha: float = 0.05\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Визуализировать результаты множественных сравнений\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pvalues_raw : np.ndarray\n",
        "        Исходные p-значения\n",
        "    pvalues_corrected : np.ndarray\n",
        "        Скорректированные p-значения\n",
        "    rejected : np.ndarray\n",
        "        Маска отклонённых гипотез\n",
        "    test_names : List[str]\n",
        "        Названия тестов\n",
        "    alpha : float\n",
        "        Уровень значимости\n",
        "    \"\"\"\n",
        "    # TODO: Построить volcano plot или bar plot\n",
        "    # TODO: Показать линию отсечения α\n",
        "    # TODO: Выделить значимые тесты\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16e55719",
      "metadata": {
        "id": "16e55719"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# БАЙЕСОВСКАЯ РЕГРЕССИЯ (PyMC)\n",
        "# =============================================================================\n",
        "\n",
        "def build_bayesian_linear_model(\n",
        "    X: pd.DataFrame,\n",
        "    y: np.ndarray,\n",
        "    prior_scale: float = 10.0,\n",
        "    prior_sigma: str = 'halfcauchy'\n",
        ") -> pm.Model:\n",
        "    \"\"\"\n",
        "    Построить байесовскую линейную модель\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pd.DataFrame\n",
        "        Матрица признаков (стандартизированная)\n",
        "    y : np.ndarray\n",
        "        Целевая переменная\n",
        "    prior_scale : float\n",
        "        Масштаб априорного распределения для β\n",
        "    prior_sigma : str\n",
        "        Тип априора для σ ('halfcauchy', 'halfnormal', 'exponential')\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pm.Model\n",
        "        PyMC модель\n",
        "    \"\"\"\n",
        "    # TODO: Создать PyMC модель\n",
        "    # TODO: Задать априоры: β ~ N(0, prior_scale²)\n",
        "    # TODO: Задать априор для σ (HalfCauchy, HalfNormal)\n",
        "    # TODO: Задать likelihood: y ~ N(Xβ, σ²)\n",
        "    pass\n",
        "\n",
        "\n",
        "def sample_bayesian_model(\n",
        "    model: pm.Model,\n",
        "    draws: int = 2000,\n",
        "    tune: int = 1000,\n",
        "    chains: int = 4,\n",
        "    target_accept: float = 0.95\n",
        ") -> az.InferenceData:\n",
        "    \"\"\"\n",
        "    Сэмплировать из апостериорного распределения\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : pm.Model\n",
        "        PyMC модель\n",
        "    draws : int\n",
        "        Число сэмплов после warmup\n",
        "    tune : int\n",
        "        Число warmup итераций\n",
        "    chains : int\n",
        "        Число цепей\n",
        "    target_accept : float\n",
        "        Целевая вероятность принятия (для NUTS)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    az.InferenceData\n",
        "        Результаты сэмплирования\n",
        "    \"\"\"\n",
        "    # TODO: Использовать pm.sample с NUTS\n",
        "    # TODO: Вернуть InferenceData объект\n",
        "    pass\n",
        "\n",
        "\n",
        "def check_convergence_diagnostics(trace: az.InferenceData) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Проверить диагностики сходимости\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    trace : az.InferenceData\n",
        "        Результаты сэмплирования\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Таблица с R-hat, ESS для каждого параметра\n",
        "    \"\"\"\n",
        "    # TODO: Вычислить R-hat (должен быть < 1.01)\n",
        "    # TODO: Вычислить ESS (effective sample size)\n",
        "    # TODO: Построить trace plots\n",
        "    # TODO: Построить autocorrelation plots\n",
        "    pass\n",
        "\n",
        "\n",
        "def posterior_predictive_check(\n",
        "    model: pm.Model,\n",
        "    trace: az.InferenceData,\n",
        "    y_observed: np.ndarray,\n",
        "    n_samples: int = 1000\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Выполнить постериорно-предсказательную проверку (PPC)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : pm.Model\n",
        "        PyMC модель\n",
        "    trace : az.InferenceData\n",
        "        Апостериорное распределение\n",
        "    y_observed : np.ndarray\n",
        "        Наблюдаемые данные\n",
        "    n_samples : int\n",
        "        Число предсказательных сэмплов\n",
        "    \"\"\"\n",
        "    # TODO: Сгенерировать предсказания из апостериора\n",
        "    # TODO: Сравнить распределение предсказаний с наблюдениями\n",
        "    # TODO: Построить PPC plots (гистограммы, density plots)\n",
        "    # TODO: Проверить статистики (среднее, дисперсия, квантили)\n",
        "    pass\n",
        "\n",
        "\n",
        "def extract_posterior_intervals(\n",
        "    trace: az.InferenceData,\n",
        "    var_names: List[str],\n",
        "    hdi_prob: float = 0.95\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Извлечь апостериорные интервалы для параметров\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    trace : az.InferenceData\n",
        "        Апостериорное распределение\n",
        "    var_names : List[str]\n",
        "        Названия переменных\n",
        "    hdi_prob : float\n",
        "        Вероятность для HDI (highest density interval)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Таблица с mean, sd, HDI для каждого параметра\n",
        "    \"\"\"\n",
        "    # TODO: Использовать arviz.summary\n",
        "    # TODO: Извлечь HDI интервалы\n",
        "    # TODO: Построить forest plots\n",
        "    pass\n",
        "\n",
        "\n",
        "def compare_bayesian_models(\n",
        "    models: Dict[str, pm.Model],\n",
        "    traces: Dict[str, az.InferenceData]\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Сравнить байесовские модели через LOO/WAIC\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    models : Dict[str, pm.Model]\n",
        "        Словарь моделей\n",
        "    traces : Dict[str, az.InferenceData]\n",
        "        Словарь апостериорных распределений\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Таблица сравнения (LOO, WAIC, weights)\n",
        "    \"\"\"\n",
        "    # TODO: Вычислить LOO (leave-one-out cross-validation)\n",
        "    # TODO: Вычислить WAIC\n",
        "    # TODO: Использовать arviz.compare\n",
        "    # TODO: Вернуть таблицу сравнения моделей\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f6d3207",
      "metadata": {
        "id": "4f6d3207"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 7. БУТСТРЕП\n",
        "# =============================================================================\n",
        "\n",
        "def bootstrap_metric(\n",
        "    X: pd.DataFrame,\n",
        "    y: np.ndarray,\n",
        "    metric_func: callable,\n",
        "    n_bootstrap: int = 1000,\n",
        "    confidence_level: float = 0.95,\n",
        "    random_state: int = RANDOM_STATE\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Вычислить бутстреп доверительный интервал для метрики\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pd.DataFrame\n",
        "        Матрица признаков\n",
        "    y : np.ndarray\n",
        "        Целевая переменная\n",
        "    metric_func : callable\n",
        "        Функция метрики (принимает X, y; возвращает число)\n",
        "    n_bootstrap : int\n",
        "        Число бутстреп-итераций\n",
        "    confidence_level : float\n",
        "        Уровень доверия\n",
        "    random_state : int\n",
        "        Зерно для воспроизводимости\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, float]\n",
        "        mean, std, CI_lower, CI_upper\n",
        "    \"\"\"\n",
        "    # TODO: Для каждой итерации:\n",
        "    #   - Сформировать бутстреп-выборку (с возвращением)\n",
        "    #   - Вычислить метрику\n",
        "    # TODO: Вычислить процентильный CI\n",
        "    # TODO: Построить гистограмму распределения\n",
        "    pass\n",
        "\n",
        "\n",
        "def bootstrap_coefficients(\n",
        "    X: pd.DataFrame,\n",
        "    y: np.ndarray,\n",
        "    n_bootstrap: int = 1000,\n",
        "    confidence_level: float = 0.95,\n",
        "    model_type: str = 'ols'\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Бутстреп доверительные интервалы для коэффициентов регрессии\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pd.DataFrame\n",
        "        Матрица признаков\n",
        "    y : np.ndarray\n",
        "        Целевая переменная\n",
        "    n_bootstrap : int\n",
        "        Число бутстреп-итераций\n",
        "    confidence_level : float\n",
        "        Уровень доверия\n",
        "    model_type : str\n",
        "        Тип модели ('ols', 'ridge', 'lasso')\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Таблица с оценками и CI для каждого коэффициента\n",
        "    \"\"\"\n",
        "    # TODO: Для каждой итерации обучить модель на бутстреп-выборке\n",
        "    # TODO: Сохранить коэффициенты\n",
        "    # TODO: Вычислить процентильные CI для каждого коэффициента\n",
        "    # TODO: Построить violin plots для важных коэффициентов\n",
        "    pass\n",
        "\n",
        "\n",
        "def bootstrap_model_comparison(\n",
        "    X: pd.DataFrame,\n",
        "    y: np.ndarray,\n",
        "    model1_func: callable,\n",
        "    model2_func: callable,\n",
        "    metric_func: callable,\n",
        "    n_bootstrap: int = 1000,\n",
        "    confidence_level: float = 0.95\n",
        ") -> Dict[str, Union[float, np.ndarray]]:\n",
        "    \"\"\"\n",
        "    Бутстреп сравнение двух моделей\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X, y : данные\n",
        "    model1_func, model2_func : callable\n",
        "        Функции обучения моделей\n",
        "    metric_func : callable\n",
        "        Функция метрики\n",
        "    n_bootstrap : int\n",
        "        Число итераций\n",
        "    confidence_level : float\n",
        "        Уровень доверия\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict\n",
        "        Статистики разницы метрик и CI\n",
        "    \"\"\"\n",
        "    # TODO: Для каждой итерации:\n",
        "    #   - Сформировать бутстреп-выборку\n",
        "    #   - Обучить обе модели\n",
        "    #   - Вычислить разницу метрик\n",
        "    # TODO: Вычислить CI для разницы\n",
        "    # TODO: Тест: включает ли CI ноль?\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f91e8314",
      "metadata": {
        "id": "f91e8314"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ПЕРЕСТАНОВОЧНЫЕ ТЕСТЫ\n",
        "# =============================================================================\n",
        "\n",
        "def permutation_test(\n",
        "    X: pd.DataFrame,\n",
        "    y: np.ndarray,\n",
        "    test_statistic_func: callable,\n",
        "    n_permutations: int = 1000,\n",
        "    alternative: str = 'two-sided',\n",
        "    random_state: int = RANDOM_STATE\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Перестановочный тест для статистики\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pd.DataFrame\n",
        "        Матрица признаков\n",
        "    y : np.ndarray\n",
        "        Целевая переменная\n",
        "    test_statistic_func : callable\n",
        "        Функция вычисления статистики (принимает X, y)\n",
        "    n_permutations : int\n",
        "        Число перестановок\n",
        "    alternative : str\n",
        "        'two-sided', 'greater', 'less'\n",
        "    random_state : int\n",
        "        Зерно\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, float]\n",
        "        observed_statistic, p_value, permuted_statistics\n",
        "    \"\"\"\n",
        "    # TODO: Вычислить наблюдаемую статистику\n",
        "    # TODO: Для каждой перестановки:\n",
        "    #   - Перемешать y (или X, в зависимости от теста)\n",
        "    #   - Вычислить статистику на перемешанных данных\n",
        "    # TODO: Вычислить p-value: (1 + #{|T_perm| >= |T_obs|}) / (1 + n_perm)\n",
        "    # TODO: Построить гистограмму нулевого распределения\n",
        "    pass\n",
        "\n",
        "\n",
        "def permutation_test_model_difference(\n",
        "    X: pd.DataFrame,\n",
        "    y: np.ndarray,\n",
        "    model1_func: callable,\n",
        "    model2_func: callable,\n",
        "    metric_func: callable,\n",
        "    n_permutations: int = 1000,\n",
        "    cv_folds: int = 5\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Перестановочный тест для разницы метрик двух моделей\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X, y : данные\n",
        "    model1_func, model2_func : callable\n",
        "        Функции обучения моделей\n",
        "    metric_func : callable\n",
        "        Функция метрики\n",
        "    n_permutations : int\n",
        "        Число перестановок\n",
        "    cv_folds : int\n",
        "        Число фолдов для CV\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, float]\n",
        "        observed_diff, p_value\n",
        "    \"\"\"\n",
        "    # TODO: Вычислить разницу метрик на исходных данных (с CV)\n",
        "    # TODO: Для каждой перестановки:\n",
        "    #   - Перемешать y\n",
        "    #   - Вычислить разницу метрик с CV\n",
        "    # TODO: Вычислить p-value\n",
        "    pass\n",
        "\n",
        "\n",
        "def permutation_feature_importance(\n",
        "    X: pd.DataFrame,\n",
        "    y: np.ndarray,\n",
        "    model_func: callable,\n",
        "    metric_func: callable,\n",
        "    n_permutations: int = 100\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Вычислить важность признаков через перестановки\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pd.DataFrame\n",
        "        Матрица признаков\n",
        "    y : np.ndarray\n",
        "        Целевая переменная\n",
        "    model_func : callable\n",
        "        Функция обучения модели\n",
        "    metric_func : callable\n",
        "        Функция метрики (чем выше, тем лучше)\n",
        "    n_permutations : int\n",
        "        Число перестановок для каждого признака\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Важность каждого признака (снижение метрики)\n",
        "    \"\"\"\n",
        "    # TODO: Обучить базовую модель, вычислить базовую метрику\n",
        "    # TODO: Для каждого признака:\n",
        "    #   - Перемешать значения признака\n",
        "    #   - Вычислить метрику с перемешанным признаком\n",
        "    #   - Важность = (base_metric - permuted_metric)\n",
        "    # TODO: Усреднить по перестановкам\n",
        "    # TODO: Построить bar plot важности\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "111d1635",
      "metadata": {
        "id": "111d1635"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# КРОСС-ВАЛИДАЦИЯ И ОЦЕНКА МОДЕЛЕЙ\n",
        "# =============================================================================\n",
        "\n",
        "def cross_validate_models(\n",
        "    X: pd.DataFrame,\n",
        "    y: np.ndarray,\n",
        "    models: Dict[str, callable],\n",
        "    cv: int = 5,\n",
        "    scoring: List[str] = ['neg_mean_squared_error', 'r2']\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Кросс-валидация нескольких моделей\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : pd.DataFrame\n",
        "        Матрица признаков\n",
        "    y : np.ndarray\n",
        "        Целевая переменная\n",
        "    models : Dict[str, callable]\n",
        "        Словарь {название: модель}\n",
        "    cv : int\n",
        "        Число фолдов\n",
        "    scoring : List[str]\n",
        "        Список метрик\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Результаты CV для каждой модели и метрики\n",
        "    \"\"\"\n",
        "    # TODO: Для каждой модели выполнить cross_val_score\n",
        "    # TODO: Вычислить среднее и std по фолдам\n",
        "    # TODO: Вернуть сводную таблицу\n",
        "    pass\n",
        "\n",
        "\n",
        "def evaluate_model_on_test(\n",
        "    model,\n",
        "    X_train: pd.DataFrame,\n",
        "    y_train: np.ndarray,\n",
        "    X_test: pd.DataFrame,\n",
        "    y_test: np.ndarray\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Оценить модель на тестовой выборке\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : обучаемая модель\n",
        "    X_train, y_train : обучающая выборка\n",
        "    X_test, y_test : тестовая выборка\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, float]\n",
        "        Метрики (RMSE, MAE, R², MAPE)\n",
        "    \"\"\"\n",
        "    # TODO: Обучить модель на train\n",
        "    # TODO: Сделать предсказания на test\n",
        "    # TODO: Вычислить метрики\n",
        "    # TODO: Построить actual vs predicted plot\n",
        "    # TODO: Построить residual plot\n",
        "    pass\n",
        "\n",
        "\n",
        "def plot_learning_curves(\n",
        "    model,\n",
        "    X: pd.DataFrame,\n",
        "    y: np.ndarray,\n",
        "    train_sizes: np.ndarray = np.linspace(0.1, 1.0, 10),\n",
        "    cv: int = 5\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Построить кривые обучения\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : обучаемая модель\n",
        "    X, y : данные\n",
        "    train_sizes : np.ndarray\n",
        "        Доли обучающей выборки\n",
        "    cv : int\n",
        "        Число фолдов\n",
        "    \"\"\"\n",
        "    # TODO: Использовать sklearn.model_selection.learning_curve\n",
        "    # TODO: Построить графики train/validation scores vs sample size\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45a51ade",
      "metadata": {
        "id": "45a51ade"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ВИЗУАЛИЗАЦИЯ И ОТЧЁТНОСТЬ\n",
        "# =============================================================================\n",
        "\n",
        "def plot_residual_diagnostics\n",
        "    \"\"\"\n",
        "    Построить диагностические графики остатков\n",
        "\n",
        "\n",
        "\n",
        "def create_coefficient_table\n",
        "\n",
        "    \"\"\"\n",
        "    Создать сводную таблицу коэффициентов\n",
        "\n",
        "\n",
        "\n",
        "def plot_model_comparison_summary\n",
        "\n",
        "    \"\"\"\n",
        "    Визуализировать сравнение моделей по метрикам\n",
        "\n",
        "\n",
        "\n",
        "def generate_summary_report\n",
        "\n",
        "    Сгенерировать текстовый отчёт с результатами\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cebc0e68",
      "metadata": {
        "id": "cebc0e68"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ОСНОВНОЙ ПАЙПЛАЙН\n",
        "# =============================================================================\n",
        "\n",
        "def run_full_analysis_pipeline\n",
        "(\n",
        "  . . .\n",
        "\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Выполнить полный анализ по лабораторной работе\n",
        "\n",
        "    Этапы:\n",
        "    1. Загрузка и предобработка данных\n",
        "    2. OLS модель и диагностика\n",
        "    .\n",
        "    .\n",
        "    .\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset_name : str\n",
        "        Название датасета\n",
        "    target_col : str\n",
        "        Целевая переменная\n",
        "   .\n",
        "   .\n",
        "   .\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict\n",
        "        Словарь со всеми результатами анализа\n",
        "    \"\"\"\n",
        "    # TODO: Реализовать полный пайплайн согласно требованиям ЛР\n",
        "    # TODO: Сохранить все графики в output_dir\n",
        "    # TODO: Сохранить таблицы результатов\n",
        "    # TODO: Сгенерировать итоговый отчёт\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cb5c77b",
      "metadata": {
        "id": "9cb5c77b"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ\n",
        "# =============================================================================\n",
        "\n",
        "def set_plot_style() -> None:\n",
        "    \"\"\"Установить стиль графиков\"\"\"\n",
        "    plt.style.use('seaborn-v0_8-darkgrid')\n",
        "    sns.set_palette(\"husl\")\n",
        "    plt.rcParams['figure.figsize'] = (12, 6)\n",
        "    plt.rcParams['font.size'] = 10\n",
        "\n",
        "\n",
        "def save_figure(fig, filename: str, output_dir: str = 'results') -> None:\n",
        "    \"\"\"Сохранить фигуру\"\"\"\n",
        "    import os\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    fig.savefig(os.path.join(output_dir, filename), dpi=300, bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def print_section_header(title: str) -> None:\n",
        "    \"\"\"Вывести заголовок раздела\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"  {title}\")\n",
        "    print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1217de0",
      "metadata": {
        "id": "a1217de0"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Утилиты для загрузки и предобработки конкретных датасетов\n",
        "Лабораторная работа 2\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# NYC TAXI DATA (D1)\n",
        "# =============================================================================\n",
        "\n",
        "class NYCTaxiLoader:\n",
        "    \"\"\"Загрузчик и обработчик данных NYC Taxi\"\"\"\n",
        "\n",
        "    # Словарь зон TLC -> Borough\n",
        "    # TODO: Заполнить полный маппинг из taxi_zone_lookup.csv\n",
        "    ZONE_TO_BOROUGH = {\n",
        "        # Примеры (не полный список!)\n",
        "        4: 'Manhattan',\n",
        "        12: 'Manhattan',\n",
        "        13: 'Manhattan',\n",
        "        24: 'Manhattan',\n",
        "        41: 'Manhattan',\n",
        "        42: 'Manhattan',\n",
        "        43: 'Manhattan',\n",
        "        48: 'Manhattan',\n",
        "        50: 'Manhattan',\n",
        "        68: 'Manhattan',\n",
        "        74: 'Manhattan',\n",
        "        75: 'Manhattan',\n",
        "        79: 'Brooklyn',\n",
        "        80: 'Brooklyn',\n",
        "        # ... дополнить остальные зоны\n",
        "    }\n",
        "\n",
        "    @staticmethod\n",
        "    def load_nyc_taxi_parquet(\n",
        "        filepath: str,\n",
        "        sample_size: Optional[int] = None,\n",
        "        year: int = 2019,\n",
        "        month: int = 1\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Загрузить NYC Taxi данные из Parquet\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        filepath : str\n",
        "            Путь к .parquet файлу\n",
        "        sample_size : Optional[int]\n",
        "            Размер случайной выборки\n",
        "        year : int\n",
        "            Год данных (для фильтрации)\n",
        "        month : int\n",
        "            Месяц данных (для фильтрации)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "        \"\"\"\n",
        "        # TODO: Загрузить parquet\n",
        "        # df = pd.read_parquet(filepath)\n",
        "\n",
        "        # TODO: Фильтровать по дате если нужно\n",
        "        # df = df[(df['pickup_datetime'].dt.year == year) &\n",
        "        #         (df['pickup_datetime'].dt.month == month)]\n",
        "\n",
        "        # TODO: Случайная выборка\n",
        "        # if sample_size and len(df) > sample_size:\n",
        "        #     df = df.sample(n=sample_size, random_state=42)\n",
        "\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def clean_nyc_taxi(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Очистить данные от аномалий\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Сырые данные\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            Очищенные данные\n",
        "        \"\"\"\n",
        "        df_clean = df.copy()\n",
        "\n",
        "        # TODO: Удалить аномальные значения\n",
        "        # - Негативные или нулевые fare_amount\n",
        "        # df_clean = df_clean[df_clean['fare_amount'] > 0]\n",
        "\n",
        "        # - Негативные или слишком большие trip_distance\n",
        "        # df_clean = df_clean[(df_clean['trip_distance'] > 0) &\n",
        "        #                     (df_clean['trip_distance'] < 100)]\n",
        "\n",
        "        # - Негативные чаевые\n",
        "        # df_clean = df_clean[df_clean['tip_amount'] >= 0]\n",
        "\n",
        "        # - Аномально большие суммы\n",
        "        # df_clean = df_clean[df_clean['total_amount'] < 500]\n",
        "\n",
        "        # - Пассажиры: 1-6\n",
        "        # df_clean = df_clean[(df_clean['passenger_count'] >= 1) &\n",
        "        #                     (df_clean['passenger_count'] <= 6)]\n",
        "\n",
        "        # TODO: Удалить поездки с аномальной длительностью\n",
        "        # df_clean['duration_min'] = (df_clean['tpep_dropoff_datetime'] -\n",
        "        #                             df_clean['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
        "        # df_clean = df_clean[(df_clean['duration_min'] > 1) &\n",
        "        #                     (df_clean['duration_min'] < 180)]\n",
        "\n",
        "        return df_clean\n",
        "\n",
        "    @staticmethod\n",
        "    def add_temporal_features(df: pd.DataFrame, datetime_col: str = 'tpep_pickup_datetime') -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Добавить временные признаки\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Данные\n",
        "        datetime_col : str\n",
        "            Название колонки с datetime\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "        \"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # TODO: Извлечь компоненты времени\n",
        "        # df['hour'] = df[datetime_col].dt.hour\n",
        "        # df['day_of_week'] = df[datetime_col].dt.dayofweek\n",
        "        # df['day_of_month'] = df[datetime_col].dt.day\n",
        "        # df['month'] = df[datetime_col].dt.month\n",
        "        # df['year'] = df[datetime_col].dt.year\n",
        "\n",
        "        # TODO: Категориальные признаки времени\n",
        "        # df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
        "        # df['is_rush_hour'] = ((df['hour'].between(7, 9)) |\n",
        "        #                       (df['hour'].between(17, 19))).astype(int)\n",
        "        # df['time_of_day'] = pd.cut(df['hour'],\n",
        "        #                             bins=[0, 6, 12, 18, 24],\n",
        "        #                             labels=['Night', 'Morning', 'Afternoon', 'Evening'])\n",
        "\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def add_borough_feature(df: pd.DataFrame, zone_col: str = 'PULocationID') -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Добавить признак Borough из LocationID\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Данные\n",
        "        zone_col : str\n",
        "            Название колонки с LocationID\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "        \"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # TODO: Маппинг через ZONE_TO_BOROUGH\n",
        "        # df['borough'] = df[zone_col].map(NYCTaxiLoader.ZONE_TO_BOROUGH)\n",
        "        # df['borough'] = df['borough'].fillna('Unknown')\n",
        "\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_trip_duration(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Вычислить длительность поездки\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Данные с pickup и dropoff datetime\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "        \"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # TODO: Вычислить в минутах\n",
        "        # df['trip_duration'] = (df['tpep_dropoff_datetime'] -\n",
        "        #                        df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# OLIST E-COMMERCE DATA (D3)\n",
        "# =============================================================================\n",
        "\n",
        "class OlistLoader:\n",
        "    \"\"\"Загрузчик и обработчик данных Olist\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_olist_tables(data_dir: str) -> Dict[str, pd.DataFrame]:\n",
        "        \"\"\"\n",
        "        Загрузить все таблицы Olist\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data_dir : str\n",
        "            Директория с CSV файлами\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict[str, pd.DataFrame]\n",
        "            Словарь таблиц\n",
        "        \"\"\"\n",
        "        tables = {}\n",
        "\n",
        "        # TODO: Загрузить каждую таблицу\n",
        "        # tables['orders'] = pd.read_csv(f'{data_dir}/olist_orders_dataset.csv')\n",
        "        # tables['order_items'] = pd.read_csv(f'{data_dir}/olist_order_items_dataset.csv')\n",
        "        # tables['order_payments'] = pd.read_csv(f'{data_dir}/olist_order_payments_dataset.csv')\n",
        "        # tables['products'] = pd.read_csv(f'{data_dir}/olist_products_dataset.csv')\n",
        "        # tables['sellers'] = pd.read_csv(f'{data_dir}/olist_sellers_dataset.csv')\n",
        "        # tables['customers'] = pd.read_csv(f'{data_dir}/olist_customers_dataset.csv')\n",
        "        # tables['geolocation'] = pd.read_csv(f'{data_dir}/olist_geolocation_dataset.csv')\n",
        "        # tables['product_category_name_translation'] = pd.read_csv(\n",
        "        #     f'{data_dir}/product_category_name_translation.csv'\n",
        "        # )\n",
        "\n",
        "        return tables\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_olist_data(tables: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Объединить таблицы Olist в единый датафрейм\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        tables : Dict[str, pd.DataFrame]\n",
        "            Словарь загруженных таблиц\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            Объединённые данные на уровне заказа\n",
        "        \"\"\"\n",
        "        # TODO: Начать с orders\n",
        "        # df = tables['orders'].copy()\n",
        "\n",
        "        # TODO: Join order_items\n",
        "        # df = df.merge(tables['order_items'], on='order_id', how='left')\n",
        "\n",
        "        # TODO: Join payments (агрегировать по order_id)\n",
        "        # payments_agg = tables['order_payments'].groupby('order_id').agg({\n",
        "        #     'payment_value': 'sum',\n",
        "        #     'payment_installments': 'mean'\n",
        "        # }).reset_index()\n",
        "        # df = df.merge(payments_agg, on='order_id', how='left')\n",
        "\n",
        "        # TODO: Join products\n",
        "        # df = df.merge(tables['products'], on='product_id', how='left')\n",
        "\n",
        "        # TODO: Join sellers\n",
        "        # df = df.merge(tables['sellers'], on='seller_id', how='left')\n",
        "\n",
        "        # TODO: Translate category names\n",
        "        # df = df.merge(tables['product_category_name_translation'],\n",
        "        #               on='product_category_name', how='left')\n",
        "\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_olist_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Вычислить производные признаки для Olist\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Объединённые данные\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "        \"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # TODO: GMV (Gross Merchandise Value)\n",
        "        # df['gmv'] = df.groupby('order_id')['price'].transform('sum')\n",
        "\n",
        "        # TODO: Delivery time\n",
        "        # df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
        "        # df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
        "        # df['delivery_time'] = (df['order_delivered_customer_date'] -\n",
        "        #                        df['order_purchase_timestamp']).dt.days\n",
        "\n",
        "        # TODO: Delivery delay\n",
        "        # df['order_estimated_delivery_date'] = pd.to_datetime(df['order_estimated_delivery_date'])\n",
        "        # df['delivery_delay'] = (df['order_delivered_customer_date'] -\n",
        "        #                         df['order_estimated_delivery_date']).dt.days\n",
        "\n",
        "        # TODO: Number of items per order\n",
        "        # df['num_items'] = df.groupby('order_id')['order_item_id'].transform('count')\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MOVIELENS DATA (D4)\n",
        "# =============================================================================\n",
        "\n",
        "class MovieLensLoader:\n",
        "    \"\"\"Загрузчик и обработчик данных MovieLens\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_movielens_100k(data_dir: str) -> Dict[str, pd.DataFrame]:\n",
        "        \"\"\"\n",
        "        Загрузить MovieLens 100K данные\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data_dir : str\n",
        "            Директория с файлами\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict[str, pd.DataFrame]\n",
        "            Словарь таблиц\n",
        "        \"\"\"\n",
        "        tables = {}\n",
        "\n",
        "        # TODO: Загрузить ratings (u.data)\n",
        "        # columns_ratings = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "        # tables['ratings'] = pd.read_csv(\n",
        "        #     f'{data_dir}/u.data',\n",
        "        #     sep='\\t',\n",
        "        #     names=columns_ratings\n",
        "        # )\n",
        "\n",
        "        # TODO: Загрузить movies (u.item)\n",
        "        # columns_movies = ['item_id', 'title', 'release_date', 'video_release_date',\n",
        "        #                   'imdb_url'] + [f'genre_{i}' for i in range(19)]\n",
        "        # tables['movies'] = pd.read_csv(\n",
        "        #     f'{data_dir}/u.item',\n",
        "        #     sep='|',\n",
        "        #     names=columns_movies,\n",
        "        #     encoding='latin-1'\n",
        "        # )\n",
        "\n",
        "        # TODO: Загрузить users (u.user)\n",
        "        # columns_users = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
        "        # tables['users'] = pd.read_csv(\n",
        "        #     f'{data_dir}/u.user',\n",
        "        #     sep='|',\n",
        "        #     names=columns_users\n",
        "        # )\n",
        "\n",
        "        return tables\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_movielens_data(tables: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Объединить таблицы MovieLens\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        tables : Dict[str, pd.DataFrame]\n",
        "            Словарь таблиц\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            Объединённые данные\n",
        "        \"\"\"\n",
        "        # TODO: Начать с ratings\n",
        "        # df = tables['ratings'].copy()\n",
        "\n",
        "        # TODO: Join movies\n",
        "        # df = df.merge(tables['movies'], on='item_id', how='left')\n",
        "\n",
        "        # TODO: Join users\n",
        "        # df = df.merge(tables['users'], on='user_id', how='left')\n",
        "\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_movie_year(df: pd.DataFrame, title_col: str = 'title') -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Извлечь год релиза из названия фильма\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Данные с колонкой title\n",
        "        title_col : str\n",
        "            Название колонки с заголовком\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "        \"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # TODO: Извлечь год из названия (обычно в конце в скобках)\n",
        "        # df['year'] = df[title_col].str.extract(r'\\((\\d{4})\\)')\n",
        "        # df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
        "\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def create_genre_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Создать one-hot признаки жанров\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Данные с колонками genre_*\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "        \"\"\"\n",
        "        # TODO: Жанры уже в one-hot формате в u.item\n",
        "        # Можно переименовать для удобства\n",
        "\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_user_movie_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Вычислить агрегированные статистики пользователей и фильмов\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Данные с рейтингами\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "        \"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # TODO: Leave-one-out средний рейтинг фильма\n",
        "        # movie_ratings = df.groupby('item_id')['rating'].transform('sum')\n",
        "        # movie_counts = df.groupby('item_id')['rating'].transform('count')\n",
        "        # df['avg_movie_rating_loo'] = (movie_ratings - df['rating']) / (movie_counts - 1)\n",
        "\n",
        "        # TODO: Активность пользователя\n",
        "        # df['user_activity'] = df.groupby('user_id')['rating'].transform('count')\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# UK ROAD SAFETY DATA - STATS19 (D5)\n",
        "# =============================================================================\n",
        "\n",
        "class STATS19Loader:\n",
        "    \"\"\"Загрузчик и обработчик данных STATS19\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_stats19_csv(filepath: str, year: int = 2017) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Загрузить STATS19 данные\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        filepath : str\n",
        "            Путь к CSV файлу\n",
        "        year : int\n",
        "            Год данных\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "        \"\"\"\n",
        "        # TODO: Загрузить accidents\n",
        "        # df = pd.read_csv(filepath)\n",
        "\n",
        "        # TODO: Фильтровать по году если нужно\n",
        "        # df['date'] = pd.to_datetime(df['date'])\n",
        "        # df = df[df['date'].dt.year == year]\n",
        "\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def create_severity_score(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Создать суррогат серьёзности ДТП\n",
        "\n",
        "        Формула: 10 * fatal + 3 * serious + 1 * slight\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Данные с casualty columns\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "        \"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # TODO: Вычислить взвешенную сумму пострадавших\n",
        "        # df['severity_score'] = (\n",
        "        #     10 * df['number_of_casualties_fatal'] +\n",
        "        #     3 * df['number_of_casualties_serious'] +\n",
        "        #     1 * df['number_of_casualties_slight']\n",
        "        # )\n",
        "\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def encode_categorical_stats19(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Закодировать категориальные признаки\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Сырые данные\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "        \"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # TODO: Weather conditions\n",
        "        # weather_mapping = {\n",
        "        #     1: 'Fine',\n",
        "        #     2: 'Raining',\n",
        "        #     3: 'Snowing',\n",
        "        #     4: 'Fine + high winds',\n",
        "        #     5: 'Raining + high winds',\n",
        "        #     6: 'Snowing + high winds',\n",
        "        #     7: 'Fog or mist',\n",
        "        #     8: 'Other',\n",
        "        #     9: 'Unknown'\n",
        "        # }\n",
        "        # df['weather_conditions'] = df['weather_conditions'].map(weather_mapping)\n",
        "\n",
        "        # TODO: Light conditions\n",
        "        # TODO: Road type\n",
        "        # TODO: Junction detail\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CHICAGO TAXI DATA (D2)\n",
        "# =============================================================================\n",
        "\n",
        "class ChicagoTaxiLoader:\n",
        "    \"\"\"Загрузчик и обработчик данных Chicago Taxi\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_chicago_taxi_csv(filepath: str, sample_size: Optional[int] = None) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Загрузить Chicago Taxi данные\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        filepath : str\n",
        "            Путь к CSV файлу\n",
        "        sample_size : Optional[int]\n",
        "            Размер выборки\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "        \"\"\"\n",
        "        # TODO: Загрузить данные\n",
        "        # df = pd.read_csv(filepath)\n",
        "\n",
        "        # TODO: Парсинг дат\n",
        "        # df['trip_start_timestamp'] = pd.to_datetime(df['trip_start_timestamp'])\n",
        "        # df['trip_end_timestamp'] = pd.to_datetime(df['trip_end_timestamp'])\n",
        "\n",
        "        # TODO: Случайная выборка\n",
        "        # if sample_size and len(df) > sample_size:\n",
        "        #     df = df.sample(n=sample_size, random_state=42)\n",
        "\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def clean_chicago_taxi(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Очистить данные Chicago Taxi\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Сырые данные\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "        \"\"\"\n",
        "        df_clean = df.copy()\n",
        "\n",
        "        # TODO: Удалить аномалии\n",
        "        # - Негативные fare\n",
        "        # - Нулевые trip_miles/trip_seconds\n",
        "        # - Аномально большие значения\n",
        "\n",
        "        return df_clean"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}