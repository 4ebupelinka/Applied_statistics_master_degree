{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4f4658",
   "metadata": {
    "id": "ad4f4658"
   },
   "source": [
    "\n",
    "# Лабораторная работа 3. Вывод для высокоразмерных и неструктурированных данных. Оценка доверия: bootstrap, permutation, cross-validation. Интерпретация: feature importance, SHAP, causal inference.\n",
    "\n",
    "\n",
    "**Курс:** Прикладная статистика и анализ данных\n",
    "\n",
    "**Раздел 3:** Авангардные подходы для ИИ и доверие к моделям    \n",
    "\n",
    "**Цель:** Построить полный цикл надёжного статистического моделирования: от корректного выбора протокола кросс-валидации и конфигурации модели до интерпретации результатов (feature importance/SHAP), причинной аргументации (DAG, эффекты вмешательств) и репликации внешних результатов в воспроизводимой среде.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd09b5",
   "metadata": {
    "id": "28dd09b5"
   },
   "source": [
    "## 1. Данные и дизайн эксперимента\n",
    "Набор данных представляет собой наблюдения вида $(x_i, y_i)$, где $x_i$ — вектор признаков (количественных и/или категориальных), а $y_i$ — целевая переменная (например, числовой показатель эффективности, выручки или другого экономического/технического результата). Предполагается, что данные получены из стационарного источника и могут рассматриваться как реализация выборки из некоторого (неизвестного) распределения. На этапе предобработки выполняются базовые шаги: удаление или обработка пропусков, кодирование категориальных переменных, при необходимости масштабирование числовых признаков, а также выделение обучающей и тестовой подвыборок.\n",
    "\n",
    "Цель эксперимента — не только построить предсказательную модель, но и провести статистический вывод относительно её характеристик и структуры. Для этого в работе используется несколько классов моделей (как минимум одна «прозрачная» базовая модель и одна более сложная модель), обучаемых на обучающей выборке. Тестовая выборка откладывается и используется для оценки обобщающей способности моделей и для последующей интерпретации результатов.\n",
    "\n",
    "Дизайн эксперимента включает три ключевых компонента. Во-первых, для оценки неопределённости метрик качества и параметров моделей применяется бутстреп по объектам: из исходной обучающей выборки многократно формируются бутстреп-выборки, на каждой из которых переобучается модель и вычисляются интересующие статистики (например, $R^2$, MSE, разности ошибок моделей). Полученное эмпирическое распределение статистики используется для построения доверительных интервалов. Во-вторых, для проверки гипотез о значимости различий между моделями и/или признаками применяются перестановочные тесты, основанные на многократной перестановке меток или отдельных признаков и сравнении наблюдаемой статистики с её нулевым распределением. В-третьих, для анализа структуры модели и вклада отдельных признаков используются модель-агностические методы интерпретации: перестановочная важность признаков и SHAP-значения. Перестановочная важность вычисляется как изменение метрики качества при искусственном «разрушении» связи признака с целевой переменной, тогда как SHAP-значения позволяют получить аддитивное разложение предсказаний на уровне отдельных наблюдений. Совокупно такой дизайн эксперимента обеспечивает не только оценку качества моделей, но и количественно обоснованную интерпретацию полученных результатов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb347b5b",
   "metadata": {
    "id": "eb347b5b"
   },
   "source": [
    "## 2. Статистический вывод и доверительные интервалы в высокоразмерных задачах\n",
    "\n",
    "Статистический вывод в контексте высокоразмерных и неструктурированных данных нацелен на переход от наблюдаемой выборки к утверждениям о генеративном механизме данных. Пусть наблюдается выборка $Y_1,\\dots,Y_n$ с признаками $X_1,\\dots,X_n$, а интересующий параметр обозначен как $\\theta$ (например, коэффициент регрессии, средний эффект вмешательства или разность предсказательной ошибки двух моделей). Точечная оценка $\\hat\\theta$ сама по себе малоинформативна без понимания её неопределённости. Поэтому ключевыми объектами статистического вывода являются доверительные интервалы для $\\theta$ и процедуры проверки гипотез вида $H_0:\\theta=\\theta_0$ против альтернатив $H_1$.\n",
    "\n",
    "В классической низкоразмерной ситуации неопределённость оценки выводится из теоретического распределения статистики. Например, для линейной регрессии при стандартных предположениях используется асимптотическая нормальность оценок МНК и формула доверительного интервала\n",
    "$\n",
    "CI_{1-\\alpha}(\\theta)=\\hat\\theta \\pm z_{1-\\alpha/2},\\widehat{\\mathrm{se}}(\\hat\\theta),\n",
    "$\n",
    "где $\\widehat{\\mathrm{se}}(\\hat\\theta)$ — оценка стандартной ошибки, а $z_{1-\\alpha/2}$ — квантиль стандартного нормального распределения. В высокоразмерных задачах, с большим числом признаков и сложными моделями (градиентный бустинг, случайные леса, нейросети), аналитическое выражение для распределения $\\hat\\theta$ либо отсутствует, либо опирается на заведомо нарушенные предположения (нормальность ошибок, гомоскедастичность, независимость наблюдений).\n",
    "\n",
    "Дополнительная сложность связана с тем, что нас обычно интересуют не только «параметры» внутри модели, но и функционалы от модели: предсказательная ошибка $Q(f)$ на новых данных, разница ошибок $\\Delta Q$ двух моделей, частные эффекты признаков, меры справедливости и устойчивости. Все эти величины представляют собой статистики $T(Y,X)$ со сложной зависимостью от данных. Для них традиционные формулы стандартных ошибок часто просто отсутствуют.\n",
    "\n",
    "Современный подход к выводу в таких условиях опирается на аппроксимацию выборочного распределения статистики с помощью методов ресемплинга. Основная идея состоит в том, чтобы искусственно сгенерировать множество «альтернативных выборок», совместимых с наблюдаемыми данными и нулевой гипотезой, и по ним эмпирически оценить распределение $T$. На этой логике основаны бутстреп-процедуры и перестановочные тесты, которые позволяют строить доверительные интервалы и p-значения без жёсткой привязки к параметрическим предположениям о распределении ошибок.\n",
    "\n",
    "Наконец, в высокоразмерных задачах особую роль играют вопросы воспроизводимости. При оценке доверительных интервалов и p-значений важно фиксировать генераторы случайных чисел, сохранять индексы ресемплированных наблюдений и чётко документировать выбранные настройки (число репликаций, тип интервалов, способ формирования статистики). Это позволяет повторно получить те же выводы, сравнивать их при изменении модели и использовать результаты как часть формальной доказательной базы при принятии решений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12536dc9",
   "metadata": {
    "id": "12536dc9"
   },
   "source": [
    "## 3. Бутстреп и перестановочные тесты: оценка неопределённости без сильных предположений\n",
    "\n",
    "Бутстреп — это общий подход к оценке неопределённости статистики $T(Y,X)$ посредством многократного ресемплинга из наблюдаемой выборки. В простейшей непараметрической версии бутстрепа предполагается, что эмпирическое распределение данных достаточно хорошо аппроксимирует истинное распределение. Тогда, вместо работы с теоретическим распределением, мы многократно генерируем бутстреп-выборки $Y_1^\\ast,\\dots,Y_n^\\ast$ путём выборки с возвращением из исходных наблюдений $(Y_1,\\dots,Y_n)$. Для каждой репликации $b=1,\\dots,B$ вычисляется статистика $T^{\\ast}_b$, после чего эмпирическое распределение ${T^{\\ast}b}{b=1}^B$ служит приближением выборочного распределения $T$.\n",
    "\n",
    "На основе бутстреп-распределения легко строятся доверительные интервалы. Наиболее простой вариант — процентильный бутстреп: интервал уровня $1-\\alpha$ задаётся как $[q_{\\alpha/2},q_{1-\\alpha/2}]$, где $q_{p}$ — $p$-квантиль эмпирического распределения ${T^{\\ast}_b}$. Более продвинутые варианты (BC, BCa) дополнительно корректируют смещение и асимметрию распределения. Бутстреп удобно применять для сложных статистик: разности ошибок двух моделей, медианы, коэффициентов в регуляризованных регрессиях, показателей справедливости.\n",
    "\n",
    "Перестановочные тесты (randomization / permutation tests) решают родственную, но концептуально отличную задачу. Здесь формируется нулевая гипотеза о том, что метки или группы в данных взаимозаменяемы (exchangeable) при $H_0$. Например, при сравнении двух групп предполагается, что распределения в группах совпадают, и различие средних обусловлено лишь случайной разметкой наблюдений. Тестовая статистика $T_{\\text{obs}}$ (разность средних, статистика $t$, разность ошибок моделей и т.п.) вычисляется на исходных данных. Далее значения меток многократно случайно переставляются, при каждой перестановке пересчитывается $T^{\\pi}_b$, и распределение ${T^{\\pi}_b}$ используется как референс-распределение при $H_0$. p-значение оценивается как доля перестановок с $|T^{\\pi}b|\\ge|T{\\text{obs}}|$.\n",
    "\n",
    "Принципиальное различие между бутстрепом и перестановочными тестами состоит в том, что бутстреп нацелен на оценку параметров и их неопределённости, тогда как перестановка фокусируется на проверке гипотез о распределениях и структуре связи (например, наличии систематического эффекта модели или вмешательства). В практических задачах ЛР3 оба подхода используются совместно: бутстреп позволяет строить доверительные интервалы для метрик качества и важности признаков, а перестановочные тесты — проверять значимость различий между моделями и устойчивость выявленных связей при минимуме параметрических допущений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22259257",
   "metadata": {
    "id": "22259257"
   },
   "source": [
    "## 4. Важность признаков и глобальная интерпретируемость сложных моделей\n",
    "\n",
    "При работе с высокоразмерными данными и сложными моделями $f(x)$ (ансамбли деревьев, бустинг, нейросети) ключевым вопросом становится оценка вклада отдельных признаков в предсказание. Под важностью признака в глобальном смысле обычно понимают меру того, насколько использование данного признака улучшает некоторый показатель качества модели, усреднённый по распределению входных данных. Глобальная интерпретируемость отвечает на вопрос «какие признаки в среднем наиболее влиятельны для предсказаний на всей выборке», в отличие от локальных методов, анализирующих одно конкретное наблюдение.\n",
    "\n",
    "В простых моделях (линейная регрессия, логистическая регрессия) в роли меры важности часто выступают стандартизованные коэффициенты, отношения шансов или t-статистики. Однако в нелинейных моделях такие прямые интерпретации отсутствуют, а сами параметры не имеют однозначного смыслового сопоставления между моделями. Поэтому используются специальные меры важности: основанные на структуре модели (например, сумма уменьшений импьюрити в деревьях решений) и модель-агностические. Модель-агностические подходы определяют важность через изменение предсказательной ошибки при искусственном «выключении» или искажении признака.\n",
    "\n",
    "Наиболее распространённый модель-агностический подход — перестановочная важность (permutation importance). Для признака $j$ строится модифицированный набор $X^{\\pi(j)}$, в котором значения $x_j$ случайно переставлены по наблюдениям, разрушая связь этого признака с целевой переменной, но сохраняя его маргинальное распределение. Модель $f$ применяют к $X$ и $X^{\\pi(j)}$, после чего важность определяют как\n",
    "$\n",
    "\\mathrm{Imp}(j) = Q(f;X,y) - Q(f;X^{\\pi(j)},y),\n",
    "$\n",
    "где $Q$ — выбранная метрика качества (например, $R^2$, AUC, лог-лосс). Чем сильнее ухудшается качество при перестановке, тем более важен признак. Повторение процедуры с несколькими случайными перестановками позволяет оценить стандартизированную важность и доверительные интервалы.\n",
    "\n",
    "Перестановочная важность удобна тем, что применима к любой «чёрной коробке» и может быть одинаково реализована для деревьев, бустинга и нейросетей. Однако у метода есть ограничения: при сильной корреляции признаков их важность может «размазываться» между группой связанных признаков; возможно появление отрицательной важности при переобучении или некорректной оценке качества. Поэтому в ЛР3 важно не только вычислить важности, но и сопоставить их с предметным смыслом признаков, проверить устойчивость результатов к изменению метрики и способа разбиения выборки, а также при необходимости применять групповые перестановки для логически связанных наборов признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de13612",
   "metadata": {
    "id": "8de13612"
   },
   "source": [
    "## 5. SHAP-значения и локальная интерпретация предсказаний\n",
    "\n",
    "Метод SHAP (SHapley Additive exPlanations) основан на переносе идей кооперативной теории игр в контекст интерпретации моделей машинного обучения. Рассматривается множество признаков $F={1,\\dots,p}$ как набор «игроков», совместно формирующих «стоимость» — предсказание модели $f(x)$. Для каждого признака $j$ вводится его вклад $\\phi_j(x)$ в предсказание для конкретного наблюдения $x$. Идея состоит в том, чтобы определять $\\phi_j(x)$ как усреднённый маргинальный вклад признака $j$ при присоединении его к всевозможным подмножествам $S\\subseteq F\\setminus{j}$:\n",
    "\n",
    "$\n",
    "\\phi_j(x)=\\sum_{S\\subseteq F\\setminus{j}} \\frac{|S|!,(|F|-|S|-1)!}{|F|!} \\left[v_x(S\\cup{j})-v_x(S)\\right],\n",
    "$\n",
    "\n",
    "где $v_x(S)$ — «значение коалиции» $S$, интерпретируемое как ожидаемое предсказание модели при известны только признаки из $S$, а остальные усреднены по их распределению. Такое определение обеспечивает несколько важных свойств: локальную аддитивность (сумма $\\sum_j \\phi_j(x)$ восстанавливает сдвиг между базовым уровнем и предсказанием для $x$), симметрию (равнозначные признаки имеют одинаковые вклады) и согласованность (если модель меняется так, что маргинальный вклад признака растёт во всех контекстах, его SHAP-важность не уменьшается).\n",
    "\n",
    "На практике точное вычисление Шеплиевских значений по формуле выше требует суммирования по всем подмножествам признаков и потому экспоненциально сложно по $p$. Однако для важных классов моделей (в первую очередь деревьев решений и их ансамблей) разработаны эффективные алгоритмы, реализованные, например, в библиотеке SHAP. Эти алгоритмы позволяют вычислять SHAP-значения для каждого наблюдения и признака с полиномиальной сложностью, что делает метод применимым в задачах реального масштаба.\n",
    "\n",
    "Результаты SHAP можно интерпретировать как локальные объяснения предсказаний: для каждого конкретного объекта становится видно, какие признаки «подтягивают» предсказание вверх, а какие — вниз и в каком численном объёме. Агрегируя $|\\phi_j(x_i)|$ по выборке, получают глобальные меры важности признаков, сопоставимые с перестановочной важностью, но обладающие более чёткой теоретической интерпретацией. SHAP-диаграммы (summary plots, dependence plots) позволяют обнаруживать нелинейности, пороговые эффекты и взаимодействия признаков, которые не видны из одних только коэффициентов или глобальных важностей.\n",
    "\n",
    "При этом важно помнить, что SHAP описывает предсказательную модель, а не причинные связи в данных. Высокое по модулю значение $\\phi_j(x)$ означает сильное влияние признака на предсказание $f(x)$ при зафиксированном распределении других признаков, но не гарантирует существование причинного эффекта признака на целевую переменную. Поэтому в ЛР3 следует использовать SHAP совместно с предметным анализом, диаграммами причинно-следственных связей и, при необходимости, специальными методами причинного вывода для наблюдательных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a84beae",
   "metadata": {
    "id": "9a84beae"
   },
   "source": [
    "## 35 вариантов заданий (обобщающие, с привязкой к D1–D10)\n",
    "\n",
    "### Общие методические требования (для всех вариантов):\n",
    "1) Формулировка цели и базовой модели.\n",
    "Для выбранного датасета чётко сформулируйте исследовательский вопрос (что именно прогнозируем/объясняем и зачем) и определите целевую переменную. Постройте базовую модель (часто — линейная регрессия или логистическая регрессия) с ограниченным числом очевидных предикторов. Зафиксируйте набор метрик качества (например, $R^2$, RMSE/MAE для регрессии или ROC-AUC/PR-AUC для классификации), которые будут использоваться в дальнейшем для сравнения моделей.\n",
    "\n",
    "2) Дизайн кросс-валидации и выбор модели.\n",
    "Разработайте протокол кросс-валидации, учитывая природу данных: для i.i.d.-наблюдений — стандартный $K$-fold с стратификацией по целевой переменной (в задачах дисбаланса); для временных рядов и логов — разбиения по времени (rolling/expanding window, TimeSeriesSplit). Обоснуйте выбор числа фолдов, размера обучающего/валидационного окна и схемы повторов. На основе CV подберите гиперпараметры основных моделей (например, коэффициент регуляризации $\\lambda$ в Ridge/Lasso, глубину/число деревьев в бустинге), а также сравните несколько конкурирующих спецификаций.\n",
    "\n",
    "3) Диагностика и интерпретируемость модели.\n",
    "Для выбранной «рабочей» модели выполните анализ важности признаков: пермутационная важность, коэффициенты линейной модели, а также, при возможности, SHAP-значения для глобальной и локальной интерпретации. Сопоставьте результаты разных методов, выделите устойчивое ядро важных факторов и обсудите, насколько они согласуются с доменной логикой. Избегайте прямолинейного причинного толкования: зафиксируйте, что модель в первую очередь предиктивная, и аккуратно отделяйте интерпретацию «ассоциации» от «эффекта».\n",
    "\n",
    "4) Причинно-следственные допущения и сценарии «что-если».\n",
    "Даже если цель работы не в строгой идентификации причинного эффекта, постройте качественную DAG-диаграмму (граф зависимостей) для ключевых переменных, обозначьте предполагаемые конфаундеры, возможные промежуточные и обратные связи. Сформулируйте потенциальный причинный вопрос (например, «как изменится $Y$ при изменении некоторого управляемого фактора $X$?») и обсудите, какие дополнительные данные или экспериментальный дизайн потребовались бы для надёжного вывода. Явно опишите, какие оценки в вашей работе можно трактовать лишь как ассоциативные.\n",
    "\n",
    "5) Оценка неопределённости и устойчивости выводов.\n",
    "Для выбранных моделей и ключевых показателей качества примените бутстреп-процедуры (percentile/BCa) для получения доверительных интервалов для $R^2$, RMSE/MAE или других метрик, а также перестановочные тесты для оценки статистической значимости разницы в качестве между двумя моделями или спецификациями (например, «модель с дополнительными признаками vs. базовая»). В явном виде интерпретируйте интервал и $p$-значение, связывая их с практической значимостью (бизнес, транспорт, медицина и т.д.).\n",
    "\n",
    "6) Репликация и воспроизводимость.\n",
    "Обеспечьте воспроизводимость экспериментов:\n",
    "- зафиксируйте случайные зерна, список версий библиотек и основные параметры среды;\n",
    "- реализуйте весь препроцессинг, разбиения на выборки и обучение моделей внутри единого конвейера (например, Pipeline/ColumnTransformer в scikit-learn или явный код с чёткой структурой);\n",
    "- документируйте шаги: от загрузки данных и фильтраций до построения финальных таблиц и рисунков;\n",
    "- сформируйте краткий протокол репликации (какие файлы/скрипты и в каком порядке запускать, какие внешние источники данных используются).\n",
    "При работе с публичными датасетами (Kaggle, Inside Airbnb и др.) обязательно фиксируйте версию выгрузки (дата скачивания, номер релиза) и, по возможности, сравнивайте свои результаты с опубликованными решениями или статьями, обсуждая причины возможных расхождений.\n",
    "\n",
    "\n",
    "### Вариант\n",
    "Вариант 1. NYC-FareCV (D1)\n",
    "Предсказать итоговую стоимость поездки (total_amount или fare_amount) по данным NYC TLC Yellow Taxi. Сформируйте выборку поездок за один месяц и случайную подвыборку 100 000 наблюдений. Постройте ряд моделей (линейная регрессия, градиентный бустинг, случайный лес) и спроектируйте протокол CV, учитывая неоднородность по времени суток и районам. Сравните K-fold и временную кросс-валидацию (TimeSeriesSplit): оцените различия в оценках RMSE/MAE и прокомментируйте возможное смещение. Затем проведите анализ важности признаков (пермутационная важность и SHAP) для лучшей модели, выделите ключевые факторы тарифа (расстояние, район, час, тип оплаты). Сформулируйте причинную гипотезу об эффекте «час пик/не час пик» на стоимость за милю и постройте упрощённый DAG; обсудите, какие переменные следует контролировать. На этапе репликации выберите внешнее исследование/бенчмарк по NYC Taxi и попытайтесь воспроизвести сопоставимую метрику качества, фиксируя версии библиотек и протокол CV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5cf82a-129b-4eff-a017-37478eb3cf4c",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb3b0701-4484-47ba-a506-e652ea4d6f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный размер: (3574091, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "      <th>cbd_congestion_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-08-01 00:52:23</td>\n",
       "      <td>2025-08-01 01:12:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>33.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.49</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-08-01 00:03:01</td>\n",
       "      <td>2025-08-01 00:15:33</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-08-01 00:24:38</td>\n",
       "      <td>2025-08-01 00:24:38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>249</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.94</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-08-01 00:48:19</td>\n",
       "      <td>2025-08-01 00:48:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.58</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-08-01 00:25:34</td>\n",
       "      <td>2025-08-01 00:33:18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.72</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2025-08-01 00:52:23   2025-08-01 01:12:20              1.0   \n",
       "1         2  2025-08-01 00:03:01   2025-08-01 00:15:33              2.0   \n",
       "2         7  2025-08-01 00:24:38   2025-08-01 00:24:38              2.0   \n",
       "3         7  2025-08-01 00:48:19   2025-08-01 00:48:19              1.0   \n",
       "4         2  2025-08-01 00:25:34   2025-08-01 00:33:18              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           8.44         1.0                  N           138           141   \n",
       "1           4.98         1.0                  N           138           193   \n",
       "2           1.89         1.0                  N           249            45   \n",
       "3           2.35         1.0                  N            79           229   \n",
       "4           2.14         1.0                  N            43            48   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1         33.8    6.0      0.5        5.00          6.94   \n",
       "1             1         21.2    6.0      0.5        0.00          0.00   \n",
       "2             1         14.2    0.0      0.5        3.99          0.00   \n",
       "3             1         11.4    0.0      0.5        3.43          0.00   \n",
       "4             1         11.4    1.0      0.5        2.57          0.00   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \\\n",
       "0                    1.0         57.49                   2.5         1.75   \n",
       "1                    1.0         30.45                   0.0         1.75   \n",
       "2                    1.0         23.94                   2.5         0.00   \n",
       "3                    1.0         20.58                   2.5         0.00   \n",
       "4                    1.0         19.72                   2.5         0.00   \n",
       "\n",
       "   cbd_congestion_fee  \n",
       "0                0.00  \n",
       "1                0.00  \n",
       "2                0.75  \n",
       "3                0.75  \n",
       "4                0.75  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Загружаем данные\n",
    "df = pd.read_parquet(\"yellow_tripdata_2025-08.parquet\")\n",
    "\n",
    "print(\"Исходный размер:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dfb77ff-f2cd-4c49-b36c-0f5092ff4d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер после очистки: (2574569, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-01 00:52:23</td>\n",
       "      <td>2025-08-01 01:12:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.44</td>\n",
       "      <td>138</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>57.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-01 00:03:01</td>\n",
       "      <td>2025-08-01 00:15:33</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.98</td>\n",
       "      <td>138</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>30.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-01 00:24:38</td>\n",
       "      <td>2025-08-01 00:24:38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.89</td>\n",
       "      <td>249</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>23.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-01 00:48:19</td>\n",
       "      <td>2025-08-01 00:48:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>79</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>20.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-08-01 00:25:34</td>\n",
       "      <td>2025-08-01 00:33:18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>19.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  trip_distance  \\\n",
       "0  2025-08-01 00:52:23   2025-08-01 01:12:20              1.0           8.44   \n",
       "1  2025-08-01 00:03:01   2025-08-01 00:15:33              2.0           4.98   \n",
       "2  2025-08-01 00:24:38   2025-08-01 00:24:38              2.0           1.89   \n",
       "3  2025-08-01 00:48:19   2025-08-01 00:48:19              1.0           2.35   \n",
       "4  2025-08-01 00:25:34   2025-08-01 00:33:18              1.0           2.14   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  total_amount  \n",
       "0           138           141             1         57.49  \n",
       "1           138           193             1         30.45  \n",
       "2           249            45             1         23.94  \n",
       "3            79           229             1         20.58  \n",
       "4            43            48             1         19.72  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- 1) Оставляем нужные для модели столбцы -----\n",
    "\n",
    "columns_needed = [\n",
    "    \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\",\n",
    "    \"passenger_count\", \"trip_distance\",\n",
    "    \"PULocationID\", \"DOLocationID\",\n",
    "    \"payment_type\", \"total_amount\"\n",
    "]\n",
    "\n",
    "df = df[columns_needed].copy()\n",
    "\n",
    "# ----- 2) Удаляем строки с NaN по важным признакам -----\n",
    "df = df.dropna(subset=[\"passenger_count\", \"trip_distance\", \"total_amount\"])\n",
    "\n",
    "# ----- 3) Удаляем невозможные значения -----\n",
    "df = df[(df[\"trip_distance\"] > 0) & (df[\"total_amount\"] > 0)]\n",
    "df = df[df[\"trip_distance\"] < 200]       # Физический максимум поездки в NYC\n",
    "df = df[df[\"total_amount\"] < 500]        # Защита от аномально дорогих поездок\n",
    "\n",
    "print(\"Размер после очистки:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4628e02-af2e-4edb-8c75-2e64a562701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Готово!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>trip_duration_min</th>\n",
       "      <th>PULocation_bin</th>\n",
       "      <th>DOLocation_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1</td>\n",
       "      <td>57.49</td>\n",
       "      <td>0</td>\n",
       "      <td>19.950000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.98</td>\n",
       "      <td>1</td>\n",
       "      <td>30.45</td>\n",
       "      <td>0</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1</td>\n",
       "      <td>23.94</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "      <td>20.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1</td>\n",
       "      <td>19.72</td>\n",
       "      <td>0</td>\n",
       "      <td>7.733333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_count  trip_distance  payment_type  total_amount  pickup_hour  \\\n",
       "0              1.0           8.44             1         57.49            0   \n",
       "1              2.0           4.98             1         30.45            0   \n",
       "2              2.0           1.89             1         23.94            0   \n",
       "3              1.0           2.35             1         20.58            0   \n",
       "4              1.0           2.14             1         19.72            0   \n",
       "\n",
       "   trip_duration_min  PULocation_bin  DOLocation_bin  \n",
       "0          19.950000              10              10  \n",
       "1          12.533333              10              14  \n",
       "2           1.000000              18               3  \n",
       "3           1.000000               5              17  \n",
       "4           7.733333               3               3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== Генерация признаков =====\n",
    "\n",
    "# 1) Час поездки\n",
    "df[\"pickup_hour\"] = df[\"tpep_pickup_datetime\"].dt.hour\n",
    "\n",
    "# 2) Продолжительность поездки в минутах\n",
    "df[\"trip_duration_min\"] = (df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]).dt.total_seconds() / 60\n",
    "df[\"trip_duration_min\"] = df[\"trip_duration_min\"].clip(lower=1)\n",
    "\n",
    "# 3) Убираем datetime после извлечения признаков\n",
    "df = df.drop(columns=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "\n",
    "# 4) Бинning для районов по LocationID\n",
    "df[\"PULocation_bin\"] = pd.cut(df[\"PULocationID\"], bins=20, labels=False)\n",
    "df[\"DOLocation_bin\"] = pd.cut(df[\"DOLocationID\"], bins=20, labels=False)\n",
    "\n",
    "# 5) Выбрасываем исходные LocationID\n",
    "df = df.drop(columns=[\"PULocationID\", \"DOLocationID\"])\n",
    "\n",
    "print(\"Готово!\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f93a6e-1e63-4c78-a01a-72a32f279b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер X: (2574569, 7)\n",
      "Размер y: (2574569,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>trip_duration_min</th>\n",
       "      <th>PULocation_bin</th>\n",
       "      <th>DOLocation_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.950000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.733333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_count  trip_distance  payment_type  pickup_hour  \\\n",
       "0              1.0           8.44             1            0   \n",
       "1              2.0           4.98             1            0   \n",
       "2              2.0           1.89             1            0   \n",
       "3              1.0           2.35             1            0   \n",
       "4              1.0           2.14             1            0   \n",
       "\n",
       "   trip_duration_min  PULocation_bin  DOLocation_bin  \n",
       "0          19.950000              10              10  \n",
       "1          12.533333              10              14  \n",
       "2           1.000000              18               3  \n",
       "3           1.000000               5              17  \n",
       "4           7.733333               3               3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== Отделяем y =====\n",
    "y = df[\"total_amount\"].copy()\n",
    "X = df.drop(columns=[\"total_amount\"])\n",
    "\n",
    "print(\"Размер X:\", X.shape)\n",
    "print(\"Размер y:\", y.shape)\n",
    "\n",
    "display(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "912c8f13-2c8b-4b59-8354-803f7c8cb732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Взята подвыборка 100k:\n",
      "Размер X: (100000, 7)\n"
     ]
    }
   ],
   "source": [
    "if len(df) > 100_000:\n",
    "    df_sample = df.sample(100_000, random_state=42)\n",
    "    y = df_sample[\"total_amount\"]\n",
    "    X = df_sample.drop(columns=[\"total_amount\"])\n",
    "    print(\"Взята подвыборка 100k:\")\n",
    "    print(\"Размер X:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549c7ff-9fe3-4380-9d8d-363b03688351",
   "metadata": {},
   "source": [
    "# Предобработка (ColumnTransformer) + Модели (Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e8090a-4bbb-4268-8f29-130feb42d0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонки X: ['passenger_count', 'trip_distance', 'payment_type', 'pickup_hour', 'trip_duration_min', 'PULocation_bin', 'DOLocation_bin']\n",
      "Числовые признаки: ['passenger_count', 'trip_distance', 'pickup_hour', 'trip_duration_min']\n",
      "Категориальные признаки: ['payment_type', 'PULocation_bin', 'DOLocation_bin']\n"
     ]
    }
   ],
   "source": [
    "# Проверим, какие признаки есть в X\n",
    "print(\"Колонки X:\", list(X.columns))\n",
    "\n",
    "# Числовые признаки (будем масштабировать)\n",
    "numeric_features = [\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"pickup_hour\",\n",
    "    \"trip_duration_min\"\n",
    "]\n",
    "\n",
    "# Категориальные признаки (будем one-hot кодировать)\n",
    "categorical_features = [\n",
    "    \"payment_type\",\n",
    "    \"PULocation_bin\",\n",
    "    \"DOLocation_bin\"\n",
    "]\n",
    "\n",
    "print(\"Числовые признаки:\", numeric_features)\n",
    "print(\"Категориальные признаки:\", categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da82db87-ed5a-4a78-9107-f33a961be605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def create_preprocessing_pipeline(numeric_features, categorical_features):\n",
    "    \"\"\"\n",
    "    Создать пайплайн предобработки:\n",
    "    - масштабирование числовых признаков\n",
    "    - one-hot кодирование категориальных\n",
    "    \"\"\"\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "def create_model_pipeline(preprocessor, model):\n",
    "    \"\"\"\n",
    "    Создать полный пайплайн: предобработка + модель\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d2f9fd7-37e0-478f-92dc-d554edd97461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('preprocessor',\n",
       "                  ColumnTransformer(transformers=[('num',\n",
       "                                                   Pipeline(steps=[('scaler',\n",
       "                                                                    StandardScaler())]),\n",
       "                                                   ['passenger_count',\n",
       "                                                    'trip_distance',\n",
       "                                                    'pickup_hour',\n",
       "                                                    'trip_duration_min']),\n",
       "                                                  ('cat',\n",
       "                                                   Pipeline(steps=[('onehot',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                  sparse_output=False))]),\n",
       "                                                   ['payment_type',\n",
       "                                                    'PULocation_bin',\n",
       "                                                    'DOLocation_bin'])])),\n",
       "                 ('model', LinearRegression())]),\n",
       " Pipeline(steps=[('preprocessor',\n",
       "                  ColumnTransformer(transformers=[('num',\n",
       "                                                   Pipeline(steps=[('scaler',\n",
       "                                                                    StandardScaler())]),\n",
       "                                                   ['passenger_count',\n",
       "                                                    'trip_distance',\n",
       "                                                    'pickup_hour',\n",
       "                                                    'trip_duration_min']),\n",
       "                                                  ('cat',\n",
       "                                                   Pipeline(steps=[('onehot',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                  sparse_output=False))]),\n",
       "                                                   ['payment_type',\n",
       "                                                    'PULocation_bin',\n",
       "                                                    'DOLocation_bin'])])),\n",
       "                 ('model',\n",
       "                  RandomForestRegressor(n_estimators=200, n_jobs=-1,\n",
       "                                        random_state=42))]),\n",
       " Pipeline(steps=[('preprocessor',\n",
       "                  ColumnTransformer(transformers=[('num',\n",
       "                                                   Pipeline(steps=[('scaler',\n",
       "                                                                    StandardScaler())]),\n",
       "                                                   ['passenger_count',\n",
       "                                                    'trip_distance',\n",
       "                                                    'pickup_hour',\n",
       "                                                    'trip_duration_min']),\n",
       "                                                  ('cat',\n",
       "                                                   Pipeline(steps=[('onehot',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                  sparse_output=False))]),\n",
       "                                                   ['payment_type',\n",
       "                                                    'PULocation_bin',\n",
       "                                                    'DOLocation_bin'])])),\n",
       "                 ('model',\n",
       "                  GradientBoostingRegressor(n_estimators=200, random_state=42))]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# 1) Пайплайн предобработки\n",
    "preprocessor = create_preprocessing_pipeline(numeric_features, categorical_features)\n",
    "\n",
    "# 2) Модели\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_model = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3) Полные пайплайны: предобработка + модель\n",
    "pipeline_linear = create_model_pipeline(preprocessor, linear_model)\n",
    "pipeline_rf = create_model_pipeline(preprocessor, rf_model)\n",
    "pipeline_gb = create_model_pipeline(preprocessor, gb_model)\n",
    "\n",
    "pipeline_linear, pipeline_rf, pipeline_gb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a786a15-c318-4d70-a29d-0105e030f0b4",
   "metadata": {},
   "source": [
    "# Сравнение стратегий кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a794c8a-2962-481d-97e8-3ba81cd8e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, TimeSeriesSplit, GroupKFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def compare_cv_strategies(X, y, pipeline, groups=None, n_splits=5):\n",
    "    \"\"\"\n",
    "    Сравнить разные стратегии кросс-валидации для регрессии.\n",
    "    \n",
    "    Считаем RMSE и MAE для:\n",
    "    - KFold (перемешанный)\n",
    "    - TimeSeriesSplit (по порядку строк X, поэтому важно, чтобы X был отсортирован по времени)\n",
    "    - GroupKFold (опционально, если передан groups)\n",
    "    \"\"\"\n",
    "\n",
    "    cv_strategies = {\n",
    "        \"KFold\": KFold(n_splits=n_splits, shuffle=True, random_state=42),\n",
    "        \"TimeSeriesSplit\": TimeSeriesSplit(n_splits=n_splits)\n",
    "    }\n",
    "\n",
    "    # Добавляем GroupKFold, если заданы группы\n",
    "    if groups is not None:\n",
    "        cv_strategies[\"GroupKFold\"] = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    results = {}\n",
    "    for cv_name, cv_splitter in cv_strategies.items():\n",
    "        rmse_scores = []\n",
    "        mae_scores = []\n",
    "\n",
    "        # Особый случай для GroupKFold: нужен параметр groups\n",
    "        if isinstance(cv_splitter, GroupKFold):\n",
    "            split_iter = cv_splitter.split(X, y, groups=groups)\n",
    "        else:\n",
    "            split_iter = cv_splitter.split(X, y)\n",
    "\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(split_iter, start=1):\n",
    "            X_train_fold = X.iloc[train_idx]\n",
    "            X_val_fold = X.iloc[val_idx]\n",
    "            y_train_fold = y.iloc[train_idx]\n",
    "            y_val_fold = y.iloc[val_idx]\n",
    "\n",
    "            # Обучаем пайплайн\n",
    "            pipeline.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Предсказываем на валидации\n",
    "            y_pred = pipeline.predict(X_val_fold)\n",
    "\n",
    "            # --- ВАЖНО: считаем RMSE через sqrt(MSE), без параметра squared ---\n",
    "            mse = mean_squared_error(y_val_fold, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "\n",
    "            mae = mean_absolute_error(y_val_fold, y_pred)\n",
    "\n",
    "            rmse_scores.append(rmse)\n",
    "            mae_scores.append(mae)\n",
    "        results[cv_name] = {\n",
    "            \"rmse_mean\": float(np.mean(rmse_scores)),\n",
    "            \"rmse_std\": float(np.std(rmse_scores)),\n",
    "            \"mae_mean\": float(np.mean(mae_scores)),\n",
    "            \"mae_std\": float(np.std(mae_scores)),\n",
    "        }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ed95a90-3559-43c9-b52c-22720380831d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KFold': {'rmse_mean': 7.333314532774233,\n",
       "  'rmse_std': 0.3592797794238624,\n",
       "  'mae_mean': 2.879975243812699,\n",
       "  'mae_std': 0.04422039511813796},\n",
       " 'TimeSeriesSplit': {'rmse_mean': 7.336057652308503,\n",
       "  'rmse_std': 0.21414418073222985,\n",
       "  'mae_mean': 2.936601710431989,\n",
       "  'mae_std': 0.06804428284685471},\n",
       " 'GroupKFold': {'rmse_mean': 8.215810598154256,\n",
       "  'rmse_std': 3.07130001023099,\n",
       "  'mae_mean': 3.5694660246023333,\n",
       "  'mae_std': 1.7311874542656547}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = X[\"PULocation_bin\"]\n",
    "\n",
    "cv_results_rf = compare_cv_strategies(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    pipeline=pipeline_rf,\n",
    "    groups=groups,\n",
    "    n_splits=5\n",
    ")\n",
    "\n",
    "cv_results_rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14a91e5-29c8-4eb7-a5cc-73ec9ecead29",
   "metadata": {},
   "source": [
    "# Bootstrap доверительных интервалов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b4fc39f-8fad-4ef5-b19a-462604f9d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def rmse_metric(y_true, y_pred):\n",
    "    \"\"\"Вычисление RMSE.\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return float(np.sqrt(mse))\n",
    "\n",
    "\n",
    "def bootstrap_confidence_interval(X, y, pipeline, metric_func, n_bootstrap=1000, alpha=0.05, random_state=42):\n",
    "    \"\"\"\n",
    "    Построить доверительный интервал метрики через bootstrap.\n",
    "    \n",
    "    Параметры\n",
    "    ---------\n",
    "    X : pd.DataFrame\n",
    "        Признаки (желательно train-часть).\n",
    "    y : pd.Series\n",
    "        Целевая переменная.\n",
    "    pipeline : sklearn Pipeline\n",
    "        Пайплайн (предобработка + модель).\n",
    "    metric_func : callable\n",
    "        Функция метрики: metric_func(y_true, y_pred) -> float.\n",
    "        В нашем случае — RMSE.\n",
    "    n_bootstrap : int\n",
    "        Число bootstrap-итераций.\n",
    "    alpha : float\n",
    "        Уровень значимости (0.05 ⇒ 95% ДИ).\n",
    "    random_state : int\n",
    "        Зерно генератора случайных чисел.\n",
    "    \n",
    "    Возвращает\n",
    "    ----------\n",
    "    lower : float\n",
    "        Нижняя граница доверительного интервала (percentile).\n",
    "    upper : float\n",
    "        Верхняя граница доверительного интервала.\n",
    "    bootstrap_metrics : list of float\n",
    "        Значения метрики на всех bootstrap-выборках.\n",
    "    \"\"\"\n",
    "    n_samples = len(X)\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    bootstrap_metrics = []\n",
    "\n",
    "    for i in range(n_bootstrap):\n",
    "        # 1) bootstrap-индексы с возвращением\n",
    "        indices = rng.integers(0, n_samples, size=n_samples)\n",
    "\n",
    "        X_boot = X.iloc[indices]\n",
    "        y_boot = y.iloc[indices]\n",
    "\n",
    "        # 2) обучение модели на bootstrap-выборке\n",
    "        pipeline.fit(X_boot, y_boot)\n",
    "\n",
    "        # 3) предсказание на этой же выборке\n",
    "        y_pred = pipeline.predict(X_boot)\n",
    "\n",
    "        # 4) вычисление метрики\n",
    "        metric_value = metric_func(y_boot, y_pred)\n",
    "        bootstrap_metrics.append(metric_value)\n",
    "\n",
    "    # 5) percentiles для ДИ\n",
    "    lower = float(np.percentile(bootstrap_metrics, 100 * alpha / 2))\n",
    "    upper = float(np.percentile(bootstrap_metrics, 100 * (1 - alpha / 2)))\n",
    "\n",
    "    return lower, upper, bootstrap_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a1ade9b-5fbf-43d5-a66b-f733ba6277a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Пример: bootstrap CI для RMSE RandomForest\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m lower_rmse, upper_rmse, boot_rmse_values = \u001b[43mbootstrap_confidence_interval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# в финальной версии лучше X_train\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# и y_train\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline_rf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrmse_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# для начала можно взять 300, потом 1000\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m95% bootstrap CI для RMSE (RandomForest): [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlower_rmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupper_rmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mbootstrap_confidence_interval\u001b[39m\u001b[34m(X, y, pipeline, metric_func, n_bootstrap, alpha, random_state)\u001b[39m\n\u001b[32m     51\u001b[39m y_boot = y.iloc[indices]\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# 2) обучение модели на bootstrap-выборке\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_boot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# 3) предсказание на этой же выборке\u001b[39;00m\n\u001b[32m     57\u001b[39m y_pred = pipeline.predict(X_boot)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\pipeline.py:663\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    658\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    659\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    660\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    661\u001b[39m             all_params=params,\n\u001b[32m    662\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\ensemble\\_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Пример: bootstrap CI для RMSE RandomForest\n",
    "\n",
    "lower_rmse, upper_rmse, boot_rmse_values = bootstrap_confidence_interval(\n",
    "    X=X,          # в финальной версии лучше X_train\n",
    "    y=y,          # и y_train\n",
    "    pipeline=pipeline_rf,\n",
    "    metric_func=rmse_metric,\n",
    "    n_bootstrap=300,   # для начала можно взять 300, потом 1000\n",
    "    alpha=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"95% bootstrap CI для RMSE (RandomForest): [{lower_rmse:.3f}, {upper_rmse:.3f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a662292-2c75-4968-9374-1d4e783939cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "diff_arr = np.array(differences_lr_rf)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(diff_arr, bins=30, kde=True)\n",
    "plt.axvline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Разность RMSE: Linear - RandomForest\")\n",
    "plt.ylabel(\"Частота\")\n",
    "plt.title(\"Bootstrap-распределение разности RMSE (Linear - RF)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Средняя разность RMSE (Linear - RF):\", diff_arr.mean())\n",
    "print(\"Стандартное отклонение разности:\", diff_arr.std())\n",
    "print(\"Доля случаев, когда RF лучше (разность > 0):\", (diff_arr > 0).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f4af9-838f-4dd7-8b23-37b09d34c2bc",
   "metadata": {},
   "source": [
    "# Сравнение моделей через bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262b4d0b-326b-4970-b201-9aaca77c2b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_bootstrap(X, y, pipeline1, pipeline2, metric_func, \n",
    "                             n_bootstrap=1000, random_state=42):\n",
    "    \"\"\"\n",
    "    Сравнить две модели через bootstrap по заданной метрике.\n",
    "    \n",
    "    На каждой bootstrap-итерации:\n",
    "    - обучаем обе модели на одной и той же bootstrap-выборке;\n",
    "    - считаем метрику для каждой;\n",
    "    - сохраняем разность: metric1 - metric2.\n",
    "    \n",
    "    Параметры\n",
    "    ---------\n",
    "    X : pd.DataFrame\n",
    "        Признаки (желательно train-часть).\n",
    "    y : pd.Series\n",
    "        Целевая переменная.\n",
    "    pipeline1 : sklearn Pipeline\n",
    "        Первая модель (например, LinearRegression).\n",
    "    pipeline2 : sklearn Pipeline\n",
    "        Вторая модель (например, RandomForestRegressor).\n",
    "    metric_func : callable\n",
    "        Функция метрики: metric_func(y_true, y_pred) -> float.\n",
    "        В нашем случае — RMSE.\n",
    "    n_bootstrap : int\n",
    "        Количество bootstrap-итераций.\n",
    "    random_state : int\n",
    "        Зерно генератора случайных чисел.\n",
    "    \n",
    "    Возвращает\n",
    "    ----------\n",
    "    differences : list of float\n",
    "        Список разностей metric1 - metric2 на каждой итерации.\n",
    "        Если метрика = RMSE, то значения > 0 означают, что модель 2 лучше.\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = len(X)\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    differences = []\n",
    "\n",
    "    for i in range(n_bootstrap):\n",
    "        # bootstrap-индексы\n",
    "        indices = rng.integers(0, n_samples, size=n_samples)\n",
    "\n",
    "        X_boot = X.iloc[indices]\n",
    "        y_boot = y.iloc[indices]\n",
    "\n",
    "        # обучаем обе модели\n",
    "        pipeline1.fit(X_boot, y_boot)\n",
    "        pipeline2.fit(X_boot, y_boot)\n",
    "\n",
    "        # предсказания\n",
    "        y_pred1 = pipeline1.predict(X_boot)\n",
    "        y_pred2 = pipeline2.predict(X_boot)\n",
    "\n",
    "        # вычисляем метрики\n",
    "        m1 = metric_func(y_boot, y_pred1)\n",
    "        m2 = metric_func(y_boot, y_pred2)\n",
    "\n",
    "        # разность: metric1 - metric2\n",
    "        diff = m1 - m2\n",
    "        differences.append(float(diff))\n",
    "\n",
    "    return differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36855dd8-2939-42bd-9300-2115079b706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем LinearRegression (pipeline_linear) и RandomForest (pipeline_rf)\n",
    "differences_lr_rf = compare_models_bootstrap(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    pipeline1=pipeline_linear,\n",
    "    pipeline2=pipeline_rf,\n",
    "    metric_func=rmse_metric,\n",
    "    n_bootstrap=300,      # можно позже увеличить до 1000\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Быстрая сводка\n",
    "diff_arr = np.array(differences_lr_rf)\n",
    "print(\"Средняя разность RMSE (Linear - RF):\", diff_arr.mean())\n",
    "print(\"Стандартное отклонение разности:\", diff_arr.std())\n",
    "print(\"Доля случаев, когда RF лучше (разность > 0):\", (diff_arr > 0).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae7700-3a3e-440c-b04e-a2a705462801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "diff_arr = np.array(differences_lr_rf)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(diff_arr, bins=30, kde=True)\n",
    "plt.axvline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Разность RMSE: Linear - RandomForest\")\n",
    "plt.ylabel(\"Частота\")\n",
    "plt.title(\"Bootstrap-распределение разности RMSE (Linear - RF)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Средняя разность RMSE (Linear - RF):\", diff_arr.mean())\n",
    "print(\"Стандартное отклонение разности:\", diff_arr.std())\n",
    "print(\"Доля случаев, когда RF лучше (разность > 0):\", (diff_arr > 0).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf534564-421b-4dfa-a4f1-47ff78ddc2fc",
   "metadata": {},
   "source": [
    "# Permutation-test значимости модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9462f2-eb89-4cbe-94cc-f11aeeff7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def permutation_test(X, y, pipeline, metric_func, n_permutations=1000, random_state=42):\n",
    "    \"\"\"\n",
    "    Permutation test значимости модели.\n",
    "    \n",
    "    1) Обучаем модель на исходных (X, y), считаем метрику (RMSE).\n",
    "    2) n_permutations раз перемешиваем y, обучаем модель, считаем метрику.\n",
    "    3) p-value = доля permuted_metric <= real_metric \n",
    "       (для RMSE: если модель хорошая, real_metric сильно меньше, p-value ~ 0).\n",
    "    \n",
    "    Параметры\n",
    "    ---------\n",
    "    X : pd.DataFrame\n",
    "        Признаки.\n",
    "    y : pd.Series\n",
    "        Целевая.\n",
    "    pipeline : sklearn Pipeline\n",
    "        Модель (предобработка + алгоритм).\n",
    "    metric_func : callable\n",
    "        Функция метрики: metric_func(y_true, y_pred) -> float (RMSE).\n",
    "    n_permutations : int\n",
    "        Количество перестановок.\n",
    "    random_state : int\n",
    "        Зерно генератора случайных чисел.\n",
    "    \n",
    "    Возвращает\n",
    "    ----------\n",
    "    real_score : float\n",
    "        Метрика на реальных данных.\n",
    "    permuted_scores : list of float\n",
    "        Метрики на перемешанных данных.\n",
    "    p_value : float\n",
    "        Оценка p-value.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # --- 1. Реальный скор ---\n",
    "    pipeline.fit(X, y)\n",
    "    y_pred = pipeline.predict(X)\n",
    "    real_score = metric_func(y, y_pred)\n",
    "\n",
    "    permuted_scores = []\n",
    "\n",
    "    # Чтобы при перестановках не путаться с индексами, сделаем массив\n",
    "    y_values = y.values\n",
    "\n",
    "    for i in range(n_permutations):\n",
    "        # Перестановка целевой\n",
    "        perm_indices = rng.permutation(len(y_values))\n",
    "        y_perm = y_values[perm_indices]\n",
    "\n",
    "        # Обучаем на (X, y_perm)\n",
    "        pipeline.fit(X, y_perm)\n",
    "        y_pred_perm = pipeline.predict(X)\n",
    "\n",
    "        perm_score = metric_func(y_perm, y_pred_perm)\n",
    "        permuted_scores.append(float(perm_score))\n",
    "\n",
    "    permuted_scores = np.array(permuted_scores)\n",
    "\n",
    "    # --- 3. p-value ---\n",
    "    # Для RMSE \"меньше = лучше\". Нулевая модель ожидается с БОЛЬШИМ RMSE.\n",
    "    # Поэтому берём долю permuted_scores <= real_score\n",
    "    p_value = float(np.mean(permuted_scores <= real_score))\n",
    "\n",
    "    return float(real_score), permuted_scores, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bff6cd7-701d-44fc-b0dd-2aeddd95364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем уже определённую rmse_metric из предыдущих шагов\n",
    "\n",
    "real_rmse_rf, perm_rmse_rf, p_value_rf = permutation_test(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    pipeline=pipeline_rf,\n",
    "    metric_func=rmse_metric,\n",
    "    n_permutations=300,   # чтобы не ждать очень долго, потом можно увеличить\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Real RMSE (RandomForest): {real_rmse_rf:.3f}\")\n",
    "print(f\"Mean permuted RMSE: {perm_rmse_rf.mean():.3f}\")\n",
    "print(f\"p-value: {p_value_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf06ddba-7e59-49c5-a0c9-cbd75dc27b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(perm_rmse_rf, bins=30, kde=True)\n",
    "plt.axvline(real_rmse_rf, color=\"red\", linestyle=\"--\", label=f\"Real RMSE = {real_rmse_rf:.2f}\")\n",
    "plt.xlabel(\"RMSE (перемешанный y)\")\n",
    "plt.ylabel(\"Частота\")\n",
    "plt.title(\"Permutation test для RandomForest\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37877287-120d-429a-a9f7-070ce4b6a7a6",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de946463-8b9d-45f5-99aa-c2260b4bc424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c5e3a-1be2-41f3-9933-7e9bb261f20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0122228-f3fd-46ea-b619-774de65059cc",
   "metadata": {},
   "source": [
    "# SHAP анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2001ffcb-0e08-4b16-9055-24e914074a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26b5f1-3bc9-4ca5-8916-992e40c4b520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1fa9a",
   "metadata": {
    "id": "a2f1fa9a"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Лабораторная работа 3: Скелет кода\n",
    "Вывод для высокоразмерных данных, Bootstrap, CV, Feature Importance, SHAP\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, TimeSeriesSplit, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. ЗАГРУЗКА И ПРЕДВАРИТЕЛЬНАЯ ПОДГОТОВКА ДАННЫХ\n",
    "# ==============================================================================\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"Загрузить датасет и провести базовую подготовку\"\"\"\n",
    "    # TODO: Загрузите ваш датасет\n",
    "    # df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "    # TODO: Обработайте пропуски\n",
    "    # df = df.dropna(subset=['target_column'])\n",
    "\n",
    "    # TODO: Определите признаки и целевую переменную\n",
    "    # X = df.drop('target', axis=1)\n",
    "    # y = df['target']\n",
    "\n",
    "    return None, None  # замените на X, y\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. СОЗДАНИЕ ПАЙПЛАЙНОВ\n",
    "# ==============================================================================\n",
    "\n",
    "def create_preprocessing_pipeline(numeric_features, categorical_features):\n",
    "    \"\"\"Создать пайплайн предобработки\"\"\"\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "def create_model_pipeline(preprocessor, model):\n",
    "    \"\"\"Создать полный пайплайн: предобработка + модель\"\"\"\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. КРОСС-ВАЛИДАЦИЯ\n",
    "# ==============================================================================\n",
    "\n",
    "def compare_cv_strategies(X, y, pipeline, groups=None):\n",
    "    \"\"\"Сравнить разные стратегии кросс-валидации\"\"\"\n",
    "\n",
    "    cv_strategies = {\n",
    "        'KFold': KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        # TODO: добавьте TimeSeriesSplit если есть временная зависимость\n",
    "        # 'TimeSeries': TimeSeriesSplit(n_splits=5),\n",
    "        # TODO: добавьте GroupKFold если есть группы\n",
    "        # 'GroupKFold': GroupKFold(n_splits=5)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for cv_name, cv_splitter in cv_strategies.items():\n",
    "        scores = []\n",
    "\n",
    "        # TODO: реализуйте цикл кросс-валидации\n",
    "        # for train_idx, val_idx in cv_splitter.split(X, y, groups):\n",
    "        #     X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        #     y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        #\n",
    "        #     pipeline.fit(X_train_fold, y_train_fold)\n",
    "        #     y_pred = pipeline.predict(X_val_fold)\n",
    "        #     score = r2_score(y_val_fold, y_pred)\n",
    "        #     scores.append(score)\n",
    "\n",
    "        results[cv_name] = {\n",
    "            'mean': None,  # TODO: np.mean(scores)\n",
    "            'std': None    # TODO: np.std(scores)\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. BOOTSTRAP ДЛЯ ДОВЕРИТЕЛЬНЫХ ИНТЕРВАЛОВ\n",
    "# ==============================================================================\n",
    "\n",
    "def bootstrap_confidence_interval(X, y, pipeline, metric_func, n_bootstrap=1000, alpha=0.05):\n",
    "    \"\"\"Построить доверительный интервал метрики через bootstrap\"\"\"\n",
    "\n",
    "    n_samples = len(X)\n",
    "    bootstrap_metrics = []\n",
    "\n",
    "    for i in range(n_bootstrap):\n",
    "        # TODO: создайте bootstrap-выборку\n",
    "        # indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        # X_boot = X.iloc[indices]\n",
    "        # y_boot = y.iloc[indices]\n",
    "\n",
    "        # TODO: обучите модель и вычислите метрику\n",
    "        # pipeline.fit(X_boot, y_boot)\n",
    "        # y_pred = pipeline.predict(X_boot)\n",
    "        # metric = metric_func(y_boot, y_pred)\n",
    "        # bootstrap_metrics.append(metric)\n",
    "\n",
    "        pass\n",
    "\n",
    "    # TODO: вычислите квантили для доверительного интервала\n",
    "    lower = None  # np.percentile(bootstrap_metrics, 100 * alpha / 2)\n",
    "    upper = None  # np.percentile(bootstrap_metrics, 100 * (1 - alpha / 2))\n",
    "\n",
    "    return lower, upper, bootstrap_metrics\n",
    "\n",
    "\n",
    "def compare_models_bootstrap(X, y, pipeline1, pipeline2, n_bootstrap=1000):\n",
    "    \"\"\"Сравнить две модели через bootstrap\"\"\"\n",
    "\n",
    "    differences = []\n",
    "\n",
    "    for i in range(n_bootstrap):\n",
    "        # TODO: создайте bootstrap-выборку\n",
    "        # indices = np.random.choice(len(X), len(X), replace=True)\n",
    "        # X_boot = X.iloc[indices]\n",
    "        # y_boot = y.iloc[indices]\n",
    "\n",
    "        # TODO: обучите обе модели\n",
    "        # pipeline1.fit(X_boot, y_boot)\n",
    "        # pipeline2.fit(X_boot, y_boot)\n",
    "\n",
    "        # TODO: вычислите разность метрик\n",
    "        # y_pred1 = pipeline1.predict(X_boot)\n",
    "        # y_pred2 = pipeline2.predict(X_boot)\n",
    "        # diff = r2_score(y_boot, y_pred1) - r2_score(y_boot, y_pred2)\n",
    "        # differences.append(diff)\n",
    "\n",
    "        pass\n",
    "\n",
    "    return differences\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. PERMUTATION TEST\n",
    "# ==============================================================================\n",
    "\n",
    "def permutation_test(X, y, pipeline, n_permutations=1000):\n",
    "    \"\"\"Проверка значимости модели через permutation test\"\"\"\n",
    "\n",
    "    # TODO: обучите модель на реальных данных\n",
    "    # pipeline.fit(X, y)\n",
    "    # y_pred = pipeline.predict(X)\n",
    "    # true_score = r2_score(y, y_pred)\n",
    "\n",
    "    permuted_scores = []\n",
    "\n",
    "    for i in range(n_permutations):\n",
    "        # TODO: перемешайте целевую переменную\n",
    "        # y_perm = y.sample(frac=1, random_state=i).values\n",
    "\n",
    "        # TODO: обучите модель на перемешанных данных\n",
    "        # pipeline.fit(X, y_perm)\n",
    "        # y_pred_perm = pipeline.predict(X)\n",
    "        # perm_score = r2_score(y_perm, y_pred_perm)\n",
    "        # permuted_scores.append(perm_score)\n",
    "\n",
    "        pass\n",
    "\n",
    "    # TODO: вычислите p-value\n",
    "    # p_value = np.mean([s >= true_score for s in permuted_scores])\n",
    "\n",
    "    return None, permuted_scores  # замените на true_score, permuted_scores\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. FEATURE IMPORTANCE\n",
    "# ==============================================================================\n",
    "\n",
    "def calculate_permutation_importance(X, y, pipeline, n_repeats=10):\n",
    "    \"\"\"Вычислить permutation importance\"\"\"\n",
    "\n",
    "    # TODO: обучите модель\n",
    "    # pipeline.fit(X, y)\n",
    "\n",
    "    # TODO: вычислите permutation importance\n",
    "    # perm_importance = permutation_importance(\n",
    "    #     pipeline, X, y,\n",
    "    #     n_repeats=n_repeats,\n",
    "    #     random_state=42,\n",
    "    #     scoring='r2'\n",
    "    # )\n",
    "\n",
    "    # TODO: создайте DataFrame с результатами\n",
    "    # importance_df = pd.DataFrame({\n",
    "    #     'feature': X.columns,\n",
    "    #     'importance_mean': perm_importance.importances_mean,\n",
    "    #     'importance_std': perm_importance.importances_std\n",
    "    # }).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "    return None  # замените на importance_df\n",
    "\n",
    "\n",
    "def plot_feature_importance(importance_df, top_n=20):\n",
    "    \"\"\"Визуализировать важность признаков\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # TODO: постройте barplot для top_n признаков\n",
    "    # top_features = importance_df.head(top_n)\n",
    "    # plt.barh(top_features['feature'], top_features['importance_mean'])\n",
    "    # plt.xlabel('Permutation Importance')\n",
    "    # plt.title(f'Top {top_n} Features by Permutation Importance')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 7. SHAP АНАЛИЗ\n",
    "# ==============================================================================\n",
    "\n",
    "def calculate_shap_values(pipeline, X_sample):\n",
    "    \"\"\"Вычислить SHAP значения\"\"\"\n",
    "\n",
    "    # TODO: извлеките обученную модель из пайплайна\n",
    "    # model = pipeline.named_steps['model']\n",
    "\n",
    "    # TODO: создайте SHAP explainer\n",
    "    # explainer = shap.Explainer(model, X_sample)\n",
    "    # shap_values = explainer(X_sample)\n",
    "\n",
    "    return None  # замените на shap_values\n",
    "\n",
    "\n",
    "def plot_shap_summary(shap_values, X_sample):\n",
    "    \"\"\"Визуализировать SHAP summary plot\"\"\"\n",
    "\n",
    "    # TODO: постройте summary plot\n",
    "    # shap.summary_plot(shap_values, X_sample)\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def plot_shap_waterfall(shap_values, X_sample, observation_index=0):\n",
    "    \"\"\"Визуализировать SHAP waterfall для одного наблюдения\"\"\"\n",
    "\n",
    "    # TODO: постройте waterfall plot\n",
    "    # shap.waterfall_plot(shap_values[observation_index])\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 8. ОСНОВНОЙ WORKFLOW\n",
    "# ==============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Основной workflow лабораторной работы\"\"\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ЛАБОРАТОРНАЯ РАБОТА 3: СТАТИСТИЧЕСКИЙ ВЫВОД И ИНТЕРПРЕТАЦИЯ\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Шаг 1: Загрузка данных\n",
    "    print(\"\\n[1] Загрузка и подготовка данных...\")\n",
    "    X, y = load_and_prepare_data()\n",
    "\n",
    "    # TODO: определите списки числовых и категориальных признаков\n",
    "    # numeric_features = [...]\n",
    "    # categorical_features = [...]\n",
    "\n",
    "    # Шаг 2: Разделение на train/test\n",
    "    print(\"\\n[2] Разделение на train/test...\")\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(\n",
    "    #     X, y, test_size=0.2, random_state=42\n",
    "    # )\n",
    "\n",
    "    # Шаг 3: Создание пайплайнов\n",
    "    print(\"\\n[3] Создание пайплайнов...\")\n",
    "    # preprocessor = create_preprocessing_pipeline(numeric_features, categorical_features)\n",
    "\n",
    "    # TODO: создайте несколько моделей для сравнения\n",
    "    # pipeline_linear = create_model_pipeline(preprocessor, LinearRegression())\n",
    "    # pipeline_rf = create_model_pipeline(preprocessor, RandomForestRegressor(random_state=42))\n",
    "    # pipeline_gb = create_model_pipeline(preprocessor, GradientBoostingRegressor(random_state=42))\n",
    "\n",
    "    # Шаг 4: Сравнение стратегий CV\n",
    "    print(\"\\n[4] Сравнение стратегий кросс-валидации...\")\n",
    "    # cv_results = compare_cv_strategies(X_train, y_train, pipeline_rf)\n",
    "    # print(cv_results)\n",
    "\n",
    "    # Шаг 5: Bootstrap доверительные интервалы\n",
    "    print(\"\\n[5] Bootstrap для доверительных интервалов...\")\n",
    "    # lower, upper, boot_metrics = bootstrap_confidence_interval(\n",
    "    #     X_train, y_train, pipeline_rf, r2_score, n_bootstrap=1000\n",
    "    # )\n",
    "    # print(f\"95% CI для R²: [{lower:.4f}, {upper:.4f}]\")\n",
    "\n",
    "    # Шаг 6: Сравнение моделей через bootstrap\n",
    "    print(\"\\n[6] Сравнение моделей через bootstrap...\")\n",
    "    # differences = compare_models_bootstrap(\n",
    "    #     X_train, y_train, pipeline_rf, pipeline_linear, n_bootstrap=1000\n",
    "    # )\n",
    "\n",
    "    # Шаг 7: Permutation test\n",
    "    print(\"\\n[7] Permutation test...\")\n",
    "    # true_score, perm_scores = permutation_test(\n",
    "    #     X_train, y_train, pipeline_rf, n_permutations=1000\n",
    "    # )\n",
    "\n",
    "    # Шаг 8: Обучение финальных моделей\n",
    "    print(\"\\n[8] Обучение финальных моделей на всех train данных...\")\n",
    "    # pipeline_rf.fit(X_train, y_train)\n",
    "    # y_pred_test = pipeline_rf.predict(X_test)\n",
    "    # test_r2 = r2_score(y_test, y_pred_test)\n",
    "    # print(f\"Test R²: {test_r2:.4f}\")\n",
    "\n",
    "    # Шаг 9: Permutation Importance\n",
    "    print(\"\\n[9] Вычисление permutation importance...\")\n",
    "    # importance_df = calculate_permutation_importance(\n",
    "    #     X_test, y_test, pipeline_rf, n_repeats=10\n",
    "    # )\n",
    "    # plot_feature_importance(importance_df, top_n=20)\n",
    "\n",
    "    # Шаг 10: SHAP анализ\n",
    "    print(\"\\n[10] SHAP анализ...\")\n",
    "    # X_sample = X_test.sample(min(1000, len(X_test)), random_state=42)\n",
    "    # X_sample_transformed = pipeline_rf.named_steps['preprocessor'].transform(X_sample)\n",
    "    # shap_values = calculate_shap_values(pipeline_rf, X_sample_transformed)\n",
    "    # plot_shap_summary(shap_values, X_sample)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ГОТОВО!\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d756afb-b3e5-4101-bd17-dfc6cc447050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "      <th>cbd_congestion_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-08-01 00:52:23</td>\n",
       "      <td>2025-08-01 01:12:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>33.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.49</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-08-01 00:03:01</td>\n",
       "      <td>2025-08-01 00:15:33</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-08-01 00:24:38</td>\n",
       "      <td>2025-08-01 00:24:38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>249</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.94</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-08-01 00:48:19</td>\n",
       "      <td>2025-08-01 00:48:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.58</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-08-01 00:25:34</td>\n",
       "      <td>2025-08-01 00:33:18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.72</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2025-08-01 00:52:23   2025-08-01 01:12:20              1.0   \n",
       "1         2  2025-08-01 00:03:01   2025-08-01 00:15:33              2.0   \n",
       "2         7  2025-08-01 00:24:38   2025-08-01 00:24:38              2.0   \n",
       "3         7  2025-08-01 00:48:19   2025-08-01 00:48:19              1.0   \n",
       "4         2  2025-08-01 00:25:34   2025-08-01 00:33:18              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           8.44         1.0                  N           138           141   \n",
       "1           4.98         1.0                  N           138           193   \n",
       "2           1.89         1.0                  N           249            45   \n",
       "3           2.35         1.0                  N            79           229   \n",
       "4           2.14         1.0                  N            43            48   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1         33.8    6.0      0.5        5.00          6.94   \n",
       "1             1         21.2    6.0      0.5        0.00          0.00   \n",
       "2             1         14.2    0.0      0.5        3.99          0.00   \n",
       "3             1         11.4    0.0      0.5        3.43          0.00   \n",
       "4             1         11.4    1.0      0.5        2.57          0.00   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \\\n",
       "0                    1.0         57.49                   2.5         1.75   \n",
       "1                    1.0         30.45                   0.0         1.75   \n",
       "2                    1.0         23.94                   2.5         0.00   \n",
       "3                    1.0         20.58                   2.5         0.00   \n",
       "4                    1.0         19.72                   2.5         0.00   \n",
       "\n",
       "   cbd_congestion_fee  \n",
       "0                0.00  \n",
       "1                0.00  \n",
       "2                0.75  \n",
       "3                0.75  \n",
       "4                0.75  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер (строки, столбцы): (3574091, 20)\n",
      "\n",
      "Список колонок:\n",
      "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
      "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
      "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
      "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
      "       'total_amount', 'congestion_surcharge', 'Airport_fee',\n",
      "       'cbd_congestion_fee'],\n",
      "      dtype='object')\n",
      "\n",
      "Типы данных:\n",
      "VendorID                          int32\n",
      "tpep_pickup_datetime     datetime64[us]\n",
      "tpep_dropoff_datetime    datetime64[us]\n",
      "passenger_count                 float64\n",
      "trip_distance                   float64\n",
      "RatecodeID                      float64\n",
      "store_and_fwd_flag               object\n",
      "PULocationID                      int32\n",
      "DOLocationID                      int32\n",
      "payment_type                      int64\n",
      "fare_amount                     float64\n",
      "extra                           float64\n",
      "mta_tax                         float64\n",
      "tip_amount                      float64\n",
      "tolls_amount                    float64\n",
      "improvement_surcharge           float64\n",
      "total_amount                    float64\n",
      "congestion_surcharge            float64\n",
      "Airport_fee                     float64\n",
      "cbd_congestion_fee              float64\n",
      "dtype: object\n",
      "\n",
      "Пропущенные значения:\n",
      "VendorID                      0\n",
      "tpep_pickup_datetime          0\n",
      "tpep_dropoff_datetime         0\n",
      "passenger_count          886234\n",
      "trip_distance                 0\n",
      "RatecodeID               886234\n",
      "store_and_fwd_flag       886234\n",
      "PULocationID                  0\n",
      "DOLocationID                  0\n",
      "payment_type                  0\n",
      "fare_amount                   0\n",
      "extra                         0\n",
      "mta_tax                       0\n",
      "tip_amount                    0\n",
      "tolls_amount                  0\n",
      "improvement_surcharge         0\n",
      "total_amount                  0\n",
      "congestion_surcharge     886234\n",
      "Airport_fee              886234\n",
      "cbd_congestion_fee            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"yellow_tripdata_2025-08.parquet\")\n",
    "\n",
    "display(df.head())\n",
    "print(\"Размер (строки, столбцы):\", df.shape)\n",
    "print(\"\\nСписок колонок:\")\n",
    "print(df.columns)\n",
    "print(\"\\nТипы данных:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nПропущенные значения:\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d55a4d-855f-484c-9890-2020bdc339df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
